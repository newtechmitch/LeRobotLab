{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef2ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeRobot Dataset Explorer - Ready!\n",
      "This notebook will help you explore all available LeRobot datasets\n"
     ]
    }
   ],
   "source": [
    "# Essential imports\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# LeRobot specific imports  \n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata\n",
    "\n",
    "print(\"LeRobot Dataset Explorer - Ready!\")\n",
    "print(\"This notebook will help you explore all available LeRobot datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e744403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovering LeRobot datasets...\n",
      "Found 103 datasets:\n",
      "   1. lerobot/aloha_mobile_cabinet\n",
      "   2. lerobot/aloha_mobile_chair\n",
      "   3. lerobot/aloha_mobile_elevator\n",
      "   4. lerobot/aloha_mobile_shrimp\n",
      "   5. lerobot/aloha_mobile_wash_pan\n",
      "   6. lerobot/aloha_mobile_wipe_wine\n",
      "   7. lerobot/aloha_sim_insertion_human\n",
      "   8. lerobot/aloha_sim_insertion_human_image\n",
      "   9. lerobot/aloha_sim_insertion_scripted\n",
      "  10. lerobot/aloha_sim_insertion_scripted_image\n",
      "  ... and 93 more\n",
      "\n",
      "Dataset Family Analysis:\n",
      "  aloha: 29 dataset(s)\n",
      "  berkeley: 8 dataset(s)\n",
      "  xarm: 8 dataset(s)\n",
      "  utokyo: 5 dataset(s)\n",
      "  koch: 4 dataset(s)\n",
      "  libero: 4 dataset(s)\n",
      "  unitreeh1: 4 dataset(s)\n",
      "  austin: 3 dataset(s)\n",
      "  cmu: 3 dataset(s)\n",
      "  dlr: 3 dataset(s)\n"
     ]
    }
   ],
   "source": [
    "def get_lerobot_datasets():\n",
    "    \"\"\"Get list of all LeRobot datasets from HuggingFace Hub\"\"\"\n",
    "    api = HfApi()\n",
    "    \n",
    "    try:\n",
    "        datasets = api.list_datasets(author=\"lerobot\", limit=None)\n",
    "        dataset_names = [dataset.id for dataset in datasets]\n",
    "        return sorted(dataset_names)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching datasets: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"Discovering LeRobot datasets...\")\n",
    "available_datasets = get_lerobot_datasets()\n",
    "\n",
    "print(f\"Found {len(available_datasets)} datasets:\")\n",
    "for i, dataset_name in enumerate(available_datasets[:10]):  # Show first 10\n",
    "    print(f\"  {i+1:2d}. {dataset_name}\")\n",
    "\n",
    "if len(available_datasets) > 10:\n",
    "    print(f\"  ... and {len(available_datasets) - 10} more\")\n",
    "\n",
    "# Analyze dataset families\n",
    "print(f\"\\nDataset Family Analysis:\")\n",
    "families = {}\n",
    "for dataset in available_datasets:\n",
    "    family = dataset.replace(\"lerobot/\", \"\").split('_')[0]\n",
    "    families[family] = families.get(family, 0) + 1\n",
    "\n",
    "sorted_families = sorted(families.items(), key=lambda x: x[1], reverse=True)\n",
    "for family, count in sorted_families[:10]:  # Show top 10 families\n",
    "    print(f\"  {family}: {count} dataset(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e38741f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_metadata(dataset_name):\n",
    "    \"\"\"Get metadata without loading the full dataset\"\"\"\n",
    "    try:\n",
    "        print(f\"  Processing {dataset_name}...\")\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(1.0)\n",
    "        \n",
    "        metadata = LeRobotDatasetMetadata(dataset_name)\n",
    "        \n",
    "        return {\n",
    "            'dataset_name': dataset_name,\n",
    "            'category': dataset_name.replace(\"lerobot/\", \"\").split('_')[0],\n",
    "            'num_episodes': metadata.total_episodes,\n",
    "            'total_samples': metadata.total_frames,\n",
    "            'fps': metadata.fps,\n",
    "            'robot_type': metadata.robot_type,\n",
    "            'camera_keys': metadata.camera_keys,\n",
    "            'features': list(metadata.features.keys()),\n",
    "            'has_images': len(metadata.camera_keys) > 0  \n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Error: {e}\")\n",
    "        return {\n",
    "            'dataset_name': dataset_name,\n",
    "            'category': dataset_name.replace(\"lerobot/\", \"\").split('_')[0],\n",
    "            'num_episodes': 'Error',\n",
    "            'total_samples': 'Error',\n",
    "            'fps': 'Error',\n",
    "            'robot_type': 'Error',\n",
    "            'camera_keys': [],\n",
    "            'features': [],\n",
    "            'has_images': False\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c88541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting metadata from all datasets...\n",
      "This may take a few minutes...\n",
      "Processing 1/103: aloha_mobile_cabinet\n",
      "  Processing lerobot/aloha_mobile_cabinet...\n",
      "Processing 2/103: aloha_mobile_chair\n",
      "  Processing lerobot/aloha_mobile_chair...\n",
      "Processing 3/103: aloha_mobile_elevator\n",
      "  Processing lerobot/aloha_mobile_elevator...\n",
      "Processing 4/103: aloha_mobile_shrimp\n",
      "  Processing lerobot/aloha_mobile_shrimp...\n",
      "Processing 5/103: aloha_mobile_wash_pan\n",
      "  Processing lerobot/aloha_mobile_wash_pan...\n",
      "  Taking a break...\n",
      "Processing 6/103: aloha_mobile_wipe_wine\n",
      "  Processing lerobot/aloha_mobile_wipe_wine...\n",
      "Processing 7/103: aloha_sim_insertion_human\n",
      "  Processing lerobot/aloha_sim_insertion_human...\n",
      "Processing 8/103: aloha_sim_insertion_human_image\n",
      "  Processing lerobot/aloha_sim_insertion_human_image...\n",
      "Processing 9/103: aloha_sim_insertion_scripted\n",
      "  Processing lerobot/aloha_sim_insertion_scripted...\n",
      "Processing 10/103: aloha_sim_insertion_scripted_image\n",
      "  Processing lerobot/aloha_sim_insertion_scripted_image...\n",
      "  Taking a break...\n",
      "Processing 11/103: aloha_sim_transfer_cube_human\n",
      "  Processing lerobot/aloha_sim_transfer_cube_human...\n",
      "Processing 12/103: aloha_sim_transfer_cube_human_image\n",
      "  Processing lerobot/aloha_sim_transfer_cube_human_image...\n",
      "Processing 13/103: aloha_sim_transfer_cube_scripted\n",
      "  Processing lerobot/aloha_sim_transfer_cube_scripted...\n",
      "Processing 14/103: aloha_sim_transfer_cube_scripted_image\n",
      "  Processing lerobot/aloha_sim_transfer_cube_scripted_image...\n",
      "Processing 15/103: aloha_static_battery\n",
      "  Processing lerobot/aloha_static_battery...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/aloha_static_battery) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/aloha_static_battery \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "  Taking a break...\n",
      "Processing 16/103: aloha_static_candy\n",
      "  Processing lerobot/aloha_static_candy...\n",
      "Processing 17/103: aloha_static_coffee\n",
      "  Processing lerobot/aloha_static_coffee...\n",
      "Processing 18/103: aloha_static_coffee_new\n",
      "  Processing lerobot/aloha_static_coffee_new...\n",
      "Processing 19/103: aloha_static_cups_open\n",
      "  Processing lerobot/aloha_static_cups_open...\n",
      "Processing 20/103: aloha_static_fork_pick_up\n",
      "  Processing lerobot/aloha_static_fork_pick_up...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/aloha_static_fork_pick_up) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/aloha_static_fork_pick_up \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "  Taking a break...\n",
      "Processing 21/103: aloha_static_pingpong_test\n",
      "  Processing lerobot/aloha_static_pingpong_test...\n",
      "Processing 22/103: aloha_static_pro_pencil\n",
      "  Processing lerobot/aloha_static_pro_pencil...\n",
      "Processing 23/103: aloha_static_screw_driver\n",
      "  Processing lerobot/aloha_static_screw_driver...\n",
      "Processing 24/103: aloha_static_tape\n",
      "  Processing lerobot/aloha_static_tape...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/aloha_static_tape) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/aloha_static_tape \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 25/103: aloha_static_thread_velcro\n",
      "  Processing lerobot/aloha_static_thread_velcro...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/aloha_static_thread_velcro) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/aloha_static_thread_velcro \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "  Taking a break...\n",
      "Processing 26/103: aloha_static_towel\n",
      "  Processing lerobot/aloha_static_towel...\n",
      "Processing 27/103: aloha_static_vinh_cup\n",
      "  Processing lerobot/aloha_static_vinh_cup...\n",
      "Processing 28/103: aloha_static_vinh_cup_left\n",
      "  Processing lerobot/aloha_static_vinh_cup_left...\n",
      "Processing 29/103: aloha_static_ziploc_slide\n",
      "  Processing lerobot/aloha_static_ziploc_slide...\n",
      "Processing 30/103: asu_table_top\n",
      "  Processing lerobot/asu_table_top...\n",
      "  Taking a break...\n",
      "Processing 31/103: austin_buds_dataset\n",
      "  Processing lerobot/austin_buds_dataset...\n",
      "Processing 32/103: austin_sailor_dataset\n",
      "  Processing lerobot/austin_sailor_dataset...\n",
      "Processing 33/103: austin_sirius_dataset\n",
      "  Processing lerobot/austin_sirius_dataset...\n",
      "Processing 34/103: berkeley_autolab_ur5\n",
      "  Processing lerobot/berkeley_autolab_ur5...\n",
      "Processing 35/103: berkeley_cable_routing\n",
      "  Processing lerobot/berkeley_cable_routing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/berkeley_cable_routing) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/berkeley_cable_routing\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Taking a break...\n",
      "Processing 36/103: berkeley_fanuc_manipulation\n",
      "  Processing lerobot/berkeley_fanuc_manipulation...\n",
      "Processing 37/103: berkeley_gnm_cory_hall\n",
      "  Processing lerobot/berkeley_gnm_cory_hall...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/berkeley_gnm_cory_hall) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/berkeley_gnm_cory_hall\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 38/103: berkeley_gnm_recon\n",
      "  Processing lerobot/berkeley_gnm_recon...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/berkeley_gnm_recon) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/berkeley_gnm_recon\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 39/103: berkeley_gnm_sac_son\n",
      "  Processing lerobot/berkeley_gnm_sac_son...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/berkeley_gnm_sac_son) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/berkeley_gnm_sac_son\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 40/103: berkeley_mvp\n",
      "  Processing lerobot/berkeley_mvp...\n",
      "  Taking a break...\n",
      "Processing 41/103: berkeley_rpt\n",
      "  Processing lerobot/berkeley_rpt...\n",
      "Processing 42/103: cmu_franka_exploration_dataset\n",
      "  Processing lerobot/cmu_franka_exploration_dataset...\n",
      "Processing 43/103: cmu_play_fusion\n",
      "  Processing lerobot/cmu_play_fusion...\n",
      "Processing 44/103: cmu_stretch\n",
      "  Processing lerobot/cmu_stretch...\n",
      "Processing 45/103: columbia_cairlab_pusht_real\n",
      "  Processing lerobot/columbia_cairlab_pusht_real...\n",
      "  Taking a break...\n",
      "Processing 46/103: conq_hose_manipulation\n",
      "  Processing lerobot/conq_hose_manipulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/conq_hose_manipulation) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/conq_hose_manipulation\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 47/103: dlr_edan_shared_control\n",
      "  Processing lerobot/dlr_edan_shared_control...\n",
      "Processing 48/103: dlr_sara_grid_clamp\n",
      "  Processing lerobot/dlr_sara_grid_clamp...\n",
      "Processing 49/103: dlr_sara_pour\n",
      "  Processing lerobot/dlr_sara_pour...\n",
      "Processing 50/103: droid_100\n",
      "  Processing lerobot/droid_100...\n",
      "  Taking a break...\n",
      "Processing 51/103: fmb\n",
      "  Processing lerobot/fmb...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/fmb) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/fmb\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 52/103: iamlab_cmu_pickup_insert\n",
      "  Processing lerobot/iamlab_cmu_pickup_insert...\n",
      "Processing 53/103: imperialcollege_sawyer_wrist_cam\n",
      "  Processing lerobot/imperialcollege_sawyer_wrist_cam...\n",
      "Processing 54/103: jaco_play\n",
      "  Processing lerobot/jaco_play...\n",
      "Processing 55/103: kaist_nonprehensile\n",
      "  Processing lerobot/kaist_nonprehensile...\n",
      "  Taking a break...\n",
      "Processing 56/103: koch_pick_place_1_lego\n",
      "  Processing lerobot/koch_pick_place_1_lego...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/koch_pick_place_1_lego) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/koch_pick_place_1_lego \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 57/103: koch_pick_place_1_lego_raph\n",
      "  Processing lerobot/koch_pick_place_1_lego_raph...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/koch_pick_place_1_lego_raph) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/koch_pick_place_1_lego_raph \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 58/103: koch_pick_place_5_lego\n",
      "  Processing lerobot/koch_pick_place_5_lego...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/koch_pick_place_5_lego) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/koch_pick_place_5_lego \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 59/103: koch_pick_place_5_lego_random_pose\n",
      "  Processing lerobot/koch_pick_place_5_lego_random_pose...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/koch_pick_place_5_lego_random_pose) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/koch_pick_place_5_lego_random_pose \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 60/103: libero_10_image\n",
      "  Processing lerobot/libero_10_image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/libero_10_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/libero_10_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Taking a break...\n",
      "Processing 61/103: libero_goal_image\n",
      "  Processing lerobot/libero_goal_image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/libero_goal_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/libero_goal_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 62/103: libero_object_image\n",
      "  Processing lerobot/libero_object_image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/libero_object_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/libero_object_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 63/103: libero_spatial_image\n",
      "  Processing lerobot/libero_spatial_image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/libero_spatial_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/libero_spatial_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 64/103: metaworld_mt50\n",
      "  Processing lerobot/metaworld_mt50...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/metaworld_mt50) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/metaworld_mt50\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 65/103: metaworld_mt50_push_v2_image\n",
      "  Processing lerobot/metaworld_mt50_push_v2_image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/metaworld_mt50_push_v2_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/metaworld_mt50_push_v2_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Taking a break...\n",
      "Processing 66/103: nyu_door_opening_surprising_effectiveness\n",
      "  Processing lerobot/nyu_door_opening_surprising_effectiveness...\n",
      "Processing 67/103: nyu_franka_play_dataset\n",
      "  Processing lerobot/nyu_franka_play_dataset...\n",
      "Processing 68/103: nyu_rot_dataset\n",
      "  Processing lerobot/nyu_rot_dataset...\n",
      "Processing 69/103: pusht\n",
      "  Processing lerobot/pusht...\n",
      "Processing 70/103: pusht_image\n",
      "  Processing lerobot/pusht_image...\n",
      "  Taking a break...\n",
      "Processing 71/103: pusht_keypoints\n",
      "  Processing lerobot/pusht_keypoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/pusht_keypoints) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/pusht_keypoints\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 72/103: roboturk\n",
      "  Processing lerobot/roboturk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/roboturk) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/roboturk\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 73/103: stanford_hydra_dataset\n",
      "  Processing lerobot/stanford_hydra_dataset...\n",
      "Processing 74/103: stanford_kuka_multimodal_dataset\n",
      "  Processing lerobot/stanford_kuka_multimodal_dataset...\n",
      "Processing 75/103: stanford_robocook\n",
      "  Processing lerobot/stanford_robocook...\n",
      "  Taking a break...\n",
      "Processing 76/103: taco_play\n",
      "  Processing lerobot/taco_play...\n",
      "Processing 77/103: test\n",
      "  Processing lerobot/test...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/test) is in 1.5 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/test \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 78/103: tokyo_u_lsmo\n",
      "  Processing lerobot/tokyo_u_lsmo...\n",
      "Processing 79/103: toto\n",
      "  Processing lerobot/toto...\n",
      "Processing 80/103: ucsd_kitchen_dataset\n",
      "  Processing lerobot/ucsd_kitchen_dataset...\n",
      "  Taking a break...\n",
      "Processing 81/103: ucsd_pick_and_place_dataset\n",
      "  Processing lerobot/ucsd_pick_and_place_dataset...\n",
      "Processing 82/103: uiuc_d3field\n",
      "  Processing lerobot/uiuc_d3field...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/uiuc_d3field) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/uiuc_d3field \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 83/103: umi_cup_in_the_wild\n",
      "  Processing lerobot/umi_cup_in_the_wild...\n",
      "Processing 84/103: unitreeh1_fold_clothes\n",
      "  Processing lerobot/unitreeh1_fold_clothes...\n",
      "Processing 85/103: unitreeh1_rearrange_objects\n",
      "  Processing lerobot/unitreeh1_rearrange_objects...\n",
      "  Taking a break...\n",
      "Processing 86/103: unitreeh1_two_robot_greeting\n",
      "  Processing lerobot/unitreeh1_two_robot_greeting...\n",
      "Processing 87/103: unitreeh1_warehouse\n",
      "  Processing lerobot/unitreeh1_warehouse...\n",
      "Processing 88/103: usc_cloth_sim\n",
      "  Processing lerobot/usc_cloth_sim...\n",
      "Processing 89/103: utaustin_mutex\n",
      "  Processing lerobot/utaustin_mutex...\n",
      "Processing 90/103: utokyo_pr2_opening_fridge\n",
      "  Processing lerobot/utokyo_pr2_opening_fridge...\n",
      "  Taking a break...\n",
      "Processing 91/103: utokyo_pr2_tabletop_manipulation\n",
      "  Processing lerobot/utokyo_pr2_tabletop_manipulation...\n",
      "Processing 92/103: utokyo_saytap\n",
      "  Processing lerobot/utokyo_saytap...\n",
      "Processing 93/103: utokyo_xarm_bimanual\n",
      "  Processing lerobot/utokyo_xarm_bimanual...\n",
      "Processing 94/103: utokyo_xarm_pick_and_place\n",
      "  Processing lerobot/utokyo_xarm_pick_and_place...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/utokyo_xarm_pick_and_place) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/utokyo_xarm_pick_and_place\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 95/103: viola\n",
      "  Processing lerobot/viola...\n",
      "    Error: \n",
      "The dataset you requested (lerobot/viola) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/viola \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "  Taking a break...\n",
      "Processing 96/103: xarm_lift_medium\n",
      "  Processing lerobot/xarm_lift_medium...\n",
      "Processing 97/103: xarm_lift_medium_image\n",
      "  Processing lerobot/xarm_lift_medium_image...\n",
      "Processing 98/103: xarm_lift_medium_replay\n",
      "  Processing lerobot/xarm_lift_medium_replay...\n",
      "Processing 99/103: xarm_lift_medium_replay_image\n",
      "  Processing lerobot/xarm_lift_medium_replay_image...\n",
      "Processing 100/103: xarm_push_medium\n",
      "  Processing lerobot/xarm_push_medium...\n",
      "  Taking a break...\n",
      "Processing 101/103: xarm_push_medium_image\n",
      "  Processing lerobot/xarm_push_medium_image...\n",
      "Processing 102/103: xarm_push_medium_replay\n",
      "  Processing lerobot/xarm_push_medium_replay...\n",
      "Processing 103/103: xarm_push_medium_replay_image\n",
      "  Processing lerobot/xarm_push_medium_replay_image...\n",
      "\n",
      "Collected metadata for 103 datasets\n",
      "Processing: 103 out of 103 total\n",
      "FULL PROCESSING: Processing all 103 datasets\n"
     ]
    }
   ],
   "source": [
    "print(\"Collecting metadata from all datasets...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# IMPORTANT: Change this to process all datasets\n",
    "# For testing: available_datasets[:10]  \n",
    "# For full run: available_datasets\n",
    "datasets_to_process = available_datasets  # FULL PROCESSING MODE\n",
    "\n",
    "dataset_metrics = []\n",
    "for i, dataset_name in enumerate(datasets_to_process):\n",
    "    print(f\"Processing {i+1}/{len(datasets_to_process)}: {dataset_name.split('/')[-1]}\")\n",
    "    \n",
    "    metadata = get_dataset_metadata(dataset_name)\n",
    "    if metadata:\n",
    "        dataset_metrics.append(metadata)\n",
    "        \n",
    "    # Break every 5 datasets\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"  Taking a break...\")\n",
    "        time.sleep(3)\n",
    "\n",
    "# Create DataFrame\n",
    "df_metrics = pd.DataFrame(dataset_metrics)\n",
    "\n",
    "print(f\"\\nCollected metadata for {len(df_metrics)} datasets\")\n",
    "print(f\"Processing: {len(datasets_to_process)} out of {len(available_datasets)} total\")\n",
    "\n",
    "if len(datasets_to_process) < len(available_datasets):\n",
    "    print(f\"TESTING MODE: To process ALL datasets, change datasets_to_process = available_datasets\")\n",
    "else:\n",
    "    print(f\"FULL PROCESSING: Processing all {len(available_datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ad92e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Analysis Summary\n",
      "==================================================\n",
      "Dataset Overview:\n",
      "  Total Processed: 103\n",
      "  Successfully Loaded: 92\n",
      "  With Camera Data: 91\n",
      "  Total Episodes: 65,318\n",
      "  Total Samples: 7,823,344\n",
      "\n",
      "Category Summary:\n",
      "           total  with_cameras\n",
      "category                      \n",
      "aloha         29            25\n",
      "berkeley       8             8\n",
      "xarm           8             8\n",
      "utokyo         5             5\n",
      "koch           4             0\n",
      "unitreeh1      4             4\n",
      "libero         4             4\n",
      "austin         3             3\n",
      "stanford       3             3\n",
      "cmu            3             3\n",
      "\n",
      "Sample datasets with cameras:\n",
      "  aloha_mobile_cabinet: 85 episodes, 3 cameras\n",
      "  aloha_mobile_chair: 55 episodes, 3 cameras\n",
      "  aloha_mobile_elevator: 20 episodes, 3 cameras\n",
      "  aloha_mobile_shrimp: 18 episodes, 3 cameras\n",
      "  aloha_mobile_wash_pan: 50 episodes, 3 cameras\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Analysis Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic statistics\n",
    "successful_df = df_metrics[df_metrics['num_episodes'] != 'Error']\n",
    "total_datasets = len(df_metrics)\n",
    "successful_loads = len(successful_df)\n",
    "datasets_with_images = len(df_metrics[df_metrics['has_images'] == True])\n",
    "\n",
    "print(f\"Dataset Overview:\")\n",
    "print(f\"  Total Processed: {total_datasets}\")\n",
    "print(f\"  Successfully Loaded: {successful_loads}\")\n",
    "print(f\"  With Camera Data: {datasets_with_images}\")\n",
    "\n",
    "if len(successful_df) > 0:\n",
    "    total_episodes = successful_df['num_episodes'].sum()\n",
    "    total_samples = successful_df['total_samples'].sum()\n",
    "    print(f\"  Total Episodes: {total_episodes:,}\")\n",
    "    print(f\"  Total Samples: {total_samples:,}\")\n",
    "\n",
    "# Category breakdown\n",
    "print(f\"\\nCategory Summary:\")\n",
    "category_summary = df_metrics.groupby('category').agg({\n",
    "    'dataset_name': 'count',\n",
    "    'has_images': lambda x: sum(1 for val in x if val == True)\n",
    "}).rename(columns={'dataset_name': 'total', 'has_images': 'with_cameras'})\n",
    "\n",
    "category_summary = category_summary.sort_values('total', ascending=False)\n",
    "print(category_summary.head(10).to_string())\n",
    "\n",
    "# Show sample of datasets with cameras\n",
    "if datasets_with_images > 0:\n",
    "    print(f\"\\nSample datasets with cameras:\")\n",
    "    sample_with_cameras = df_metrics[df_metrics['has_images'] == True].head(5)\n",
    "    for _, row in sample_with_cameras.iterrows():\n",
    "        dataset_short = row['dataset_name'].replace('lerobot/', '')\n",
    "        cameras = len(row['camera_keys'])\n",
    "        episodes = row['num_episodes'] if row['num_episodes'] != 'Error' else 'Unknown'\n",
    "        print(f\"  {dataset_short}: {episodes} episodes, {cameras} cameras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40cbebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video download functions ready!\n"
     ]
    }
   ],
   "source": [
    "def download_episode_videos(datasets_df, videos_folder=\"videos\", max_datasets=None, max_workers=3):\n",
    "    \"\"\"Download episode videos from datasets with parallel processing\"\"\"\n",
    "    \n",
    "    print(f\"Starting video download process...\")\n",
    "    \n",
    "    # Filter to datasets with images only\n",
    "    datasets_with_images = datasets_df[\n",
    "        (datasets_df['has_images'] == True) & \n",
    "        (datasets_df['num_episodes'] != 'Error')\n",
    "    ].copy()\n",
    "    \n",
    "    if max_datasets:\n",
    "        datasets_with_images = datasets_with_images.head(max_datasets)\n",
    "    \n",
    "    print(f\"Target: {len(datasets_with_images)} datasets with cameras\")\n",
    "    \n",
    "    # Create videos directory\n",
    "    os.makedirs(videos_folder, exist_ok=True)\n",
    "    \n",
    "    downloaded_videos = []\n",
    "    failed_videos = []\n",
    "    \n",
    "    def download_single_video(args):\n",
    "        dataset_name, camera_key, dataset_folder = args\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        \n",
    "        try:\n",
    "            # Create dataset folder\n",
    "            os.makedirs(dataset_folder, exist_ok=True)\n",
    "            \n",
    "            # Try to download episode 0 video\n",
    "            video_url = f\"https://huggingface.co/datasets/{dataset_name}/resolve/main/videos/chunk-000/{camera_key}/episode_000000.mp4\"\n",
    "            video_path = os.path.join(dataset_folder, f\"{camera_key.replace('.', '_')}_episode_000000.mp4\")\n",
    "            \n",
    "            if os.path.exists(video_path):\n",
    "                file_size = os.path.getsize(video_path)\n",
    "                return {\n",
    "                    'status': 'exists',\n",
    "                    'dataset': dataset_short,\n",
    "                    'camera': camera_key,\n",
    "                    'path': video_path,\n",
    "                    'size': file_size\n",
    "                }\n",
    "            \n",
    "            # Download the video\n",
    "            response = requests.get(video_url, timeout=30, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                with open(video_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                \n",
    "                file_size = os.path.getsize(video_path)\n",
    "                return {\n",
    "                    'status': 'downloaded',\n",
    "                    'dataset': dataset_short,\n",
    "                    'camera': camera_key,\n",
    "                    'path': video_path,\n",
    "                    'size': file_size\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'status': 'failed',\n",
    "                    'dataset': dataset_short,\n",
    "                    'camera': camera_key,\n",
    "                    'error': f\"HTTP {response.status_code}\"\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'dataset': dataset_short,\n",
    "                'camera': camera_key,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    # Prepare download tasks\n",
    "    download_tasks = []\n",
    "    for _, row in datasets_with_images.iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        dataset_folder = os.path.join(videos_folder, dataset_short)\n",
    "        \n",
    "        # Download from all cameras\n",
    "        for camera_key in row['camera_keys']:\n",
    "            download_tasks.append((dataset_name, camera_key, dataset_folder))\n",
    "    \n",
    "    # Execute downloads in parallel\n",
    "    print(f\"Downloading {len(download_tasks)} videos using {max_workers} workers...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_task = {executor.submit(download_single_video, task): task for task in download_tasks}\n",
    "        \n",
    "        for i, future in enumerate(as_completed(future_to_task)):\n",
    "            result = future.result()\n",
    "            \n",
    "            if result['status'] in ['downloaded', 'exists']:\n",
    "                downloaded_videos.append(result)\n",
    "                status_text = \"Downloaded\" if result['status'] == 'downloaded' else \"Found\"\n",
    "                size_mb = result['size'] / (1024*1024)\n",
    "                print(f\"  {status_text}: {result['dataset']}/{result['camera']} ({size_mb:.1f}MB)\")\n",
    "            else:\n",
    "                failed_videos.append(result)\n",
    "                print(f\"  Failed: {result['dataset']}/{result['camera']}: {result['error']}\")\n",
    "            \n",
    "            # Progress update\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"    Progress: {i+1}/{len(download_tasks)} completed\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nDownload Summary:\")\n",
    "    print(f\"  Successfully downloaded: {len([v for v in downloaded_videos if v['status'] == 'downloaded'])}\")\n",
    "    print(f\"  Already existed: {len([v for v in downloaded_videos if v['status'] == 'exists'])}\")\n",
    "    print(f\"  Failed: {len(failed_videos)}\")\n",
    "    \n",
    "    total_size = sum(v.get('size', 0) for v in downloaded_videos)\n",
    "    print(f\"  Total size: {total_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    return downloaded_videos, failed_videos\n",
    "\n",
    "print(\"Video download functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ba8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute video downloads\n",
    "if 'df_metrics' in locals() and not df_metrics.empty:\n",
    "    print(\"Starting video download process...\")\n",
    "    \n",
    "    # For full run: remove max_datasets parameter\n",
    "    downloaded_videos, failed_videos = download_episode_videos(\n",
    "        df_metrics, \n",
    "        videos_folder=\"videos\", \n",
    "        max_datasets=None,  # FULL PROCESSING: Download from all datasets with cameras\n",
    "        max_workers=3\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nVideo download completed!\")\n",
    "    print(f\"Check the 'videos/' folder for downloaded content\")\n",
    "    \n",
    "else:\n",
    "    print(\"No dataset metrics available. Run the previous cells first.\")\n",
    "    downloaded_videos, failed_videos = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae294fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_html_with_videos(datasets_df, downloaded_videos, output_file=\"lerobot_datasets_videos.html\"):\n",
    "    \"\"\"Create an interactive HTML page with embedded videos\"\"\"\n",
    "    \n",
    "    print(f\"Creating HTML page: {output_file}\")\n",
    "    \n",
    "    # Create video lookup\n",
    "    video_lookup = {}\n",
    "    for video in downloaded_videos:\n",
    "        key = f\"{video['dataset']}_{video['camera']}\"\n",
    "        video_lookup[key] = video\n",
    "    \n",
    "    # Filter successful datasets\n",
    "    successful_df = datasets_df[datasets_df['num_episodes'] != 'Error'].copy()\n",
    "    if len(successful_df) > 0:\n",
    "        successful_df['num_episodes'] = pd.to_numeric(successful_df['num_episodes'])\n",
    "        successful_df = successful_df.sort_values('num_episodes', ascending=False)\n",
    "    \n",
    "    # HTML template\n",
    "    html_content = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>LeRobot Datasets - Explorer ({len(successful_df)} datasets)</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            background-color: #f8f9fa;\n",
    "            line-height: 1.6;\n",
    "        }}\n",
    "        .header {{\n",
    "            text-align: center;\n",
    "            margin-bottom: 40px;\n",
    "            padding: 30px;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .stats {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
    "            gap: 20px;\n",
    "            margin: 30px 0;\n",
    "        }}\n",
    "        .stat-card {{\n",
    "            background: white;\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "            text-align: center;\n",
    "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .stat-number {{\n",
    "            font-size: 2em;\n",
    "            font-weight: bold;\n",
    "            color: #667eea;\n",
    "        }}\n",
    "        .dataset-grid {{\n",
    "            display: grid;\n",
    "            gap: 25px;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));\n",
    "        }}\n",
    "        .dataset-card {{\n",
    "            background: white;\n",
    "            border-radius: 12px;\n",
    "            padding: 25px;\n",
    "            box-shadow: 0 3px 12px rgba(0,0,0,0.1);\n",
    "            transition: transform 0.2s;\n",
    "        }}\n",
    "        .dataset-card:hover {{\n",
    "            transform: translateY(-2px);\n",
    "            box-shadow: 0 5px 20px rgba(0,0,0,0.15);\n",
    "        }}\n",
    "        .dataset-name {{\n",
    "            font-size: 1.4em;\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 15px;\n",
    "            color: #2c3e50;\n",
    "        }}\n",
    "        .dataset-stats {{\n",
    "            margin: 15px 0;\n",
    "            color: #666;\n",
    "        }}\n",
    "        .category-tag {{\n",
    "            display: inline-block;\n",
    "            background: #e3f2fd;\n",
    "            color: #1976d2;\n",
    "            padding: 4px 12px;\n",
    "            border-radius: 20px;\n",
    "            font-size: 0.8em;\n",
    "            font-weight: bold;\n",
    "            margin-right: 10px;\n",
    "        }}\n",
    "        .video-section {{\n",
    "            margin-top: 20px;\n",
    "        }}\n",
    "        .video-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n",
    "            gap: 15px;\n",
    "            margin-top: 15px;\n",
    "        }}\n",
    "        .video-container {{\n",
    "            text-align: center;\n",
    "        }}\n",
    "        .camera-label {{\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 8px;\n",
    "            color: #495057;\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        video {{\n",
    "            width: 100%;\n",
    "            max-width: 300px;\n",
    "            height: auto;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .no-videos {{\n",
    "            background: #e9ecef;\n",
    "            color: #6c757d;\n",
    "            padding: 30px 20px;\n",
    "            border-radius: 8px;\n",
    "            text-align: center;\n",
    "            font-style: italic;\n",
    "        }}\n",
    "        .video-link {{\n",
    "            display: block;\n",
    "            margin-top: 5px;\n",
    "            font-size: 0.8em;\n",
    "            color: #667eea;\n",
    "            text-decoration: none;\n",
    "        }}\n",
    "        .video-link:hover {{\n",
    "            text-decoration: underline;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>LeRobot Datasets Explorer</h1>\n",
    "        <p>Interactive exploration of {len(successful_df)} robot learning datasets</p>\n",
    "        <p style=\"opacity: 0.9; font-size: 0.9em;\">Generated on {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "    \n",
    "    # Statistics section\n",
    "    if len(successful_df) > 0:\n",
    "        total_episodes = successful_df['num_episodes'].sum()\n",
    "        total_samples = successful_df['total_samples'].sum() if 'total_samples' in successful_df.columns else 0\n",
    "        datasets_with_videos = len(set(v['dataset'] for v in downloaded_videos))\n",
    "        \n",
    "        html_content += f\"\"\"    <div class=\"stats\">\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{len(successful_df)}</div>\n",
    "            <div>Datasets</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{int(total_episodes):,}</div>\n",
    "            <div>Episodes</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{int(total_samples):,}</div>\n",
    "            <div>Samples</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{datasets_with_videos}</div>\n",
    "            <div>With Videos</div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"dataset-grid\">\n",
    "\"\"\"\n",
    "    \n",
    "    # Generate dataset cards\n",
    "    for _, row in successful_df.iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        \n",
    "        episodes = int(row['num_episodes']) if row['num_episodes'] != 'Error' else 'Unknown'\n",
    "        samples = int(row['total_samples']) if row['total_samples'] != 'Error' else 'Unknown'\n",
    "        \n",
    "        # Find videos for this dataset\n",
    "        dataset_videos = [v for v in downloaded_videos if v['dataset'] == dataset_short]\n",
    "        \n",
    "        # Video section\n",
    "        video_section_html = \"\"\n",
    "        if dataset_videos:\n",
    "            video_section_html = '<div class=\"video-grid\">'\n",
    "            for video in dataset_videos:\n",
    "                camera_display = video['camera'].replace('observation.images.', '').replace('.', ' ')\n",
    "                relative_path = f\"videos/{video['dataset']}/{os.path.basename(video['path'])}\"\n",
    "                file_size = video.get('size', 0) / (1024*1024)\n",
    "                \n",
    "                video_section_html += f\"\"\"\n",
    "                <div class=\"video-container\">\n",
    "                    <div class=\"camera-label\">Camera: {camera_display}</div>\n",
    "                    <video class=\"video-player\" controls preload=\"metadata\">\n",
    "                        <source src=\"{relative_path}\" type=\"video/mp4\">\n",
    "                        Your browser does not support the video tag.\n",
    "                    </video>\n",
    "                    <a href=\"{relative_path}\" target=\"_blank\" class=\"video-link\">Download ({file_size:.1f} MB)</a>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            video_section_html += '</div>'\n",
    "        else:\n",
    "            video_section_html = '<div class=\"no-videos\">No local videos available for this dataset</div>'\n",
    "        \n",
    "        html_content += f\"\"\"        <div class=\"dataset-card\">\n",
    "            <div class=\"dataset-name\">{dataset_short}</div>\n",
    "            <div class=\"dataset-stats\">\n",
    "                <span class=\"category-tag\">{row['category']}</span>\n",
    "                <strong>{episodes:,}</strong> episodes  <strong>{samples:,}</strong> samples\n",
    "            </div>\n",
    "            <div class=\"video-section\">\n",
    "                {video_section_html}\n",
    "            </div>\n",
    "        </div>\n",
    "\"\"\"\n",
    "    \n",
    "    # Close HTML\n",
    "    html_content += \"\"\"    </div>\n",
    "    \n",
    "    <div style=\"text-align: center; margin-top: 40px; color: #7f8c8d;\">\n",
    "        <p>Generated from LeRobot Dataset Exploration Notebook</p>\n",
    "        <p><a href=\"https://github.com/huggingface/lerobot\" target=\"_blank\">LeRobot GitHub</a>  \n",
    "           <a href=\"https://lerobot.huggingface.co\" target=\"_blank\">Documentation</a></p>\n",
    "        <p><small>Videos stored locally for offline browsing</small></p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "    \n",
    "    # Write HTML file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    file_path = Path(output_file).resolve()\n",
    "    print(f\"HTML file created: {output_file}\")\n",
    "    print(f\"Open in browser: file://{file_path}\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "print(\"HTML generation function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75134c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the HTML page\n",
    "if 'df_metrics' in locals() and 'downloaded_videos' in locals():\n",
    "    print(\"Generating final HTML page...\")\n",
    "    \n",
    "    html_file = create_dataset_html_with_videos(\n",
    "        df_metrics, \n",
    "        downloaded_videos, \n",
    "        output_file=\"lerobot_datasets_videos.html\"\n",
    "    )\n",
    "    \n",
    "    # Try to open in browser\n",
    "    import webbrowser\n",
    "    try:\n",
    "        abs_path = Path(html_file).resolve()\n",
    "        webbrowser.open(f'file://{abs_path}')\n",
    "        print(f\"Opened in browser automatically\")\n",
    "    except Exception as e:\n",
    "        print(f\"Manual link: file://{Path(html_file).resolve()}\")\n",
    "    \n",
    "    # Final statistics\n",
    "    print(f\"\\nFinal Project Statistics:\")\n",
    "    print(f\"  Datasets processed: {len(df_metrics)}\")\n",
    "    print(f\"  Videos downloaded: {len(downloaded_videos)}\")\n",
    "    print(f\"  HTML file: {html_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Missing data. Please run all previous cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1bb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PROJECT COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"LeRobot Dataset Explorer successfully created!\")\n",
    "print(f\"Open lerobot_datasets_videos.html to explore {len(df_metrics) if 'df_metrics' in locals() else 'all'} datasets\")\n",
    "print(f\"Videos stored in the 'videos/' folder\")\n",
    "print(\"Happy robot learning!\")\n",
    "print(\"End of notebook execution.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobotlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
