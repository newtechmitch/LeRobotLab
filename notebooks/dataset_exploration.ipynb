{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84e13dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Checking current session state...\n",
      "âŒ available_datasets: Not found in session\n",
      "âŒ df_metrics: Not found in session\n",
      "âŒ datasets_to_process: Not found in session\n",
      "\n",
      "ðŸ“ Current directory: /Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks\n",
      "ðŸ“¹ Found 25 video folders in videos/\n",
      "ðŸŽ¬ Total video files: 31\n",
      "ðŸŒ HTML file exists: lerobot_datasets_videos.html (0.1 MB)\n"
     ]
    }
   ],
   "source": [
    "# Check Current Session State\n",
    "print(\"ðŸ” Checking current session state...\")\n",
    "\n",
    "# Check if key variables exist\n",
    "variables_to_check = ['available_datasets', 'df_metrics', 'datasets_to_process']\n",
    "\n",
    "for var_name in variables_to_check:\n",
    "    if var_name in locals() or var_name in globals():\n",
    "        var_value = locals().get(var_name) or globals().get(var_name)\n",
    "        if hasattr(var_value, '__len__'):\n",
    "            print(f\"âœ… {var_name}: {type(var_value).__name__} with {len(var_value)} items\")\n",
    "        else:\n",
    "            print(f\"âœ… {var_name}: {type(var_value).__name__} = {var_value}\")\n",
    "    else:\n",
    "        print(f\"âŒ {var_name}: Not found in session\")\n",
    "\n",
    "# Check directory contents\n",
    "import os\n",
    "print(f\"\\nðŸ“ Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check videos directory\n",
    "videos_dir = 'videos'\n",
    "if os.path.exists(videos_dir):\n",
    "    video_folders = [d for d in os.listdir(videos_dir) if os.path.isdir(os.path.join(videos_dir, d))]\n",
    "    print(f\"ðŸ“¹ Found {len(video_folders)} video folders in {videos_dir}/\")\n",
    "    \n",
    "    # Count total video files\n",
    "    total_videos = 0\n",
    "    for folder in video_folders:\n",
    "        folder_path = os.path.join(videos_dir, folder)\n",
    "        videos_in_folder = [f for f in os.listdir(folder_path) if f.endswith('.mp4')]\n",
    "        total_videos += len(videos_in_folder)\n",
    "    print(f\"ðŸŽ¬ Total video files: {total_videos}\")\n",
    "else:\n",
    "    print(f\"âŒ Videos directory '{videos_dir}' not found\")\n",
    "\n",
    "# Check HTML file\n",
    "html_file = 'lerobot_datasets_videos.html'\n",
    "if os.path.exists(html_file):\n",
    "    file_size = os.path.getsize(html_file) / (1024*1024)  # MB\n",
    "    print(f\"ðŸŒ HTML file exists: {html_file} ({file_size:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"âŒ HTML file '{html_file}' not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dcd5dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting video download and HTML generation process...\n",
      "âš ï¸ No metadata loaded. Please run the metadata loading cells first\n",
      "\n",
      "ðŸ“ Next: Check the generated HTML file and optionally run full processing\n"
     ]
    }
   ],
   "source": [
    "# Execute Video Downloads and Generate HTML - Test Run\n",
    "\n",
    "print(\"ðŸš€ Starting video download and HTML generation process...\")\n",
    "\n",
    "# Check if we have metadata loaded\n",
    "if 'df_metrics' in locals() and not df_metrics.empty:\n",
    "    print(f\"âœ… Found {len(df_metrics)} datasets with metadata\")\n",
    "    \n",
    "    # Start with a small test batch\n",
    "    print(f\"\\nðŸ§ª Testing with first 3 datasets that have images...\")\n",
    "    test_datasets = df_metrics[df_metrics['has_images'] == True].head(3)\n",
    "    \n",
    "    if len(test_datasets) > 0:\n",
    "        print(f\"  Testing with {len(test_datasets)} datasets:\")\n",
    "        for _, row in test_datasets.iterrows():\n",
    "            print(f\"    - {row['dataset_name']} ({len(row['camera_keys'])} cameras)\")\n",
    "        \n",
    "        # Download videos for test datasets\n",
    "        downloaded_videos, failed_videos = download_episode_videos(\n",
    "            test_datasets, \n",
    "            videos_folder=\"videos\", \n",
    "            max_datasets=3, \n",
    "            max_workers=2  # Conservative for testing\n",
    "        )\n",
    "        \n",
    "        # Generate HTML with test results\n",
    "        if downloaded_videos or len(test_datasets) > 0:\n",
    "            html_file = create_dataset_html_with_videos(\n",
    "                test_datasets, \n",
    "                downloaded_videos, \n",
    "                output_file=\"lerobot_datasets_test.html\"\n",
    "            )\n",
    "            print(f\"\\nðŸŽ† Test completed! HTML file: {html_file}\")\n",
    "            \n",
    "            # Try to open in browser\n",
    "            import webbrowser\n",
    "            from pathlib import Path\n",
    "            try:\n",
    "                abs_path = Path(html_file).resolve()\n",
    "                webbrowser.open(f'file://{abs_path}')\n",
    "                print(f\"ðŸŒ Opened in browser\")\n",
    "            except Exception as e:\n",
    "                print(f\"ðŸ”— Manual link: file://{Path(html_file).resolve()}\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ No videos were downloaded in the test\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ No datasets with images found in current metadata\")\n",
    "        \n",
    "else:\n",
    "    print(f\"âš ï¸ No metadata loaded. Please run the metadata loading cells first\")\n",
    "\n",
    "print(f\"\\nðŸ“ Next: Check the generated HTML file and optionally run full processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae409c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¨ HTML generation function ready!\n"
     ]
    }
   ],
   "source": [
    "# HTML Generation Function\n",
    "\n",
    "def create_dataset_html_with_videos(datasets_df, downloaded_videos, output_file=\"lerobot_datasets_videos.html\"):\n",
    "    \"\"\"Create an HTML page with embedded local videos\"\"\"\n",
    "    \n",
    "    print(f\"ðŸŽ¨ Creating HTML page: {output_file}\")\n",
    "    \n",
    "    # Create video lookup by dataset and camera\n",
    "    video_lookup = {}\n",
    "    for video in downloaded_videos:\n",
    "        key = f\"{video['dataset']}_{video['camera']}\"\n",
    "        video_lookup[key] = video\n",
    "    \n",
    "    # Filter successful datasets and sort\n",
    "    successful_df = datasets_df[datasets_df['num_episodes'] != 'Error'].copy()\n",
    "    if len(successful_df) > 0:\n",
    "        successful_df['num_episodes'] = pd.to_numeric(successful_df['num_episodes'])\n",
    "        successful_df = successful_df.sort_values('num_episodes', ascending=False)\n",
    "    \n",
    "    html_content = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>LeRobot Datasets - Local Videos ({len(successful_df)} datasets)</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            line-height: 1.6;\n",
    "            background-color: #f8f9fa;\n",
    "        }}\n",
    "        .header {{\n",
    "            text-align: center;\n",
    "            margin-bottom: 40px;\n",
    "            padding: 30px;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .stats {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
    "            gap: 20px;\n",
    "            margin: 30px 0;\n",
    "        }}\n",
    "        .stat-card {{\n",
    "            background: white;\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "            text-align: center;\n",
    "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .stat-number {{\n",
    "            font-size: 2em;\n",
    "            font-weight: bold;\n",
    "            color: #667eea;\n",
    "        }}\n",
    "        .dataset-grid {{\n",
    "            display: grid;\n",
    "            gap: 25px;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));\n",
    "        }}\n",
    "        .dataset-card {{\n",
    "            background: white;\n",
    "            border-radius: 12px;\n",
    "            padding: 25px;\n",
    "            box-shadow: 0 3px 12px rgba(0,0,0,0.1);\n",
    "            transition: transform 0.2s;\n",
    "        }}\n",
    "        .dataset-card:hover {{\n",
    "            transform: translateY(-2px);\n",
    "            box-shadow: 0 5px 20px rgba(0,0,0,0.15);\n",
    "        }}\n",
    "        .dataset-title {{\n",
    "            font-size: 1.4em;\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 15px;\n",
    "            color: #2c3e50;\n",
    "        }}\n",
    "        .dataset-meta {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(120px, 1fr));\n",
    "            gap: 10px;\n",
    "            margin: 15px 0;\n",
    "            font-size: 0.9em;\n",
    "            color: #666;\n",
    "        }}\n",
    "        .meta-item {{\n",
    "            background: #f8f9fa;\n",
    "            padding: 8px 12px;\n",
    "            border-radius: 6px;\n",
    "            text-align: center;\n",
    "        }}\n",
    "        .video-container {{\n",
    "            margin-top: 20px;\n",
    "        }}\n",
    "        .video-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
    "            gap: 15px;\n",
    "            margin-top: 15px;\n",
    "        }}\n",
    "        .video-item {{\n",
    "            text-align: center;\n",
    "        }}\n",
    "        .video-label {{\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 8px;\n",
    "            color: #495057;\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        video {{\n",
    "            width: 100%;\n",
    "            max-width: 300px;\n",
    "            height: auto;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .no-video {{\n",
    "            background: #e9ecef;\n",
    "            color: #6c757d;\n",
    "            padding: 40px 20px;\n",
    "            border-radius: 8px;\n",
    "            text-align: center;\n",
    "            font-style: italic;\n",
    "        }}\n",
    "        .category-badge {{\n",
    "            display: inline-block;\n",
    "            background: #e3f2fd;\n",
    "            color: #1976d2;\n",
    "            padding: 4px 12px;\n",
    "            border-radius: 20px;\n",
    "            font-size: 0.8em;\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 10px;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>ðŸ¤– LeRobot Datasets Collection</h1>\n",
    "        <p>Explore {len(successful_df)} robot learning datasets with episode videos</p>\n",
    "        <p style=\"opacity: 0.9; font-size: 0.9em;\">Generated on {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "    \n",
    "    # Add statistics\n",
    "    total_episodes = sum(pd.to_numeric(successful_df['num_episodes'], errors='coerce').fillna(0))\n",
    "    total_samples = sum(pd.to_numeric(successful_df['total_samples'], errors='coerce').fillna(0))\n",
    "    datasets_with_videos = len([d for d in successful_df['dataset_name'] if any(v['dataset'] == d.replace('lerobot/', '') for v in downloaded_videos)])\n",
    "    \n",
    "    html_content += f\"\"\"    <div class=\"stats\">\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{len(successful_df)}</div>\n",
    "            <div>Datasets</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{int(total_episodes):,}</div>\n",
    "            <div>Episodes</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{int(total_samples):,}</div>\n",
    "            <div>Samples</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{datasets_with_videos}</div>\n",
    "            <div>With Videos</div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"dataset-grid\">\n",
    "\"\"\"\n",
    "    \n",
    "    # Generate dataset cards\n",
    "    for _, row in successful_df.iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        \n",
    "        # Find videos for this dataset\n",
    "        dataset_videos = [v for v in downloaded_videos if v['dataset'] == dataset_short]\n",
    "        \n",
    "        episodes = int(row['num_episodes']) if row['num_episodes'] != 'Error' else 'Unknown'\n",
    "        samples = int(row['total_samples']) if row['total_samples'] != 'Error' else 'Unknown'\n",
    "        \n",
    "        html_content += f\"\"\"        <div class=\"dataset-card\">\n",
    "            <div class=\"category-badge\">{row['category']}</div>\n",
    "            <div class=\"dataset-title\">{dataset_short}</div>\n",
    "            \n",
    "            <div class=\"dataset-meta\">\n",
    "                <div class=\"meta-item\">\n",
    "                    <strong>{episodes:,}</strong><br>Episodes\n",
    "                </div>\n",
    "                <div class=\"meta-item\">\n",
    "                    <strong>{samples:,}</strong><br>Samples\n",
    "                </div>\n",
    "                <div class=\"meta-item\">\n",
    "                    <strong>{row['fps']}</strong><br>FPS\n",
    "                </div>\n",
    "                <div class=\"meta-item\">\n",
    "                    <strong>{row['robot_type']}</strong><br>Robot\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"video-container\">\"\"\"\n",
    "        \n",
    "        if dataset_videos:\n",
    "            html_content += f\"\"\"                <div class=\"video-grid\">\"\"\"\n",
    "            \n",
    "            for video in dataset_videos[:4]:  # Show up to 4 videos\n",
    "                if video['status'] in ['downloaded', 'already_exists']:\n",
    "                    video_path = video['local_path']\n",
    "                    camera_name = video['camera']\n",
    "                    html_content += f\"\"\"                    <div class=\"video-item\">\n",
    "                        <div class=\"video-label\">{camera_name}</div>\n",
    "                        <video controls preload=\"metadata\">\n",
    "                            <source src=\"{video_path}\" type=\"video/mp4\">\n",
    "                            Your browser does not support the video tag.\n",
    "                        </video>\n",
    "                    </div>\"\"\"\n",
    "            \n",
    "            html_content += f\"\"\"                </div>\"\"\"\n",
    "        else:\n",
    "            html_content += f\"\"\"                <div class=\"no-video\">\n",
    "                    ðŸ“¹ No videos available<br>\n",
    "                    <small>Videos may not exist or failed to download</small>\n",
    "                </div>\"\"\"\n",
    "        \n",
    "        html_content += f\"\"\"            </div>\n",
    "        </div>\n",
    "\"\"\"\n",
    "    \n",
    "    html_content += \"\"\"    </div>\n",
    "\n",
    "    <script>\n",
    "        // Simple filter functionality could be added here\n",
    "        console.log('LeRobot Dataset Explorer loaded');\n",
    "    </script>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "    \n",
    "    # Write HTML file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"âœ… HTML page created: {output_file}\")\n",
    "    print(f\"  ðŸ“„ {len(successful_df)} datasets included\")\n",
    "    print(f\"  ðŸŽ¥ {len(downloaded_videos)} videos embedded\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "print(\"ðŸŽ¨ HTML generation function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2141c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¬ Video Download and HTML Generation\n",
      "==================================================\n",
      "ðŸš€ Video download functions ready!\n"
     ]
    }
   ],
   "source": [
    "# Video Download and HTML Generation Functions\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from urllib.parse import quote\n",
    "import threading\n",
    "from pathlib import Path\n",
    "\n",
    "# Create videos directory\n",
    "videos_folder = Path(\"videos\")\n",
    "videos_folder.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"ðŸŽ¬ Video Download and HTML Generation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def download_single_video(dataset_name, camera_key, videos_folder=\"videos\"):\n",
    "    \"\"\"Download a single episode video for a specific camera\"\"\"\n",
    "    dataset_short = dataset_name.replace(\"lerobot/\", \"\")\n",
    "    camera_display = camera_key.split('.')[-1] if '.' in camera_key else camera_key\n",
    "    \n",
    "    # Create dataset folder\n",
    "    dataset_folder = Path(videos_folder) / dataset_short\n",
    "    dataset_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Local file path\n",
    "    local_filename = f\"{camera_display}_episode_000000.mp4\"\n",
    "    local_path = dataset_folder / local_filename\n",
    "    \n",
    "    # Skip if already exists\n",
    "    if local_path.exists():\n",
    "        return {\n",
    "            'dataset': dataset_short,\n",
    "            'camera': camera_display,\n",
    "            'local_path': str(local_path),\n",
    "            'status': 'already_exists',\n",
    "            'size': local_path.stat().st_size\n",
    "        }\n",
    "    \n",
    "    # Construct URL\n",
    "    video_url = f\"https://huggingface.co/datasets/{dataset_name}/resolve/main/videos/chunk-000/{camera_key}/episode_000000.mp4\"\n",
    "    \n",
    "    try:\n",
    "        # Download with streaming\n",
    "        response = requests.get(video_url, stream=True, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            with open(local_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            \n",
    "            file_size = local_path.stat().st_size\n",
    "            return {\n",
    "                'dataset': dataset_short,\n",
    "                'camera': camera_display,\n",
    "                'local_path': str(local_path),\n",
    "                'status': 'downloaded',\n",
    "                'size': file_size\n",
    "            }\n",
    "        elif response.status_code == 404:\n",
    "            return {\n",
    "                'dataset': dataset_short,\n",
    "                'camera': camera_display,\n",
    "                'local_path': None,\n",
    "                'status': 'not_found',\n",
    "                'error': '404 - Video not found'\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'dataset': dataset_short,\n",
    "                'camera': camera_display,\n",
    "                'local_path': None,\n",
    "                'status': 'error',\n",
    "                'error': f'HTTP {response.status_code}'\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'dataset': dataset_short,\n",
    "            'camera': camera_display,\n",
    "            'local_path': None,\n",
    "            'status': 'error',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def download_episode_videos(datasets_df, videos_folder=\"videos\", max_datasets=None, max_workers=3):\n",
    "    \"\"\"Download episode_000000.mp4 videos for datasets with parallel processing\"\"\"\n",
    "    \n",
    "    print(f\"ðŸ“¥ Starting video downloads...\")\n",
    "    print(f\"  Max workers: {max_workers}\")\n",
    "    print(f\"  Videos folder: {videos_folder}\")\n",
    "    \n",
    "    # Filter datasets that have images\n",
    "    datasets_with_images = datasets_df[datasets_df['has_images'] == True].copy()\n",
    "    \n",
    "    if max_datasets:\n",
    "        datasets_with_images = datasets_with_images.head(max_datasets)\n",
    "    \n",
    "    print(f\"  Datasets to process: {len(datasets_with_images)}\")\n",
    "    \n",
    "    # Prepare download tasks\n",
    "    download_tasks = []\n",
    "    for _, row in datasets_with_images.iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        camera_keys = row['camera_keys']\n",
    "        \n",
    "        if camera_keys:  # Make sure camera_keys is not empty\n",
    "            # Take first camera or up to 3 cameras\n",
    "            cameras_to_download = camera_keys[:3] if len(camera_keys) > 3 else camera_keys\n",
    "            \n",
    "            for camera_key in cameras_to_download:\n",
    "                download_tasks.append((dataset_name, camera_key))\n",
    "    \n",
    "    print(f\"  Total video download tasks: {len(download_tasks)}\")\n",
    "    \n",
    "    downloaded_videos = []\n",
    "    failed_videos = []\n",
    "    \n",
    "    # Thread-safe progress tracking\n",
    "    progress_lock = threading.Lock()\n",
    "    completed_count = [0]  # Use list for mutable reference\n",
    "    \n",
    "    def update_progress(result):\n",
    "        with progress_lock:\n",
    "            completed_count[0] += 1\n",
    "            if completed_count[0] % 5 == 0 or completed_count[0] == len(download_tasks):\n",
    "                print(f\"  Progress: {completed_count[0]}/{len(download_tasks)} tasks completed\")\n",
    "    \n",
    "    # Execute downloads with parallel processing\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all download tasks\n",
    "        future_to_task = {\n",
    "            executor.submit(download_single_video, dataset_name, camera_key, videos_folder): (dataset_name, camera_key)\n",
    "            for dataset_name, camera_key in download_tasks\n",
    "        }\n",
    "        \n",
    "        # Process completed downloads\n",
    "        for future in as_completed(future_to_task):\n",
    "            dataset_name, camera_key = future_to_task[future]\n",
    "            \n",
    "            try:\n",
    "                result = future.result()\n",
    "                update_progress(result)\n",
    "                \n",
    "                if result['status'] in ['downloaded', 'already_exists']:\n",
    "                    downloaded_videos.append(result)\n",
    "                else:\n",
    "                    failed_videos.append(result)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                update_progress(None)\n",
    "                failed_videos.append({\n",
    "                    'dataset': dataset_name.replace(\"lerobot/\", \"\"),\n",
    "                    'camera': camera_key,\n",
    "                    'status': 'error',\n",
    "                    'error': str(e)\n",
    "                })\n",
    "    \n",
    "    # Summary\n",
    "    total_downloaded = len([v for v in downloaded_videos if v['status'] == 'downloaded'])\n",
    "    total_existing = len([v for v in downloaded_videos if v['status'] == 'already_exists'])\n",
    "    total_failed = len(failed_videos)\n",
    "    \n",
    "    print(f\"\\nâœ… Download Summary:\")\n",
    "    print(f\"  ðŸ“¥ New downloads: {total_downloaded}\")\n",
    "    print(f\"  ðŸ’¾ Already existed: {total_existing}\")\n",
    "    print(f\"  âŒ Failed downloads: {total_failed}\")\n",
    "    print(f\"  ðŸ“Š Total successful: {len(downloaded_videos)}\")\n",
    "    \n",
    "    if failed_videos:\n",
    "        print(f\"\\nâš ï¸ Failed downloads by reason:\")\n",
    "        error_counts = {}\n",
    "        for failure in failed_videos:\n",
    "            reason = failure.get('error', 'Unknown')\n",
    "            error_counts[reason] = error_counts.get(reason, 0) + 1\n",
    "        \n",
    "        for reason, count in error_counts.items():\n",
    "            print(f\"  {reason}: {count}\")\n",
    "    \n",
    "    return downloaded_videos, failed_videos\n",
    "\n",
    "print(\"ðŸš€ Video download functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4940c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Executing metadata loading for pipeline testing...\n",
      "ðŸ”„ Re-fetching dataset list...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_lerobot_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailable_datasets\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available_datasets:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ”„ Re-fetching dataset list...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     available_datasets \u001b[38;5;241m=\u001b[39m \u001b[43mget_lerobot_datasets\u001b[49m()\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(available_datasets)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m datasets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load metadata for first 10 datasets\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_lerobot_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "# Execute Metadata Loading for Testing\n",
    "# Let's load metadata for just the first 10 datasets to test our pipeline\n",
    "\n",
    "print(\"ðŸš€ Executing metadata loading for pipeline testing...\")\n",
    "\n",
    "# Make sure we have the dataset list\n",
    "if 'available_datasets' not in locals() or not available_datasets:\n",
    "    print(\"ðŸ”„ Re-fetching dataset list...\")\n",
    "    available_datasets = get_lerobot_datasets()\n",
    "    print(f\"  Found {len(available_datasets)} datasets\")\n",
    "\n",
    "# Load metadata for first 10 datasets\n",
    "print(f\"\\nðŸ“‹ Loading metadata for first 10 datasets...\")\n",
    "datasets_to_process = available_datasets[:10]\n",
    "\n",
    "dataset_metrics = []\n",
    "for i, dataset_name in enumerate(datasets_to_process):\n",
    "    print(f\"  {i+1}/10: {dataset_name}\")\n",
    "    \n",
    "    metadata = get_dataset_metadata(dataset_name)\n",
    "    if metadata:\n",
    "        dataset_metrics.append(metadata)\n",
    "    \n",
    "    # Brief pause between requests\n",
    "    if i < len(datasets_to_process) - 1:  # Don't sleep after last item\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Create DataFrame\n",
    "df_metrics = pd.DataFrame(dataset_metrics)\n",
    "\n",
    "print(f\"\\nâœ… Metadata loading complete!\")\n",
    "print(f\"  Processed: {len(df_metrics)} datasets\")\n",
    "print(f\"  Successful: {sum(1 for val in df_metrics['num_episodes'] if val != 'Error')} datasets\")\n",
    "print(f\"  With images: {sum(1 for val in df_metrics['has_images'] if val == True)} datasets\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nðŸ“‹ Sample results:\")\n",
    "for i, row in df_metrics.head(5).iterrows():\n",
    "    episodes = row['num_episodes'] if row['num_episodes'] != 'Error' else 'Error'\n",
    "    has_img = 'ðŸ“¹' if row['has_images'] else 'âŒ'\n",
    "    print(f\"  {has_img} {row['dataset_name']}: {episodes} episodes\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Ready for video downloads!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick display of current metadata results\n",
    "if 'df_metrics' in locals() and not df_metrics.empty:\n",
    "    print(f\"\\nðŸ“Š Current Metadata Results:\")\n",
    "    print(f\"  Datasets processed: {len(df_metrics)}\")\n",
    "    print(f\"  Successful loads: {sum(1 for val in df_metrics['num_episodes'] if val != 'Error')}\")\n",
    "    \n",
    "    # Show a few examples\n",
    "    print(f\"\\nðŸ“‹ Sample Results:\")\n",
    "    for i, row in df_metrics.head().iterrows():\n",
    "        episodes = row['num_episodes'] if row['num_episodes'] != 'Error' else 'Error'\n",
    "        has_img = 'ðŸ“¹' if row['has_images'] else 'âŒ'\n",
    "        print(f\"  {has_img} {row['dataset_name']}: {episodes} episodes\")\n",
    "        \n",
    "    print(f\"\\nðŸŽ¯ Ready to continue with video download and HTML generation!\")\n",
    "else:\n",
    "    print(\"âŒ No metadata loaded yet. Please run previous cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977e8d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeRobot Dataset Explorer\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# LeRobot Dataset Exploration Notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Import lerobot components\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset\n",
    "\n",
    "# Import for dataset discovery\n",
    "from huggingface_hub import list_datasets\n",
    "\n",
    "print(\"LeRobot Dataset Explorer\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba64f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get list of datasets with author=\"lerobot\" on Hugging Face Hub\n",
      "Fetching dataset list from Hugging Face Hub...\n",
      "Found 103 datasets :\n",
      " 1. lerobot/aloha_mobile_cabinet\n",
      " 2. lerobot/libero_object_image\n",
      " 3. lerobot/pusht\n",
      " 4. lerobot/aloha_sim_insertion_human\n",
      " 5. lerobot/aloha_sim_insertion_scripted\n",
      " 6. lerobot/aloha_sim_transfer_cube_human\n",
      " 7. lerobot/aloha_sim_transfer_cube_scripted\n",
      " 8. lerobot/xarm_lift_medium\n",
      " 9. lerobot/xarm_lift_medium_replay\n",
      "10. lerobot/xarm_push_medium\n",
      "11. lerobot/xarm_push_medium_replay\n",
      "12. lerobot/umi_cup_in_the_wild\n",
      "13. lerobot/aloha_static_screw_driver\n",
      "14. lerobot/aloha_static_candy\n",
      "15. lerobot/aloha_static_tape\n",
      "16. lerobot/aloha_mobile_wipe_wine\n",
      "17. lerobot/aloha_static_thread_velcro\n",
      "18. lerobot/aloha_static_battery\n",
      "19. lerobot/aloha_static_coffee\n",
      "20. lerobot/aloha_static_towel\n",
      "21. lerobot/aloha_static_vinh_cup\n",
      "22. lerobot/aloha_static_vinh_cup_left\n",
      "23. lerobot/aloha_static_ziploc_slide\n",
      "24. lerobot/aloha_static_coffee_new\n",
      "25. lerobot/aloha_static_cups_open\n",
      "26. lerobot/aloha_static_fork_pick_up\n",
      "27. lerobot/aloha_static_pingpong_test\n",
      "28. lerobot/aloha_static_pro_pencil\n",
      "29. lerobot/aloha_mobile_shrimp\n",
      "30. lerobot/aloha_mobile_wash_pan\n",
      "31. lerobot/pusht_image\n",
      "32. lerobot/xarm_lift_medium_image\n",
      "33. lerobot/xarm_lift_medium_replay_image\n",
      "34. lerobot/xarm_push_medium_image\n",
      "35. lerobot/xarm_push_medium_replay_image\n",
      "36. lerobot/aloha_mobile_chair\n",
      "37. lerobot/aloha_mobile_elevator\n",
      "38. lerobot/aloha_sim_insertion_scripted_image\n",
      "39. lerobot/aloha_sim_transfer_cube_human_image\n",
      "40. lerobot/aloha_sim_transfer_cube_scripted_image\n",
      "41. lerobot/aloha_sim_insertion_human_image\n",
      "42. lerobot/unitreeh1_rearrange_objects\n",
      "43. lerobot/unitreeh1_two_robot_greeting\n",
      "44. lerobot/unitreeh1_warehouse\n",
      "45. lerobot/unitreeh1_fold_clothes\n",
      "46. lerobot/pusht_keypoints\n",
      "47. lerobot/test\n",
      "48. lerobot/nyu_rot_dataset\n",
      "49. lerobot/tokyo_u_lsmo\n",
      "50. lerobot/utokyo_pr2_opening_fridge\n",
      "51. lerobot/cmu_stretch\n",
      "52. lerobot/asu_table_top\n",
      "53. lerobot/utokyo_pr2_tabletop_manipulation\n",
      "54. lerobot/ucsd_kitchen_dataset\n",
      "55. lerobot/austin_buds_dataset\n",
      "56. lerobot/dlr_sara_grid_clamp\n",
      "57. lerobot/dlr_sara_pour\n",
      "58. lerobot/dlr_edan_shared_control\n",
      "59. lerobot/ucsd_pick_and_place_dataset\n",
      "60. lerobot/nyu_franka_play_dataset\n",
      "61. lerobot/utokyo_saytap\n",
      "62. lerobot/imperialcollege_sawyer_wrist_cam\n",
      "63. lerobot/utokyo_xarm_bimanual\n",
      "64. lerobot/cmu_franka_exploration_dataset\n",
      "65. lerobot/utokyo_xarm_pick_and_place\n",
      "66. lerobot/viola\n",
      "67. lerobot/columbia_cairlab_pusht_real\n",
      "68. lerobot/berkeley_cable_routing\n",
      "69. lerobot/uiuc_d3field\n",
      "70. lerobot/conq_hose_manipulation\n",
      "71. lerobot/berkeley_gnm_sac_son\n",
      "72. lerobot/cmu_play_fusion\n",
      "73. lerobot/berkeley_fanuc_manipulation\n",
      "74. lerobot/jaco_play\n",
      "75. lerobot/kaist_nonprehensile\n",
      "76. lerobot/koch_pick_place_1_lego_raph\n",
      "77. lerobot/berkeley_gnm_recon\n",
      "78. lerobot/nyu_door_opening_surprising_effectiveness\n",
      "79. lerobot/austin_sirius_dataset\n",
      "80. lerobot/austin_sailor_dataset\n",
      "81. lerobot/berkeley_autolab_ur5\n",
      "82. lerobot/utaustin_mutex\n",
      "83. lerobot/stanford_hydra_dataset\n",
      "84. lerobot/berkeley_mvp\n",
      "85. lerobot/koch_pick_place_1_lego\n",
      "86. lerobot/koch_pick_place_5_lego_random_pose\n",
      "87. lerobot/koch_pick_place_5_lego\n",
      "88. lerobot/stanford_robocook\n",
      "89. lerobot/toto\n",
      "90. lerobot/roboturk\n",
      "91. lerobot/fmb\n",
      "92. lerobot/droid_100\n",
      "93. lerobot/berkeley_rpt\n",
      "94. lerobot/stanford_kuka_multimodal_dataset\n",
      "95. lerobot/iamlab_cmu_pickup_insert\n",
      "96. lerobot/taco_play\n",
      "97. lerobot/berkeley_gnm_cory_hall\n",
      "98. lerobot/usc_cloth_sim\n",
      "99. lerobot/metaworld_mt50_push_v2_image\n",
      "100. lerobot/metaworld_mt50\n",
      "101. lerobot/libero_10_image\n",
      "102. lerobot/libero_spatial_image\n",
      "103. lerobot/libero_goal_image\n",
      "Found 103 datasets :\n",
      " 1. lerobot/aloha_mobile_cabinet\n",
      " 2. lerobot/libero_object_image\n",
      " 3. lerobot/pusht\n",
      " 4. lerobot/aloha_sim_insertion_human\n",
      " 5. lerobot/aloha_sim_insertion_scripted\n",
      " 6. lerobot/aloha_sim_transfer_cube_human\n",
      " 7. lerobot/aloha_sim_transfer_cube_scripted\n",
      " 8. lerobot/xarm_lift_medium\n",
      " 9. lerobot/xarm_lift_medium_replay\n",
      "10. lerobot/xarm_push_medium\n",
      "11. lerobot/xarm_push_medium_replay\n",
      "12. lerobot/umi_cup_in_the_wild\n",
      "13. lerobot/aloha_static_screw_driver\n",
      "14. lerobot/aloha_static_candy\n",
      "15. lerobot/aloha_static_tape\n",
      "16. lerobot/aloha_mobile_wipe_wine\n",
      "17. lerobot/aloha_static_thread_velcro\n",
      "18. lerobot/aloha_static_battery\n",
      "19. lerobot/aloha_static_coffee\n",
      "20. lerobot/aloha_static_towel\n",
      "21. lerobot/aloha_static_vinh_cup\n",
      "22. lerobot/aloha_static_vinh_cup_left\n",
      "23. lerobot/aloha_static_ziploc_slide\n",
      "24. lerobot/aloha_static_coffee_new\n",
      "25. lerobot/aloha_static_cups_open\n",
      "26. lerobot/aloha_static_fork_pick_up\n",
      "27. lerobot/aloha_static_pingpong_test\n",
      "28. lerobot/aloha_static_pro_pencil\n",
      "29. lerobot/aloha_mobile_shrimp\n",
      "30. lerobot/aloha_mobile_wash_pan\n",
      "31. lerobot/pusht_image\n",
      "32. lerobot/xarm_lift_medium_image\n",
      "33. lerobot/xarm_lift_medium_replay_image\n",
      "34. lerobot/xarm_push_medium_image\n",
      "35. lerobot/xarm_push_medium_replay_image\n",
      "36. lerobot/aloha_mobile_chair\n",
      "37. lerobot/aloha_mobile_elevator\n",
      "38. lerobot/aloha_sim_insertion_scripted_image\n",
      "39. lerobot/aloha_sim_transfer_cube_human_image\n",
      "40. lerobot/aloha_sim_transfer_cube_scripted_image\n",
      "41. lerobot/aloha_sim_insertion_human_image\n",
      "42. lerobot/unitreeh1_rearrange_objects\n",
      "43. lerobot/unitreeh1_two_robot_greeting\n",
      "44. lerobot/unitreeh1_warehouse\n",
      "45. lerobot/unitreeh1_fold_clothes\n",
      "46. lerobot/pusht_keypoints\n",
      "47. lerobot/test\n",
      "48. lerobot/nyu_rot_dataset\n",
      "49. lerobot/tokyo_u_lsmo\n",
      "50. lerobot/utokyo_pr2_opening_fridge\n",
      "51. lerobot/cmu_stretch\n",
      "52. lerobot/asu_table_top\n",
      "53. lerobot/utokyo_pr2_tabletop_manipulation\n",
      "54. lerobot/ucsd_kitchen_dataset\n",
      "55. lerobot/austin_buds_dataset\n",
      "56. lerobot/dlr_sara_grid_clamp\n",
      "57. lerobot/dlr_sara_pour\n",
      "58. lerobot/dlr_edan_shared_control\n",
      "59. lerobot/ucsd_pick_and_place_dataset\n",
      "60. lerobot/nyu_franka_play_dataset\n",
      "61. lerobot/utokyo_saytap\n",
      "62. lerobot/imperialcollege_sawyer_wrist_cam\n",
      "63. lerobot/utokyo_xarm_bimanual\n",
      "64. lerobot/cmu_franka_exploration_dataset\n",
      "65. lerobot/utokyo_xarm_pick_and_place\n",
      "66. lerobot/viola\n",
      "67. lerobot/columbia_cairlab_pusht_real\n",
      "68. lerobot/berkeley_cable_routing\n",
      "69. lerobot/uiuc_d3field\n",
      "70. lerobot/conq_hose_manipulation\n",
      "71. lerobot/berkeley_gnm_sac_son\n",
      "72. lerobot/cmu_play_fusion\n",
      "73. lerobot/berkeley_fanuc_manipulation\n",
      "74. lerobot/jaco_play\n",
      "75. lerobot/kaist_nonprehensile\n",
      "76. lerobot/koch_pick_place_1_lego_raph\n",
      "77. lerobot/berkeley_gnm_recon\n",
      "78. lerobot/nyu_door_opening_surprising_effectiveness\n",
      "79. lerobot/austin_sirius_dataset\n",
      "80. lerobot/austin_sailor_dataset\n",
      "81. lerobot/berkeley_autolab_ur5\n",
      "82. lerobot/utaustin_mutex\n",
      "83. lerobot/stanford_hydra_dataset\n",
      "84. lerobot/berkeley_mvp\n",
      "85. lerobot/koch_pick_place_1_lego\n",
      "86. lerobot/koch_pick_place_5_lego_random_pose\n",
      "87. lerobot/koch_pick_place_5_lego\n",
      "88. lerobot/stanford_robocook\n",
      "89. lerobot/toto\n",
      "90. lerobot/roboturk\n",
      "91. lerobot/fmb\n",
      "92. lerobot/droid_100\n",
      "93. lerobot/berkeley_rpt\n",
      "94. lerobot/stanford_kuka_multimodal_dataset\n",
      "95. lerobot/iamlab_cmu_pickup_insert\n",
      "96. lerobot/taco_play\n",
      "97. lerobot/berkeley_gnm_cory_hall\n",
      "98. lerobot/usc_cloth_sim\n",
      "99. lerobot/metaworld_mt50_push_v2_image\n",
      "100. lerobot/metaworld_mt50\n",
      "101. lerobot/libero_10_image\n",
      "102. lerobot/libero_spatial_image\n",
      "103. lerobot/libero_goal_image\n"
     ]
    }
   ],
   "source": [
    "# 1. Discover Available Datasets with Rate Limiting\n",
    "\n",
    "def get_lerobot_datasets():\n",
    "    \"\"\"Get list of datasets with author=\"lerobot\" on Hugging Face Hub\"\"\"\n",
    "    try:\n",
    "        print(\"Fetching dataset list from Hugging Face Hub...\")\n",
    "        datasets = list_datasets(author=\"lerobot\", use_auth_token=False)\n",
    "        return [dataset.id for dataset in datasets]\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to fetch datasets from Hugging Face Hub: {e}\")\n",
    "        \n",
    "print(\"Get list of datasets with author=\\\"lerobot\\\" on Hugging Face Hub\")\n",
    "available_datasets = get_lerobot_datasets()\n",
    "\n",
    "print(f\"Found {len(available_datasets)} datasets :\")\n",
    "for i, dataset_name in enumerate(available_datasets):\n",
    "    print(f\"{i+1:2d}. {dataset_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf3c8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Dataset Discovery Diagnostics:\n",
      "  ðŸ“Š Total datasets found: 103\n",
      "  ðŸŽ¯ Expected: ~103 datasets\n",
      "  âœ… Dataset count looks good!\n",
      "\n",
      "ðŸ“ Sample dataset names:\n",
      "  1. lerobot/aloha_mobile_cabinet\n",
      "  2. lerobot/libero_object_image\n",
      "  3. lerobot/pusht\n",
      "  4. lerobot/aloha_sim_insertion_human\n",
      "  5. lerobot/aloha_sim_insertion_scripted\n",
      "  ... and 98 more\n",
      "\n",
      "âœ… No duplicate dataset names found\n"
     ]
    }
   ],
   "source": [
    "# 1.5. Verify Dataset Count and Diagnose Issues\n",
    "\n",
    "print(f\"\\nðŸ” Dataset Discovery Diagnostics:\")\n",
    "print(f\"  ðŸ“Š Total datasets found: {len(available_datasets)}\")\n",
    "print(f\"  ðŸŽ¯ Expected: ~103 datasets\")\n",
    "\n",
    "if len(available_datasets) < 100:\n",
    "    print(f\"  âš ï¸ Found fewer datasets than expected!\")\n",
    "    print(f\"  ðŸ”§ This could be due to:\")\n",
    "    print(f\"     - Network connectivity issues\")\n",
    "    print(f\"     - HuggingFace Hub API rate limiting\")\n",
    "    print(f\"     - Authentication token needed for full access\")\n",
    "    print(f\"     - Recent changes to the HuggingFace Hub\")\n",
    "    \n",
    "    # Try alternative approach\n",
    "    print(f\"\\nðŸ”„ Trying alternative discovery method...\")\n",
    "    try:\n",
    "        from huggingface_hub import HfApi\n",
    "        api = HfApi()\n",
    "        datasets_alt = api.list_datasets(author=\"lerobot\", limit=200)\n",
    "        datasets_alt_ids = [d.id for d in datasets_alt]\n",
    "        print(f\"  ðŸ“Š Alternative method found: {len(datasets_alt_ids)} datasets\")\n",
    "        \n",
    "        if len(datasets_alt_ids) > len(available_datasets):\n",
    "            print(f\"  âœ… Using alternative method results\")\n",
    "            available_datasets = datasets_alt_ids\n",
    "            \n",
    "            print(f\"\\nðŸ“‹ Updated dataset list ({len(available_datasets)} total):\")\n",
    "            for i, dataset_name in enumerate(available_datasets[:10]):\n",
    "                print(f\"{i+1:2d}. {dataset_name}\")\n",
    "            if len(available_datasets) > 10:\n",
    "                print(f\"    ... and {len(available_datasets) - 10} more\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Alternative method failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"  âœ… Dataset count looks good!\")\n",
    "\n",
    "# Show some sample dataset names to verify they look correct\n",
    "print(f\"\\nðŸ“ Sample dataset names:\")\n",
    "for i, dataset in enumerate(available_datasets[:5]):\n",
    "    print(f\"  {i+1}. {dataset}\")\n",
    "if len(available_datasets) > 5:\n",
    "    print(f\"  ... and {len(available_datasets) - 5} more\")\n",
    "\n",
    "# Check for any obvious duplicates or issues\n",
    "unique_names = set(available_datasets)\n",
    "if len(unique_names) != len(available_datasets):\n",
    "    print(f\"\\nâš ï¸ Found {len(available_datasets) - len(unique_names)} duplicate dataset names!\")\n",
    "else:\n",
    "    print(f\"\\nâœ… No duplicate dataset names found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbbb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Family Analysis based on names\n",
      "  aloha: 29 dataset(s)\n",
      "  xarm: 8 dataset(s)\n",
      "  berkeley: 8 dataset(s)\n",
      "  utokyo: 5 dataset(s)\n",
      "  libero: 4 dataset(s)\n",
      "  unitreeh1: 4 dataset(s)\n",
      "  koch: 4 dataset(s)\n",
      "  pusht: 3 dataset(s)\n",
      "  nyu: 3 dataset(s)\n",
      "  cmu: 3 dataset(s)\n",
      "  austin: 3 dataset(s)\n",
      "  dlr: 3 dataset(s)\n",
      "  stanford: 3 dataset(s)\n",
      "  ucsd: 2 dataset(s)\n",
      "  metaworld: 2 dataset(s)\n",
      "  umi: 1 dataset(s)\n",
      "  test: 1 dataset(s)\n",
      "  tokyo: 1 dataset(s)\n",
      "  asu: 1 dataset(s)\n",
      "  imperialcollege: 1 dataset(s)\n",
      "  viola: 1 dataset(s)\n",
      "  columbia: 1 dataset(s)\n",
      "  uiuc: 1 dataset(s)\n",
      "  conq: 1 dataset(s)\n",
      "  jaco: 1 dataset(s)\n",
      "  kaist: 1 dataset(s)\n",
      "  utaustin: 1 dataset(s)\n",
      "  toto: 1 dataset(s)\n",
      "  roboturk: 1 dataset(s)\n",
      "  fmb: 1 dataset(s)\n",
      "  droid: 1 dataset(s)\n",
      "  iamlab: 1 dataset(s)\n",
      "  taco: 1 dataset(s)\n",
      "  usc: 1 dataset(s)\n"
     ]
    }
   ],
   "source": [
    "# 2. Extract Dataset Categories\n",
    "print(\"\\nDataset Family Analysis based on names\")\n",
    "\n",
    "# Analyze dataset names to find patterns\n",
    "families = {}\n",
    "for dataset in available_datasets:\n",
    "    # Extract potential categories from dataset names\n",
    "    dataset_short = dataset.replace(\"lerobot/\", \"\")\n",
    "    parts = dataset_short.split('_')\n",
    "    if len(parts) > 1:\n",
    "        family = parts[0]  # Use first part as category\n",
    "        if family in families:\n",
    "            families[family] += 1\n",
    "        else:\n",
    "            families[family] = 1\n",
    "    else:\n",
    "        family = dataset_short\n",
    "        families[family] = families.get(family, 0) + 1\n",
    "\n",
    "sorted_families = sorted(families.items(), key=lambda x: x[1], reverse=True)\n",
    "for family, count in sorted_families:\n",
    "    print(f\"  {family}: {count} dataset(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b422b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ Loading dataset metadata...\n",
      "This may take a few minutes as we query each dataset...\n",
      "Processing dataset 1/10: lerobot/aloha_mobile_cabinet\n",
      "  Fetching metadata for lerobot/aloha_mobile_cabinet...\n",
      "Processing dataset 2/10: lerobot/libero_object_image\n",
      "  Fetching metadata for lerobot/libero_object_image...\n",
      "Processing dataset 2/10: lerobot/libero_object_image\n",
      "  Fetching metadata for lerobot/libero_object_image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/libero_object_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/libero_object_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 3/10: lerobot/pusht\n",
      "  Fetching metadata for lerobot/pusht...\n",
      "Processing dataset 4/10: lerobot/aloha_sim_insertion_human\n",
      "  Fetching metadata for lerobot/aloha_sim_insertion_human...\n",
      "Processing dataset 4/10: lerobot/aloha_sim_insertion_human\n",
      "  Fetching metadata for lerobot/aloha_sim_insertion_human...\n",
      "Processing dataset 5/10: lerobot/aloha_sim_insertion_scripted\n",
      "  Fetching metadata for lerobot/aloha_sim_insertion_scripted...\n",
      "Processing dataset 5/10: lerobot/aloha_sim_insertion_scripted\n",
      "  Fetching metadata for lerobot/aloha_sim_insertion_scripted...\n",
      "  Processed 5 datasets - taking a longer break...\n",
      "  Processed 5 datasets - taking a longer break...\n",
      "Processing dataset 6/10: lerobot/aloha_sim_transfer_cube_human\n",
      "  Fetching metadata for lerobot/aloha_sim_transfer_cube_human...\n",
      "Processing dataset 6/10: lerobot/aloha_sim_transfer_cube_human\n",
      "  Fetching metadata for lerobot/aloha_sim_transfer_cube_human...\n",
      "Processing dataset 7/10: lerobot/aloha_sim_transfer_cube_scripted\n",
      "  Fetching metadata for lerobot/aloha_sim_transfer_cube_scripted...\n",
      "Processing dataset 7/10: lerobot/aloha_sim_transfer_cube_scripted\n",
      "  Fetching metadata for lerobot/aloha_sim_transfer_cube_scripted...\n",
      "Processing dataset 8/10: lerobot/xarm_lift_medium\n",
      "  Fetching metadata for lerobot/xarm_lift_medium...\n",
      "Processing dataset 8/10: lerobot/xarm_lift_medium\n",
      "  Fetching metadata for lerobot/xarm_lift_medium...\n",
      "Processing dataset 9/10: lerobot/xarm_lift_medium_replay\n",
      "  Fetching metadata for lerobot/xarm_lift_medium_replay...\n",
      "Processing dataset 9/10: lerobot/xarm_lift_medium_replay\n",
      "  Fetching metadata for lerobot/xarm_lift_medium_replay...\n",
      "Processing dataset 10/10: lerobot/xarm_push_medium\n",
      "  Fetching metadata for lerobot/xarm_push_medium...\n",
      "Processing dataset 10/10: lerobot/xarm_push_medium\n",
      "  Fetching metadata for lerobot/xarm_push_medium...\n",
      "  Processed 10 datasets - taking a longer break...\n",
      "  Processed 10 datasets - taking a longer break...\n",
      "\n",
      "âœ… Collected metadata for 10 datasets\n",
      "Note: Processing 10 datasets out of 103 total for testing\n",
      "Set datasets_to_process = available_datasets to process all datasets\n",
      "\n",
      "âœ… Collected metadata for 10 datasets\n",
      "Note: Processing 10 datasets out of 103 total for testing\n",
      "Set datasets_to_process = available_datasets to process all datasets\n"
     ]
    }
   ],
   "source": [
    "# 3. Load Dataset Metadata with Rate Limiting\n",
    "\n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDatasetMetadata\n",
    "\n",
    "def get_dataset_metadata(dataset_name):\n",
    "    \"\"\"Get metadata without loading the full dataset, with rate limiting\"\"\"\n",
    "    try:\n",
    "        print(f\"  Fetching metadata for {dataset_name}...\")\n",
    "        \n",
    "        # Add delay to respect rate limits\n",
    "        time.sleep(1.0)  # 1 second delay between requests\n",
    "        \n",
    "        # This only downloads lightweight metadata files\n",
    "        metadata = LeRobotDatasetMetadata(dataset_name)\n",
    "        \n",
    "        result = {\n",
    "            'dataset_name': dataset_name,\n",
    "            'category': dataset_name.replace(\"lerobot/\", \"\").split('_')[0],\n",
    "            'num_episodes': metadata.total_episodes,\n",
    "            'total_samples': metadata.total_frames,\n",
    "            'fps': metadata.fps,\n",
    "            'robot_type': metadata.robot_type,\n",
    "            'camera_keys': metadata.camera_keys,\n",
    "            'features': list(metadata.features.keys()),\n",
    "            'has_images': len(metadata.camera_keys) > 0  \n",
    "        }\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading metadata for {dataset_name}: {e}\")\n",
    "        if \"Too Many Requests\" in str(e) or \"429\" in str(e):\n",
    "            print(\"  Rate limit hit - waiting longer...\")\n",
    "            time.sleep(10)  # Wait 10 seconds on rate limit\n",
    "        \n",
    "        return {\n",
    "            'dataset_name': dataset_name,\n",
    "            'category': dataset_name.replace(\"lerobot/\", \"\").split('_')[0],\n",
    "            'num_episodes': 'Error',\n",
    "            'total_samples': 'Error',\n",
    "            'fps': 'Error',\n",
    "            'robot_type': 'Error',\n",
    "            'camera_keys': [],\n",
    "            'features': [],\n",
    "            'has_images': False\n",
    "        }\n",
    "    \n",
    "print(\"\\nðŸ“‹ Loading dataset metadata...\")\n",
    "print(\"This may take a few minutes as we query each dataset...\")\n",
    "\n",
    "# Collect metadata for first 10 datasets for testing\n",
    "dataset_metrics = []\n",
    "datasets_to_process = available_datasets[:10]  # Process first 10 for testing\n",
    "\n",
    "for i, dataset_name in enumerate(datasets_to_process):\n",
    "    print(f\"Processing dataset {i+1}/{len(datasets_to_process)}: {dataset_name}\")\n",
    "    \n",
    "    metadata = get_dataset_metadata(dataset_name)\n",
    "    if metadata:\n",
    "        dataset_metrics.append(metadata)\n",
    "        \n",
    "    # Extra delay every 5 datasets to be extra cautious\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"  Processed {i+1} datasets - taking a longer break...\")\n",
    "        time.sleep(3)\n",
    "\n",
    "# Create DataFrame for easy analysis\n",
    "df_metrics = pd.DataFrame(dataset_metrics)\n",
    "\n",
    "print(f\"\\nâœ… Collected metadata for {len(df_metrics)} datasets\")\n",
    "print(f\"Note: Processing {len(datasets_to_process)} datasets out of {len(available_datasets)} total for testing\")\n",
    "print(f\"Set datasets_to_process = available_datasets to process all datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Dataset Metrics Summary\n",
      "================================================================================\n",
      "Complete Dataset Overview (ordered by episodes):\n",
      "                                     dataset_name        category  num_episodes  total_samples   fps robot_type                                                                                                                            camera_keys                                                                                                                                                                                                                                             features  has_images\n",
      "                       lerobot/berkeley_gnm_recon        berkeley       11834.0       610907.0     3    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                   lerobot/berkeley_gnm_cory_hall        berkeley        7331.0       156012.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                                lerobot/taco_play            taco        3603.0       237798.0    15    unknown                                                                        [observation.images.rgb_static, observation.images.rgb_gripper]                                                                         [observation.images.rgb_static, observation.images.rgb_gripper, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "         lerobot/stanford_kuka_multimodal_dataset        stanford        3000.0       149985.0    20    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                     lerobot/berkeley_gnm_sac_son        berkeley        2955.0       241059.0    10    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                           lerobot/metaworld_mt50       metaworld        2500.0       204806.0    80  metaworld                                                                                                                    [observation.image]                                                                          [observation.state, action, next.reward, next.success, observation.environment_state, observation.image, task_id, timestamp, frame_index, episode_index, index, task_index]        True\n",
      "                        lerobot/stanford_robocook        stanford        2460.0       112980.0     5    unknown                       [observation.images.image_1, observation.images.image_2, observation.images.image_4, observation.images.image_3]                        [observation.images.image_1, observation.images.image_2, observation.images.image_4, observation.images.image_3, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                                 lerobot/roboturk        roboturk        1995.0       187507.0    10    unknown                                                                                                         [observation.images.front_rgb]                                                                                                          [observation.images.front_rgb, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                                      lerobot/fmb             fmb        1804.0       338188.0    10    unknown [observation.images.image_side_1, observation.images.image_side_2, observation.images.image_wrist_1, observation.images.image_wrist_2]  [observation.images.image_side_1, observation.images.image_side_2, observation.images.image_wrist_1, observation.images.image_wrist_2, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                   lerobot/berkeley_cable_routing        berkeley        1647.0        42328.0    10    unknown          [observation.images.top_image, observation.images.wrist225_image, observation.images.wrist45_image, observation.images.image]           [observation.images.top_image, observation.images.wrist225_image, observation.images.wrist45_image, observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                           lerobot/utaustin_mutex        utaustin        1500.0       361883.0    20    unknown                                                                             [observation.images.image, observation.images.wrist_image]                                                                              [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                      lerobot/umi_cup_in_the_wild             umi        1447.0       699432.0    10    unknown                                                                                                                    [observation.image]                                                                 [observation.image, observation.state, episode_index, frame_index, timestamp, episode_data_index_from, episode_data_index_to, end_pose, start_pos, gripper_width, index, task_index]        True\n",
      "              lerobot/ucsd_pick_and_place_dataset            ucsd        1355.0        67750.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                                lerobot/jaco_play            jaco        1085.0        77965.0    10    unknown                                                                             [observation.images.image, observation.images.image_wrist]                                                                              [observation.images.image, observation.images.image_wrist, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                                     lerobot/toto            toto        1003.0       325699.0    30    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                     lerobot/berkeley_autolab_ur5        berkeley        1000.0        97939.0     5    unknown                                         [observation.images.image_with_depth, observation.images.image, observation.images.hand_image]                                          [observation.images.image_with_depth, observation.images.image, observation.images.hand_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                            lerobot/usc_cloth_sim             usc        1000.0       100000.0    10    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                             lerobot/berkeley_rpt        berkeley         908.0       392578.0    30    unknown                                                                                                        [observation.images.hand_image]                                                                                                         [observation.images.hand_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                   lerobot/xarm_push_medium_image            xarm         800.0        20000.0    15    unknown                                                                                                                    [observation.image]                                                                                                                     [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, index, task_index]        True\n",
      "            lerobot/xarm_lift_medium_replay_image            xarm         800.0        20000.0    15    unknown                                                                                                                    [observation.image]                                                                                                                     [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, index, task_index]        True\n",
      "                         lerobot/xarm_push_medium            xarm         800.0        20000.0    15    unknown                                                                                                                    [observation.image]                                                                                                                     [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, index, task_index]        True\n",
      "                         lerobot/xarm_lift_medium            xarm         800.0        20000.0    15    unknown                                                                                                                    [observation.image]                                                                                                                     [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, index, task_index]        True\n",
      "                  lerobot/xarm_push_medium_replay            xarm         800.0        20000.0    15    unknown                                                                                                                    [observation.image]                                                                                                                     [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, index, task_index]        True\n",
      "            lerobot/xarm_push_medium_replay_image            xarm         800.0        20000.0    15    unknown                                                                                                                    [observation.image]                                                                                                                     [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, index, task_index]        True\n",
      "                   lerobot/xarm_lift_medium_image            xarm         800.0        20000.0    15    unknown                                                                                                                    [observation.image]                                                                                                                     [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, index, task_index]        True\n",
      "                  lerobot/xarm_lift_medium_replay            xarm         800.0        20000.0    15    unknown                                                                                                                    [observation.image]                                                                                                                     [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, index, task_index]        True\n",
      "                 lerobot/iamlab_cmu_pickup_insert          iamlab         631.0       146241.0    20    unknown                                                                             [observation.images.image, observation.images.wrist_image]                                                                              [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                          lerobot/cmu_play_fusion             cmu         576.0       235922.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                   lerobot/stanford_hydra_dataset        stanford         570.0       358234.0    10    unknown                                                                             [observation.images.image, observation.images.wrist_image]                                                                              [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                    lerobot/austin_sirius_dataset          austin         559.0       279939.0    20    unknown                                                                             [observation.images.image, observation.images.wrist_image]                                                                              [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "lerobot/nyu_door_opening_surprising_effectiveness             nyu         484.0        20405.0     3    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                             lerobot/berkeley_mvp        berkeley         480.0        45308.0     5    unknown                                                                                                        [observation.images.hand_image]                                                                                                         [observation.images.hand_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                  lerobot/nyu_franka_play_dataset             nyu         456.0        44875.0     5    unknown                                                                   [observation.images.image_additional_view, observation.images.image]                                                                    [observation.images.image_additional_view, observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                      lerobot/libero_object_image          libero         454.0        66984.0    10      panda                                                                             [observation.images.image, observation.images.wrist_image]                                                                                                      [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, frame_index, episode_index, index, task_index]        True\n",
      "                     lerobot/libero_spatial_image          libero         432.0        52970.0    10      panda                                                                             [observation.images.image, observation.images.wrist_image]                                                                                                      [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, frame_index, episode_index, index, task_index]        True\n",
      "                        lerobot/libero_goal_image          libero         428.0        52042.0    10      panda                                                                             [observation.images.image, observation.images.wrist_image]                                                                                                      [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, frame_index, episode_index, index, task_index]        True\n",
      "              lerobot/berkeley_fanuc_manipulation        berkeley         415.0        62613.0    10    unknown                                                                             [observation.images.image, observation.images.wrist_image]                                                                              [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                          lerobot/libero_10_image          libero         379.0       101469.0    10      panda                                                                             [observation.images.image, observation.images.wrist_image]                                                                                                      [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, frame_index, episode_index, index, task_index]        True\n",
      "         lerobot/utokyo_pr2_tabletop_manipulation          utokyo         240.0        32708.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                    lerobot/austin_sailor_dataset          austin         240.0       353094.0    20    unknown                                                                             [observation.images.wrist_image, observation.images.image]                                                                              [observation.images.wrist_image, observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                              lerobot/pusht_image           pusht         206.0        25650.0    10    unknown                                                                                                                    [observation.image]                                                                                                       [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, next.success, index, task_index]        True\n",
      "                          lerobot/pusht_keypoints           pusht         206.0        25650.0    10    unknown                                                                                                                                     []                                                                                           [observation.state, observation.environment_state, action, episode_index, frame_index, timestamp, next.reward, next.done, next.success, index, task_index]       False\n",
      "                                    lerobot/pusht           pusht         206.0        25650.0    10    unknown                                                                                                                    [observation.image]                                                                                                       [observation.image, observation.state, action, episode_index, frame_index, timestamp, next.reward, next.done, next.success, index, task_index]        True\n",
      "                      lerobot/kaist_nonprehensile           kaist         201.0        32429.0    10    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "           lerobot/cmu_franka_exploration_dataset             cmu         199.0         1990.0    10    unknown                                                                           [observation.images.image, observation.images.highres_image]                                                                            [observation.images.image, observation.images.highres_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "         lerobot/imperialcollege_sawyer_wrist_cam imperialcollege         170.0         7148.0     5    unknown                                                                             [observation.images.image, observation.images.wrist_image]                                                                              [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                     lerobot/ucsd_kitchen_dataset            ucsd         150.0         3970.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                   lerobot/conq_hose_manipulation            conq         139.0         8277.0    30    unknown         [observation.images.frontright_fisheye_image, observation.images.hand_color_image, observation.images.frontleft_fisheye_image]          [observation.images.frontright_fisheye_image, observation.images.hand_color_image, observation.images.frontleft_fisheye_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "              lerobot/columbia_cairlab_pusht_real        columbia         136.0        27808.0    10    unknown                                                                             [observation.images.wrist_image, observation.images.image]                                                                              [observation.images.wrist_image, observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                              lerobot/cmu_stretch             cmu         135.0        25016.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                            lerobot/asu_table_top             asu         110.0        26113.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                      lerobot/dlr_sara_grid_clamp             dlr         107.0         7622.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                  lerobot/dlr_edan_shared_control             dlr         104.0         8928.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "               lerobot/utokyo_xarm_pick_and_place          utokyo         102.0         7490.0    10    unknown                                                   [observation.images.hand_image, observation.images.image2, observation.images.image]                                                    [observation.images.hand_image, observation.images.image2, observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                    lerobot/aloha_static_vinh_cup           aloha         101.0        45500.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist] [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                            lerobot/dlr_sara_pour             dlr         100.0        12971.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "             lerobot/metaworld_mt50_push_v2_image       metaworld         100.0         6125.0    80  metaworld                                                                                                                    [observation.image]                                                                          [observation.state, action, next.reward, next.success, observation.environment_state, observation.image, task_id, timestamp, frame_index, episode_index, index, task_index]        True\n",
      "                                lerobot/droid_100           droid         100.0        32212.0    15    unknown              [observation.images.exterior_image_1_left, observation.images.exterior_image_2_left, observation.images.wrist_image_left]               [observation.images.exterior_image_1_left, observation.images.exterior_image_2_left, observation.images.wrist_image_left, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "               lerobot/aloha_static_vinh_cup_left           aloha         100.0        50000.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist] [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                     lerobot/aloha_mobile_cabinet           aloha          85.0       127500.0    50      aloha                                   [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist]                             [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                lerobot/utokyo_pr2_opening_fridge          utokyo          80.0        11522.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                     lerobot/utokyo_xarm_bimanual          utokyo          70.0         1514.0    10    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                lerobot/aloha_static_ziploc_slide           aloha          56.0        16800.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist]                     [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                       lerobot/aloha_mobile_chair           aloha          55.0       110000.0    50      aloha                                   [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist]                             [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                  lerobot/aloha_static_coffee_new           aloha          50.0        75000.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist] [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                lerobot/aloha_sim_insertion_human           aloha          50.0        25000.0    50      aloha                                                                                                               [observation.images.top]                                                                                                                             [observation.images.top, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "             lerobot/aloha_sim_insertion_scripted           aloha          50.0        20000.0    50      aloha                                                                                                               [observation.images.top]                                                                                                                             [observation.images.top, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "            lerobot/aloha_sim_transfer_cube_human           aloha          50.0        20000.0    50      aloha                                                                                                               [observation.images.top]                                                                                                                             [observation.images.top, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                      lerobot/austin_buds_dataset          austin          50.0        34112.0     5    unknown                                                                             [observation.images.image, observation.images.wrist_image]                                                                              [observation.images.image, observation.images.wrist_image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "         lerobot/aloha_sim_transfer_cube_scripted           aloha          50.0        20000.0    50      aloha                                                                                                               [observation.images.top]                                                                                                                             [observation.images.top, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                lerobot/aloha_static_screw_driver           aloha          50.0        20000.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist] [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                       lerobot/aloha_static_candy           aloha          50.0        35000.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist]                     [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                   lerobot/aloha_mobile_wipe_wine           aloha          50.0        65000.0    50      aloha                                   [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist]                             [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                      lerobot/aloha_static_coffee           aloha          50.0        55000.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist] [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                       lerobot/aloha_static_towel           aloha          50.0        25000.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist] [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                    lerobot/aloha_mobile_wash_pan           aloha          50.0        55000.0    50      aloha                                   [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist]                             [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                   lerobot/aloha_static_cups_open           aloha          50.0        20000.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist]                     [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                             lerobot/tokyo_u_lsmo           tokyo          50.0        11925.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "       lerobot/aloha_sim_insertion_scripted_image           aloha          50.0        20000.0    50      aloha                                                                                                               [observation.images.top]                                                                                                                             [observation.images.top, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "      lerobot/aloha_sim_transfer_cube_human_image           aloha          50.0        20000.0    50      aloha                                                                                                               [observation.images.top]                                                                                                                             [observation.images.top, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "   lerobot/aloha_sim_transfer_cube_scripted_image           aloha          50.0        20000.0    50      aloha                                                                                                               [observation.images.top]                                                                                                                             [observation.images.top, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "          lerobot/aloha_sim_insertion_human_image           aloha          50.0        25000.0    50      aloha                                                                                                               [observation.images.top]                                                                                                                             [observation.images.top, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                   lerobot/unitreeh1_fold_clothes       unitreeh1          38.0        19000.0    50    unknown                                                                            [observation.images.cam_left, observation.images.cam_right]                                                                                          [observation.images.cam_left, observation.images.cam_right, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "              lerobot/unitreeh1_rearrange_objects       unitreeh1          30.0         7150.0    50    unknown                                                                            [observation.images.cam_left, observation.images.cam_right]                                                                                          [observation.images.cam_left, observation.images.cam_right, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "             lerobot/unitreeh1_two_robot_greeting       unitreeh1          30.0         3750.0    50    unknown                                                                            [observation.images.cam_left, observation.images.cam_right]                                                                                          [observation.images.cam_left, observation.images.cam_right, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                  lerobot/aloha_static_pro_pencil           aloha          25.0         8750.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist] [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                      lerobot/unitreeh1_warehouse       unitreeh1          24.0        11275.0    50    unknown                                                                            [observation.images.cam_left, observation.images.cam_right]                                                                                          [observation.images.cam_left, observation.images.cam_right, observation.state, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                            lerobot/utokyo_saytap          utokyo          20.0        22937.0     5    unknown                                                                             [observation.images.wrist_image, observation.images.image]                                                                              [observation.images.wrist_image, observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "                    lerobot/aloha_mobile_elevator           aloha          20.0        45000.0    50      aloha                                   [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist]                             [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                      lerobot/aloha_mobile_shrimp           aloha          18.0        67500.0    50      aloha                                   [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist]                             [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                          lerobot/nyu_rot_dataset             nyu          14.0          440.0     5    unknown                                                                                                             [observation.images.image]                                                                                                              [observation.images.image, observation.state, action, timestamp, episode_index, frame_index, next.reward, next.done, index, task_index]        True\n",
      "               lerobot/aloha_static_pingpong_test           aloha          10.0         6000.0    50      aloha       [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist] [observation.images.cam_high, observation.images.cam_left_wrist, observation.images.cam_low, observation.images.cam_right_wrist, observation.state, observation.effort, action, episode_index, frame_index, timestamp, next.done, index, task_index]        True\n",
      "                        lerobot/aloha_static_tape           aloha           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "               lerobot/aloha_static_thread_velcro           aloha           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "                     lerobot/aloha_static_battery           aloha           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "                lerobot/aloha_static_fork_pick_up           aloha           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "                                     lerobot/test            test           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "                                    lerobot/viola           viola           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "                             lerobot/uiuc_d3field            uiuc           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "              lerobot/koch_pick_place_1_lego_raph            koch           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "                   lerobot/koch_pick_place_1_lego            koch           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "       lerobot/koch_pick_place_5_lego_random_pose            koch           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "                   lerobot/koch_pick_place_5_lego            koch           NaN            NaN Error      Error                                                                                                                                     []                                                                                                                                                                                                                                                   []       False\n",
      "\n",
      "ðŸ“ˆ Category Summary:\n",
      "                 num_datasets  total_episodes  total_samples  datasets_with_images\n",
      "category                                                                          \n",
      "aloha                      29          1270.0       997050.0                    25\n",
      "berkeley                    8         26570.0      1648744.0                     8\n",
      "xarm                        8          6400.0       160000.0                     8\n",
      "utokyo                      5           512.0        76171.0                     5\n",
      "koch                        4             0.0            0.0                     0\n",
      "unitreeh1                   4           122.0        41175.0                     4\n",
      "libero                      4          1693.0       273465.0                     4\n",
      "austin                      3           849.0       667145.0                     3\n",
      "stanford                    3          6030.0       621199.0                     3\n",
      "cmu                         3           910.0       262928.0                     3\n",
      "pusht                       3           618.0        76950.0                     2\n",
      "nyu                         3           954.0        65720.0                     3\n",
      "dlr                         3           311.0        29521.0                     3\n",
      "metaworld                   2          2600.0       210931.0                     2\n",
      "ucsd                        2          1505.0        71720.0                     2\n",
      "toto                        1          1003.0       325699.0                     1\n",
      "viola                       1             0.0            0.0                     0\n",
      "columbia                    1           136.0        27808.0                     1\n",
      "utaustin                    1          1500.0       361883.0                     1\n",
      "usc                         1          1000.0       100000.0                     1\n",
      "conq                        1           139.0         8277.0                     1\n",
      "umi                         1          1447.0       699432.0                     1\n",
      "uiuc                        1             0.0            0.0                     0\n",
      "imperialcollege             1           170.0         7148.0                     1\n",
      "tokyo                       1            50.0        11925.0                     1\n",
      "jaco                        1          1085.0        77965.0                     1\n",
      "taco                        1          3603.0       237798.0                     1\n",
      "roboturk                    1          1995.0       187507.0                     1\n",
      "droid                       1           100.0        32212.0                     1\n",
      "asu                         1           110.0        26113.0                     1\n",
      "fmb                         1          1804.0       338188.0                     1\n",
      "iamlab                      1           631.0       146241.0                     1\n",
      "kaist                       1           201.0        32429.0                     1\n",
      "test                        1             0.0            0.0                     0\n",
      "\n",
      "ðŸ”¢ Overall Statistics:\n",
      "  Total Datasets Processed: 103\n",
      "  Successfully Loaded: 92\n",
      "  Total Episodes: 65,318\n",
      "  Total Samples: 7,823,344\n",
      "  Datasets with Images: 91\n",
      "  Most Common Category: aloha (29.0 datasets)\n"
     ]
    }
   ],
   "source": [
    "# 4. Display Comprehensive Dataset Metrics Table\n",
    "\n",
    "print(\"\\nðŸ“ˆ Dataset Metrics Summary\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display the full table with formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "\n",
    "# Sort by number of episodes descending\n",
    "df_display = df_metrics.copy()\n",
    "# Convert numeric columns for proper sorting - only use columns that actually exist\n",
    "numeric_cols = ['num_episodes', 'total_samples']\n",
    "for col in numeric_cols:\n",
    "    if col in df_display.columns:  # Additional safety check\n",
    "        df_display[col] = pd.to_numeric(df_display[col], errors='coerce')\n",
    "\n",
    "df_display = df_display.sort_values('num_episodes', ascending=False, na_position='last')\n",
    "\n",
    "# Format the display\n",
    "print(f\"Dataset Overview (showing {len(df_display)} out of {len(available_datasets)} total datasets):\")\n",
    "print(df_display.to_string(index=False))\n",
    "\n",
    "# Category summary\n",
    "print(f\"\\nðŸ“ˆ Category Summary (partial data):\")\n",
    "category_summary = df_metrics.groupby('category').agg({\n",
    "    'dataset_name': 'count',\n",
    "    'num_episodes': lambda x: sum(pd.to_numeric(x, errors='coerce').fillna(0)),\n",
    "    'total_samples': lambda x: sum(pd.to_numeric(x, errors='coerce').fillna(0)),\n",
    "    'has_images': lambda x: sum(1 for val in x if val == True)\n",
    "}).rename(columns={\n",
    "    'dataset_name': 'num_datasets',\n",
    "    'num_episodes': 'total_episodes',\n",
    "    'total_samples': 'total_samples',\n",
    "    'has_images': 'datasets_with_images'\n",
    "})\n",
    "\n",
    "category_summary = category_summary.sort_values('num_datasets', ascending=False)\n",
    "print(category_summary.to_string())\n",
    "\n",
    "# Quick stats\n",
    "total_datasets = len(df_metrics)\n",
    "total_episodes = sum(pd.to_numeric(df_metrics['num_episodes'], errors='coerce').fillna(0))\n",
    "total_samples = sum(pd.to_numeric(df_metrics['total_samples'], errors='coerce').fillna(0))\n",
    "datasets_with_images = sum(1 for val in df_metrics['has_images'] if val == True)\n",
    "successful_loads = sum(1 for val in df_metrics['num_episodes'] if val != 'Error')\n",
    "\n",
    "print(f\"\\nðŸ”¢ Overall Statistics (for processed datasets):\")\n",
    "print(f\"  Datasets Processed: {total_datasets} out of {len(available_datasets)} total\")\n",
    "print(f\"  Successfully Loaded: {successful_loads}\")\n",
    "print(f\"  Total Episodes: {int(total_episodes):,}\")\n",
    "print(f\"  Total Samples: {int(total_samples):,}\")\n",
    "print(f\"  Datasets with Images: {datasets_with_images}\")\n",
    "if len(category_summary) > 0:\n",
    "    print(f\"  Most Common Category: {category_summary.index[0]} ({category_summary.iloc[0]['num_datasets']} datasets)\")\n",
    "\n",
    "print(f\"\\nâš ï¸ To process ALL {len(available_datasets)} datasets, change datasets_to_process = available_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde2b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Exploring dataset: lerobot/taco_play\n",
      "Loading dataset... This may take a moment for first-time downloads.\n",
      "Dataset loaded successfully!\n",
      "Number of episodes: 3603\n",
      "Total samples: 237798\n",
      "Frames per second: 15\n",
      "Dataset size: 237798 samples\n",
      "\n",
      "Sample data keys: ['observation.images.rgb_static', 'observation.images.rgb_gripper', 'observation.state', 'action', 'timestamp', 'episode_index', 'frame_index', 'next.reward', 'next.done', 'index', 'task_index', 'task']\n",
      "Image keys: ['observation.images.rgb_static', 'observation.images.rgb_gripper']\n",
      "  observation.images.rgb_static: torch.Size([3, 150, 200])\n",
      "  observation.images.rgb_gripper: torch.Size([3, 84, 84])\n",
      "Dataset loaded successfully!\n",
      "Number of episodes: 3603\n",
      "Total samples: 237798\n",
      "Frames per second: 15\n",
      "Dataset size: 237798 samples\n",
      "\n",
      "Sample data keys: ['observation.images.rgb_static', 'observation.images.rgb_gripper', 'observation.state', 'action', 'timestamp', 'episode_index', 'frame_index', 'next.reward', 'next.done', 'index', 'task_index', 'task']\n",
      "Image keys: ['observation.images.rgb_static', 'observation.images.rgb_gripper']\n",
      "  observation.images.rgb_static: torch.Size([3, 150, 200])\n",
      "  observation.images.rgb_gripper: torch.Size([3, 84, 84])\n"
     ]
    }
   ],
   "source": [
    "# 5. Load and Explore a Specific Dataset with Better Error Handling\n",
    "# Let's pick a dataset that loaded successfully\n",
    "successful_datasets = df_metrics[df_metrics['num_episodes'] != 'Error']['dataset_name'].tolist()\n",
    "\n",
    "if successful_datasets:\n",
    "    dataset_name = \"lerobot/taco_play\" #successful_datasets[0]  # Pick first successful dataset\n",
    "    print(f\"\\nðŸ” Exploring dataset: {dataset_name}\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Loading dataset... This may take a moment for first-time downloads.\")\n",
    "        # Load the dataset with timeout protection\n",
    "        dataset = LeRobotDataset(dataset_name)\n",
    "        \n",
    "        print(f\"Dataset loaded successfully!\")\n",
    "        print(f\"Number of episodes: {dataset.num_episodes}\")\n",
    "        print(f\"Total samples: {len(dataset)}\")\n",
    "        print(f\"Frames per second: {dataset.fps}\")\n",
    "        print(f\"Dataset size: {len(dataset)} samples\")\n",
    "        \n",
    "        # Show sample data structure\n",
    "        if len(dataset) > 0:\n",
    "            sample = dataset[0]\n",
    "            print(f\"\\nSample data keys: {list(sample.keys())}\")\n",
    "            \n",
    "            # Show image info if available\n",
    "            image_keys = [k for k in sample.keys() if 'image' in k.lower()]\n",
    "            if image_keys:\n",
    "                print(f\"Image keys: {image_keys}\")\n",
    "                for img_key in image_keys[:2]:  # Show first 2 image keys\n",
    "                    img_shape = sample[img_key].shape if hasattr(sample[img_key], 'shape') else 'Unknown'\n",
    "                    print(f\"  {img_key}: {img_shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        if \"Too Many Requests\" in str(e):\n",
    "            print(\"Rate limit hit. Try again later or use cached data.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No datasets loaded successfully. You may need to download them first.\")\n",
    "    print(\"Try using one of the working datasets like 'lerobot/pusht'\")\n",
    "    print(\"Or wait a moment and run the metadata collection again to avoid rate limits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca5379",
   "metadata": {},
   "source": [
    "## Rate Limiting Information\n",
    "\n",
    "This notebook now includes:\n",
    "\n",
    "1. **Rate Limiting**: Adds 1-second delays between API requests, 10 seconds on rate limit errors\n",
    "2. **Error Handling**: Better handling of \"Too Many Requests\" (429) errors\n",
    "3. **Reduced Load**: Processes only 20 datasets by default to minimize API usage\n",
    "4. **Extra Breaks**: Additional 3-second pauses every 5 datasets\n",
    "\n",
    "### Tips to Avoid Rate Limits:\n",
    "- Process datasets in smaller batches\n",
    "- Wait between runs if you hit rate limits\n",
    "- Consider using authentication token for higher limits\n",
    "- Use the fallback dataset list when the API is unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f45c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”— LeRobot Dataset Visualization Links\n",
      "============================================================\n",
      "Click these links to see the datasets in action on the LeRobot website:\n",
      "\n",
      "ðŸ“Š lerobot/berkeley_gnm_recon\n",
      "   Category: berkeley | Episodes: 11,834 | Samples: 610,907\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/berkeley_gnm_recon\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/berkeley_gnm_recon/viewer\n",
      "\n",
      "ðŸ“Š lerobot/berkeley_gnm_cory_hall\n",
      "   Category: berkeley | Episodes: 7,331 | Samples: 156,012\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/berkeley_gnm_cory_hall\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/berkeley_gnm_cory_hall/viewer\n",
      "\n",
      "ðŸ“Š lerobot/taco_play\n",
      "   Category: taco | Episodes: 3,603 | Samples: 237,798\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/taco_play\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/taco_play/viewer\n",
      "\n",
      "ðŸ“Š lerobot/stanford_kuka_multimodal_dataset\n",
      "   Category: stanford | Episodes: 3,000 | Samples: 149,985\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/stanford_kuka_multimodal_dataset\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/stanford_kuka_multimodal_dataset/viewer\n",
      "\n",
      "ðŸ“Š lerobot/berkeley_gnm_sac_son\n",
      "   Category: berkeley | Episodes: 2,955 | Samples: 241,059\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/berkeley_gnm_sac_son\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/berkeley_gnm_sac_son/viewer\n",
      "\n",
      "ðŸ“Š lerobot/metaworld_mt50\n",
      "   Category: metaworld | Episodes: 2,500 | Samples: 204,806\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/metaworld_mt50\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/metaworld_mt50/viewer\n",
      "\n",
      "ðŸ“Š lerobot/stanford_robocook\n",
      "   Category: stanford | Episodes: 2,460 | Samples: 112,980\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/stanford_robocook\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/stanford_robocook/viewer\n",
      "\n",
      "ðŸ“Š lerobot/roboturk\n",
      "   Category: roboturk | Episodes: 1,995 | Samples: 187,507\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/roboturk\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/roboturk/viewer\n",
      "\n",
      "ðŸ“Š lerobot/fmb\n",
      "   Category: fmb | Episodes: 1,804 | Samples: 338,188\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/fmb\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/fmb/viewer\n",
      "\n",
      "ðŸ“Š lerobot/berkeley_cable_routing\n",
      "   Category: berkeley | Episodes: 1,647 | Samples: 42,328\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/berkeley_cable_routing\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/berkeley_cable_routing/viewer\n",
      "\n",
      "ðŸ“Š lerobot/utaustin_mutex\n",
      "   Category: utaustin | Episodes: 1,500 | Samples: 361,883\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/utaustin_mutex\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/utaustin_mutex/viewer\n",
      "\n",
      "ðŸ“Š lerobot/umi_cup_in_the_wild\n",
      "   Category: umi | Episodes: 1,447 | Samples: 699,432\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/umi_cup_in_the_wild\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/umi_cup_in_the_wild/viewer\n",
      "\n",
      "ðŸ“Š lerobot/ucsd_pick_and_place_dataset\n",
      "   Category: ucsd | Episodes: 1,355 | Samples: 67,750\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/ucsd_pick_and_place_dataset\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/ucsd_pick_and_place_dataset/viewer\n",
      "\n",
      "ðŸ“Š lerobot/jaco_play\n",
      "   Category: jaco | Episodes: 1,085 | Samples: 77,965\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/jaco_play\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/jaco_play/viewer\n",
      "\n",
      "ðŸ“Š lerobot/toto\n",
      "   Category: toto | Episodes: 1,003 | Samples: 325,699\n",
      "   ðŸ“„ Dataset page: https://huggingface.co/datasets/lerobot/toto\n",
      "   ðŸ‘ï¸  Dataset viewer: https://huggingface.co/datasets/lerobot/toto/viewer\n",
      "\n",
      "ðŸŒ Additional LeRobot Resources:\n",
      "   ðŸ  LeRobot Homepage: https://github.com/huggingface/lerobot\n",
      "   ðŸ“š Documentation: https://lerobot.huggingface.co\n",
      "   ðŸŽ¥ Visualizations: https://lerobot.huggingface.co/visualize\n"
     ]
    }
   ],
   "source": [
    "# 6. Generate Links to LeRobot Dataset Visualization\n",
    "\n",
    "def create_lerobot_visualization_links(datasets_df, top_n=10):\n",
    "    \"\"\"Create clickable links to LeRobot dataset visualization page\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”— LeRobot Dataset Visualization Links\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Click these links to see the datasets in action on the LeRobot website:\\n\")\n",
    "    \n",
    "    # Get top datasets by episodes (successful loads only)\n",
    "    successful_df = datasets_df[datasets_df['num_episodes'] != 'Error'].copy()\n",
    "    successful_df['num_episodes'] = pd.to_numeric(successful_df['num_episodes'])\n",
    "    top_datasets = successful_df.sort_values('num_episodes', ascending=False).head(top_n)\n",
    "    \n",
    "    base_url = \"https://huggingface.co/datasets/\"\n",
    "    \n",
    "    for idx, row in top_datasets.iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        episodes = row['num_episodes']\n",
    "        samples = row['total_samples']\n",
    "        category = row['category']\n",
    "        \n",
    "        # Create both HuggingFace dataset page and viewer links\n",
    "        hf_url = f\"{base_url}{dataset_name}\"\n",
    "        viewer_url = f\"{base_url}{dataset_name}/viewer\"\n",
    "        \n",
    "        print(f\"ðŸ“Š {dataset_name}\")\n",
    "        print(f\"   Category: {category} | Episodes: {episodes:,.0f} | Samples: {samples:,.0f}\")\n",
    "        print(f\"   ðŸ“„ Dataset page: {hf_url}\")\n",
    "        print(f\"   ðŸ‘ï¸  Dataset viewer: {viewer_url}\")\n",
    "        print()\n",
    "    \n",
    "    # Additional useful links\n",
    "    print(\"ðŸŒ Additional LeRobot Resources:\")\n",
    "    print(\"   ðŸ  LeRobot Homepage: https://github.com/huggingface/lerobot\")\n",
    "    print(\"   ðŸ“š Documentation: https://lerobot.huggingface.co\")\n",
    "    print(\"   ðŸŽ¥ Visualizations: https://lerobot.huggingface.co/visualize\")\n",
    "\n",
    "# Generate visualization links for top datasets\n",
    "create_lerobot_visualization_links(df_metrics, top_n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f23106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¬ Creating HTML page with local video links...\n",
      "âœ… HTML page created: /Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/lerobot_datasets_videos.html\n",
      "ðŸ“‚ File size: 61.2 KB\n",
      "ðŸŽ¬ 26 local videos embedded\n",
      "\n",
      "ðŸŒ Open the HTML file in your browser to view the local dataset videos:\n",
      "file:///Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/lerobot_datasets_videos.html\n",
      "\n",
      "ðŸ“ Video files are stored in: /Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/videos\n"
     ]
    }
   ],
   "source": [
    "# 8. Generate HTML Page with Local Episode Video Links\n",
    "\n",
    "def create_dataset_video_html_local(datasets_df, downloaded_videos, output_file=\"lerobot_datasets_videos.html\", videos_folder=\"videos\"):\n",
    "    \"\"\"Create an HTML page listing all datasets with links to their local episode_000000.mp4 videos\"\"\"\n",
    "    \n",
    "    print(f\"ðŸŽ¬ Creating HTML page with local video links...\")\n",
    "    \n",
    "    # Create a lookup for downloaded videos\n",
    "    video_lookup = {}\n",
    "    for video in downloaded_videos:\n",
    "        key = f\"{video['dataset']}_{video['camera']}\"\n",
    "        video_lookup[key] = video['local_path']\n",
    "    \n",
    "    # Filter successful datasets and sort by episodes\n",
    "    successful_df = datasets_df[datasets_df['num_episodes'] != 'Error'].copy()\n",
    "    successful_df['num_episodes'] = pd.to_numeric(successful_df['num_episodes'])\n",
    "    successful_df = successful_df.sort_values('num_episodes', ascending=False)\n",
    "    \n",
    "    html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>LeRobot Datasets - Episode Videos (Local)</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "            max-width: 1200px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            line-height: 1.6;\n",
    "            background-color: #f8f9fa;\n",
    "        }}\n",
    "        .header {{\n",
    "            text-align: center;\n",
    "            margin-bottom: 40px;\n",
    "            padding: 30px;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .dataset-grid {{\n",
    "            display: grid;\n",
    "            gap: 20px;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(450px, 1fr));\n",
    "        }}\n",
    "        .dataset-card {{\n",
    "            background: white;\n",
    "            border-radius: 10px;\n",
    "            padding: 20px;\n",
    "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
    "            transition: transform 0.2s, box-shadow 0.2s;\n",
    "        }}\n",
    "        .dataset-card:hover {{\n",
    "            transform: translateY(-5px);\n",
    "            box-shadow: 0 4px 20px rgba(0,0,0,0.15);\n",
    "        }}\n",
    "        .dataset-name {{\n",
    "            font-size: 1.2em;\n",
    "            font-weight: bold;\n",
    "            color: #2c3e50;\n",
    "            margin-bottom: 10px;\n",
    "        }}\n",
    "        .dataset-stats {{\n",
    "            color: #7f8c8d;\n",
    "            font-size: 0.9em;\n",
    "            margin-bottom: 15px;\n",
    "        }}\n",
    "        .video-section {{\n",
    "            margin-top: 15px;\n",
    "        }}\n",
    "        .video-container {{\n",
    "            margin-bottom: 15px;\n",
    "            padding: 10px;\n",
    "            background: #f8f9fa;\n",
    "            border-radius: 5px;\n",
    "        }}\n",
    "        .camera-label {{\n",
    "            font-weight: bold;\n",
    "            color: #2c3e50;\n",
    "            margin-bottom: 8px;\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        .video-player {{\n",
    "            width: 100%;\n",
    "            max-width: 400px;\n",
    "            border-radius: 5px;\n",
    "        }}\n",
    "        .video-link {{\n",
    "            display: inline-block;\n",
    "            padding: 6px 12px;\n",
    "            background: #3498db;\n",
    "            color: white;\n",
    "            text-decoration: none;\n",
    "            border-radius: 3px;\n",
    "            font-size: 0.8em;\n",
    "            margin-left: 10px;\n",
    "            transition: background-color 0.2s;\n",
    "        }}\n",
    "        .video-link:hover {{\n",
    "            background: #2980b9;\n",
    "            text-decoration: none;\n",
    "            color: white;\n",
    "        }}\n",
    "        .no-videos {{\n",
    "            color: #e74c3c;\n",
    "            font-style: italic;\n",
    "            padding: 10px;\n",
    "            background: #fadbd8;\n",
    "            border-radius: 5px;\n",
    "        }}\n",
    "        .category-tag {{\n",
    "            display: inline-block;\n",
    "            background: #ecf0f1;\n",
    "            color: #2c3e50;\n",
    "            padding: 4px 8px;\n",
    "            border-radius: 3px;\n",
    "            font-size: 0.8em;\n",
    "            margin-right: 10px;\n",
    "        }}\n",
    "        .stats-summary {{\n",
    "            background: white;\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "            margin-bottom: 30px;\n",
    "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .download-info {{\n",
    "            background: #e8f5e8;\n",
    "            padding: 15px;\n",
    "            border-radius: 8px;\n",
    "            margin-bottom: 20px;\n",
    "            border-left: 4px solid #27ae60;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>ðŸ¤– LeRobot Datasets</h1>\n",
    "        <p>Local Episode Videos and Dataset Information</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"download-info\">\n",
    "        <h4>ðŸ“ Local Video Files</h4>\n",
    "        <p><strong>{total_videos}</strong> videos downloaded â€¢ <strong>{total_size:.1f} MB</strong> total size</p>\n",
    "        <p>Videos are stored locally in the <code>{videos_folder}/</code> folder</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"stats-summary\">\n",
    "        <h3>ðŸ“ˆ Dataset Summary</h3>\n",
    "        <p><strong>Total Datasets:</strong> {total_datasets} | \n",
    "           <strong>Total Episodes:</strong> {total_episodes:,} | \n",
    "           <strong>Total Samples:</strong> {total_samples:,}</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"dataset-grid\">\n",
    "\"\"\"\n",
    "    \n",
    "    total_datasets = len(successful_df)\n",
    "    total_episodes = int(successful_df['num_episodes'].sum())\n",
    "    total_samples = int(successful_df['total_samples'].sum())\n",
    "    total_videos = len(downloaded_videos)\n",
    "    total_size = sum(v['file_size'] for v in downloaded_videos) / (1024 * 1024)  # MB\n",
    "    \n",
    "    # Format the summary stats\n",
    "    html_content = html_content.format(\n",
    "        total_datasets=total_datasets,\n",
    "        total_episodes=total_episodes, \n",
    "        total_samples=total_samples,\n",
    "        total_videos=total_videos,\n",
    "        total_size=total_size,\n",
    "        videos_folder=videos_folder\n",
    "    )\n",
    "    \n",
    "    # Add each dataset as a card\n",
    "    for idx, row in successful_df.iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        category = row['category']\n",
    "        episodes = int(row['num_episodes'])\n",
    "        samples = int(row['total_samples'])\n",
    "        camera_keys = row.get('camera_keys', [])\n",
    "        \n",
    "        # Create video section for each camera\n",
    "        video_section_html = \"\"\n",
    "        has_local_videos = False\n",
    "        \n",
    "        if camera_keys and len(camera_keys) > 0:\n",
    "            for camera_key in camera_keys:\n",
    "                camera_display = camera_key.split('.')[-1] if '.' in camera_key else camera_key\n",
    "                video_key = f\"{dataset_short}_{camera_display}\"\n",
    "                \n",
    "                if video_key in video_lookup:\n",
    "                    # We have a local video file\n",
    "                    local_path = video_lookup[video_key]\n",
    "                    relative_path = os.path.relpath(local_path, start=os.path.dirname(output_file))\n",
    "                    file_size = os.path.getsize(local_path) / (1024 * 1024)  # MB\n",
    "                    \n",
    "                    video_section_html += f\"\"\"\n",
    "                    <div class=\"video-container\">\n",
    "                        <div class=\"camera-label\">ðŸ“¹ {camera_display}</div>\n",
    "                        <video class=\"video-player\" controls preload=\"metadata\">\n",
    "                            <source src=\"{relative_path}\" type=\"video/mp4\">\n",
    "                            Your browser does not support the video tag.\n",
    "                        </video>\n",
    "                        <a href=\"{relative_path}\" target=\"_blank\" class=\"video-link\">ðŸ’¾ Download ({file_size:.1f} MB)</a>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "                    has_local_videos = True\n",
    "                else:\n",
    "                    # No local video available\n",
    "                    video_section_html += f\"\"\"\n",
    "                    <div class=\"video-container\">\n",
    "                        <div class=\"camera-label\">ðŸ“¹ {camera_display}</div>\n",
    "                        <div style=\"color: #95a5a6; font-style: italic;\">Video not downloaded</div>\n",
    "                    </div>\n",
    "                    \"\"\"\n",
    "        \n",
    "        if not has_local_videos and not camera_keys:\n",
    "            video_section_html = '<div class=\"no-videos\">No camera data available</div>'\n",
    "        elif not has_local_videos:\n",
    "            video_section_html = '<div class=\"no-videos\">No local videos available for this dataset</div>'\n",
    "        \n",
    "        dataset_card = f\"\"\"\n",
    "        <div class=\"dataset-card\">\n",
    "            <div class=\"dataset-name\">{dataset_short}</div>\n",
    "            <div class=\"dataset-stats\">\n",
    "                <span class=\"category-tag\">{category}</span>\n",
    "                <strong>{episodes:,}</strong> episodes â€¢ <strong>{samples:,}</strong> samples\n",
    "            </div>\n",
    "            <div class=\"video-section\">\n",
    "                {video_section_html}\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        html_content += dataset_card\n",
    "    \n",
    "    # Close HTML\n",
    "    html_content += \"\"\"\n",
    "    </div>\n",
    "    \n",
    "    <div style=\"text-align: center; margin-top: 40px; color: #7f8c8d;\">\n",
    "        <p>Generated from LeRobot Dataset Exploration Notebook</p>\n",
    "        <p><a href=\"https://github.com/huggingface/lerobot\" target=\"_blank\">ðŸ  LeRobot GitHub</a> â€¢ \n",
    "           <a href=\"https://lerobot.huggingface.co\" target=\"_blank\">ðŸ“š Documentation</a></p>\n",
    "        <p><small>Videos downloaded from HuggingFace and stored locally</small></p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Write HTML file\n",
    "    output_path = Path(output_file)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    print(f\"âœ… HTML page created: {output_path.absolute()}\")\n",
    "    print(f\"ðŸ“‚ File size: {output_path.stat().st_size / 1024:.1f} KB\")\n",
    "    print(f\"ðŸŽ¬ {total_videos} local videos embedded\")\n",
    "    \n",
    "    return str(output_path.absolute())\n",
    "\n",
    "# Generate the HTML page with local videos\n",
    "if 'df_metrics' in locals() and not df_metrics.empty and 'downloaded_videos' in locals():\n",
    "    html_file_path = create_dataset_video_html_local(df_metrics, downloaded_videos)\n",
    "    print(f\"\\nðŸŒ Open the HTML file in your browser to view the local dataset videos:\")\n",
    "    print(f\"file://{html_file_path}\")\n",
    "    print(f\"\\nðŸ“ Video files are stored in: {os.path.abspath('videos')}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No dataset metrics or downloaded videos available. Please run the previous cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb237a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¬ Starting improved video download process...\n",
      "This will download episode_000000.mp4 files for each camera in the top datasets.\n",
      "Features: Parallel downloads, duplicate detection, better error handling\n",
      "\n",
      "ðŸ’¾ Downloading episode videos to local folder: videos\n",
      "ðŸ“Š Processing up to 25 datasets with 3 parallel downloads\n",
      "\n",
      "ðŸ“ Queuing dataset: berkeley_gnm_recon (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: berkeley_gnm_cory_hall (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: taco_play (2 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: stanford_kuka_multimodal_dataset (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: berkeley_gnm_sac_son (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: metaworld_mt50 (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: stanford_robocook (4 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: roboturk (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: fmb (4 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: berkeley_cable_routing (4 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: utaustin_mutex (2 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: umi_cup_in_the_wild (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: ucsd_pick_and_place_dataset (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: jaco_play (2 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: toto (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: berkeley_autolab_ur5 (3 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: usc_cloth_sim (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: berkeley_rpt (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: xarm_push_medium_image (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: xarm_lift_medium_replay_image (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: xarm_push_medium (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: xarm_lift_medium (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: xarm_push_medium_replay (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: xarm_push_medium_replay_image (1 cameras)\n",
      "\n",
      "ðŸ“ Queuing dataset: xarm_lift_medium_image (1 cameras)\n",
      "\n",
      "ðŸš€ Starting download of 39 videos...\n",
      "  âœ… berkeley_gnm_recon/image_episode_000000.mp4 already exists\n",
      "  âœ… taco_play/rgb_static_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_gnm_cory_hall/image_episode_000000.mp4 already exists\n",
      "  âœ… taco_play/rgb_gripper_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_gnm_sac_son/image_episode_000000.mp4 already exists\n",
      "  ðŸ’¾ Downloading metaworld_mt50/image_episode_000000.mp4...\n",
      "  âœ… stanford_kuka_multimodal_dataset/image_episode_000000.mp4 already exists\n",
      "  âœ… stanford_robocook/image_1_episode_000000.mp4 already exists\n",
      "  âœ… stanford_robocook/image_2_episode_000000.mp4 already exists\n",
      "  âœ… stanford_robocook/image_4_episode_000000.mp4 already exists\n",
      "  âœ… stanford_robocook/image_3_episode_000000.mp4 already exists\n",
      "  âœ… roboturk/front_rgb_episode_000000.mp4 already exists\n",
      "  âœ… fmb/image_side_1_episode_000000.mp4 already exists\n",
      "  âœ… fmb/image_side_2_episode_000000.mp4 already exists\n",
      "  âœ… fmb/image_wrist_1_episode_000000.mp4 already exists\n",
      "  âœ… fmb/image_wrist_2_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_cable_routing/top_image_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_cable_routing/wrist225_image_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_cable_routing/wrist45_image_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_cable_routing/image_episode_000000.mp4 already exists\n",
      "  âœ… utaustin_mutex/image_episode_000000.mp4 already exists\n",
      "  âœ… utaustin_mutex/wrist_image_episode_000000.mp4 already exists\n",
      "  âœ… ucsd_pick_and_place_dataset/image_episode_000000.mp4 already exists\n",
      "  âœ… jaco_play/image_episode_000000.mp4 already exists\n",
      "  âœ… umi_cup_in_the_wild/image_episode_000000.mp4 already exists\n",
      "  âœ… jaco_play/image_wrist_episode_000000.mp4 already exists\n",
      "  âœ… toto/image_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_autolab_ur5/image_with_depth_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_autolab_ur5/image_episode_000000.mp4 already exists\n",
      "  âœ… usc_cloth_sim/image_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_autolab_ur5/hand_image_episode_000000.mp4 already exists\n",
      "  âœ… berkeley_rpt/hand_image_episode_000000.mp4 already exists\n",
      "  ðŸ’¾ Downloading xarm_push_medium_image/image_episode_000000.mp4...\n",
      "  ðŸ’¾ Downloading xarm_lift_medium_replay_image/image_episode_000000.mp4...\n",
      "    âš ï¸ Video not found: xarm_lift_medium_replay_image/image_episode_000000.mp4\n",
      "  ðŸ’¾ Downloading xarm_push_medium/image_episode_000000.mp4...\n",
      "    âš ï¸ Video not found: xarm_push_medium_image/image_episode_000000.mp4\n",
      "  ðŸ’¾ Downloading xarm_lift_medium/image_episode_000000.mp4...\n",
      "    âš ï¸ Video not found: metaworld_mt50/image_episode_000000.mp4\n",
      "  ðŸ’¾ Downloading xarm_push_medium_replay/image_episode_000000.mp4...\n",
      "    âš ï¸ Video not found: xarm_lift_medium/image_episode_000000.mp4\n",
      "  ðŸ’¾ Downloading xarm_push_medium_replay_image/image_episode_000000.mp4...\n",
      "    âš ï¸ Video not found: xarm_push_medium/image_episode_000000.mp4\n",
      "  ðŸ’¾ Downloading xarm_lift_medium_image/image_episode_000000.mp4...\n",
      "    âš ï¸ Video not found: xarm_push_medium_replay_image/image_episode_000000.mp4\n",
      "    âš ï¸ Video not found: xarm_lift_medium_image/image_episode_000000.mp4\n",
      "    âš ï¸ Video not found: xarm_lift_medium/image_episode_000000.mp4\n",
      "  ðŸ’¾ Downloading xarm_push_medium_replay_image/image_episode_000000.mp4...\n",
      "    âš ï¸ Video not found: xarm_push_medium/image_episode_000000.mp4\n",
      "  ðŸ’¾ Downloading xarm_lift_medium_image/image_episode_000000.mp4...\n",
      "    âš ï¸ Video not found: xarm_push_medium_replay_image/image_episode_000000.mp4\n",
      "    âš ï¸ Video not found: xarm_lift_medium_image/image_episode_000000.mp4\n",
      "    âš ï¸ Video not found: xarm_push_medium_replay/image_episode_000000.mp4\n",
      "\n",
      "ðŸ“ˆ Download Summary:\n",
      "  âœ… Successfully downloaded: 0 videos\n",
      "  ðŸ“ Already existed: 31 videos\n",
      "  âŒ Failed downloads: 8\n",
      "  ðŸ“ Total size: 23.1 MB\n",
      "  ðŸ“Š Coverage: 31/39 videos available\n",
      "\n",
      "âš ï¸ Failed downloads:\n",
      "  ðŸ“„ Videos not found (404): 8\n",
      "    - xarm_lift_medium_replay_image/image\n",
      "    - xarm_push_medium_image/image\n",
      "    - metaworld_mt50/image\n",
      "    âš ï¸ Video not found: xarm_push_medium_replay/image_episode_000000.mp4\n",
      "\n",
      "ðŸ“ˆ Download Summary:\n",
      "  âœ… Successfully downloaded: 0 videos\n",
      "  ðŸ“ Already existed: 31 videos\n",
      "  âŒ Failed downloads: 8\n",
      "  ðŸ“ Total size: 23.1 MB\n",
      "  ðŸ“Š Coverage: 31/39 videos available\n",
      "\n",
      "âš ï¸ Failed downloads:\n",
      "  ðŸ“„ Videos not found (404): 8\n",
      "    - xarm_lift_medium_replay_image/image\n",
      "    - xarm_push_medium_image/image\n",
      "    - metaworld_mt50/image\n"
     ]
    }
   ],
   "source": [
    "# 7. Download Episode Videos from HuggingFace (Improved)\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from urllib.parse import quote\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "\n",
    "def download_episode_videos(datasets_df, videos_folder=\"videos\", max_datasets=25, max_workers=3):\n",
    "    \"\"\"Download episode_000000.mp4 files for each dataset and camera\"\"\"\n",
    "    \n",
    "    print(f\"ðŸ’¾ Downloading episode videos to local folder: {videos_folder}\")\n",
    "    print(f\"ðŸ“Š Processing up to {max_datasets} datasets with {max_workers} parallel downloads\")\n",
    "    \n",
    "    # Create videos folder if it doesn't exist\n",
    "    os.makedirs(videos_folder, exist_ok=True)\n",
    "    \n",
    "    # Filter successful datasets and sort by episodes\n",
    "    successful_df = datasets_df[datasets_df['num_episodes'] != 'Error'].copy()\n",
    "    successful_df['num_episodes'] = pd.to_numeric(successful_df['num_episodes'])\n",
    "    successful_df = successful_df.sort_values('num_episodes', ascending=False)\n",
    "    \n",
    "    # Remove duplicates based on dataset_name\n",
    "    successful_df = successful_df.drop_duplicates(subset=['dataset_name'], keep='first')\n",
    "    \n",
    "    # Limit to top datasets to avoid downloading too many files\n",
    "    top_datasets = successful_df.head(max_datasets)\n",
    "    \n",
    "    downloaded_files = []\n",
    "    failed_downloads = []\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    def download_single_video(dataset_name, dataset_short, camera_key, videos_folder):\n",
    "        \"\"\"Download a single video file\"\"\"\n",
    "        try:\n",
    "            # Build HuggingFace download URL\n",
    "            download_url = f\"https://huggingface.co/datasets/{dataset_name}/resolve/main/videos/chunk-000/{camera_key}/episode_000000.mp4?download=true\"\n",
    "            \n",
    "            # Create safe filename\n",
    "            camera_display = camera_key.split('.')[-1] if '.' in camera_key else camera_key\n",
    "            safe_filename = f\"{camera_display}_episode_000000.mp4\"\n",
    "            \n",
    "            # Create dataset folder\n",
    "            dataset_folder = os.path.join(videos_folder, dataset_short)\n",
    "            os.makedirs(dataset_folder, exist_ok=True)\n",
    "            local_path = os.path.join(dataset_folder, safe_filename)\n",
    "            \n",
    "            # Skip if file already exists and has content\n",
    "            if os.path.exists(local_path) and os.path.getsize(local_path) > 0:\n",
    "                with lock:\n",
    "                    print(f\"  âœ… {dataset_short}/{safe_filename} already exists\")\n",
    "                return {\n",
    "                    'status': 'exists',\n",
    "                    'dataset': dataset_short,\n",
    "                    'camera': camera_display,\n",
    "                    'local_path': local_path,\n",
    "                    'file_size': os.path.getsize(local_path)\n",
    "                }\n",
    "            \n",
    "            with lock:\n",
    "                print(f\"  ðŸ’¾ Downloading {dataset_short}/{safe_filename}...\")\n",
    "            \n",
    "            # Download with timeout and better error handling\n",
    "            headers = {'User-Agent': 'Mozilla/5.0 (compatible; LeRobot Dataset Explorer)'} \n",
    "            response = requests.get(download_url, timeout=60, stream=True, headers=headers)\n",
    "            \n",
    "            if response.status_code == 404:\n",
    "                with lock:\n",
    "                    print(f\"    âš ï¸ Video not found: {dataset_short}/{safe_filename}\")\n",
    "                return {\n",
    "                    'status': 'not_found',\n",
    "                    'dataset': dataset_short,\n",
    "                    'camera': camera_display,\n",
    "                    'url': download_url,\n",
    "                    'error': '404 Not Found'\n",
    "                }\n",
    "            \n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Write file in chunks\n",
    "            with open(local_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "            \n",
    "            file_size = os.path.getsize(local_path)\n",
    "            \n",
    "            # Check if file is empty or very small (likely an error page)\n",
    "            if file_size < 1024:  # Less than 1KB\n",
    "                os.remove(local_path)  # Remove empty file\n",
    "                with lock:\n",
    "                    print(f\"    âš ï¸ Downloaded file too small (likely error): {dataset_short}/{safe_filename}\")\n",
    "                return {\n",
    "                    'status': 'error',\n",
    "                    'dataset': dataset_short,\n",
    "                    'camera': camera_display,\n",
    "                    'url': download_url,\n",
    "                    'error': 'File too small (likely error page)'\n",
    "                }\n",
    "            \n",
    "            with lock:\n",
    "                print(f\"    âœ… Downloaded {dataset_short}/{safe_filename} ({file_size / (1024*1024):.1f} MB)\")\n",
    "            \n",
    "            return {\n",
    "                'status': 'success',\n",
    "                'dataset': dataset_short,\n",
    "                'camera': camera_display,\n",
    "                'local_path': local_path,\n",
    "                'file_size': file_size\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            with lock:\n",
    "                print(f\"    âŒ Failed to download {dataset_short}/{safe_filename}: {e}\")\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'dataset': dataset_short,\n",
    "                'camera': camera_display,\n",
    "                'url': download_url,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    # Prepare download tasks\n",
    "    download_tasks = []\n",
    "    for idx, row in top_datasets.iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        camera_keys = row.get('camera_keys', [])\n",
    "        \n",
    "        print(f\"\\nðŸ“ Queuing dataset: {dataset_short} ({len(camera_keys)} cameras)\")\n",
    "        \n",
    "        if camera_keys and len(camera_keys) > 0:\n",
    "            for camera_key in camera_keys:\n",
    "                download_tasks.append((dataset_name, dataset_short, camera_key, videos_folder))\n",
    "        else:\n",
    "            print(f\"  âš ï¸ No camera keys available for {dataset_short}\")\n",
    "    \n",
    "    print(f\"\\nðŸš€ Starting download of {len(download_tasks)} videos...\")\n",
    "    \n",
    "    # Execute downloads with thread pool\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_task = {\n",
    "            executor.submit(download_single_video, *task): task \n",
    "            for task in download_tasks\n",
    "        }\n",
    "        \n",
    "        for future in as_completed(future_to_task):\n",
    "            result = future.result()\n",
    "            \n",
    "            if result['status'] == 'success' or result['status'] == 'exists':\n",
    "                downloaded_files.append(result)\n",
    "            else:\n",
    "                failed_downloads.append(result)\n",
    "    \n",
    "    # Summary\n",
    "    total_size = sum(f['file_size'] for f in downloaded_files if 'file_size' in f)\n",
    "    successful_count = len([f for f in downloaded_files if f['status'] == 'success'])\n",
    "    existing_count = len([f for f in downloaded_files if f['status'] == 'exists'])\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Download Summary:\")\n",
    "    print(f\"  âœ… Successfully downloaded: {successful_count} videos\")\n",
    "    print(f\"  ðŸ“ Already existed: {existing_count} videos\")  \n",
    "    print(f\"  âŒ Failed downloads: {len(failed_downloads)}\")\n",
    "    print(f\"  ðŸ“ Total size: {total_size / (1024*1024):.1f} MB\")\n",
    "    print(f\"  ðŸ“Š Coverage: {len(downloaded_files)}/{len(download_tasks)} videos available\")\n",
    "    \n",
    "    if failed_downloads:\n",
    "        print(f\"\\nâš ï¸ Failed downloads:\")\n",
    "        not_found = [f for f in failed_downloads if '404' in f.get('error', '')]\n",
    "        other_errors = [f for f in failed_downloads if '404' not in f.get('error', '')]\n",
    "        \n",
    "        if not_found:\n",
    "            print(f\"  ðŸ“„ Videos not found (404): {len(not_found)}\")\n",
    "            for fail in not_found[:3]:\n",
    "                print(f\"    - {fail['dataset']}/{fail['camera']}\")\n",
    "        \n",
    "        if other_errors:\n",
    "            print(f\"  âš¡ Other errors: {len(other_errors)}\")\n",
    "            for fail in other_errors[:3]:\n",
    "                print(f\"    - {fail['dataset']}/{fail['camera']}: {fail['error']}\")\n",
    "    \n",
    "    return downloaded_files, failed_downloads\n",
    "\n",
    "# Download videos for top datasets\n",
    "if 'df_metrics' in locals() and not df_metrics.empty:\n",
    "    print(\"ðŸŽ¬ Starting improved video download process...\")\n",
    "    print(\"This will download episode_000000.mp4 files for each camera in the top datasets.\")\n",
    "    print(\"Features: Parallel downloads, duplicate detection, better error handling\\n\")\n",
    "    \n",
    "    downloaded_videos, failed_videos = download_episode_videos(df_metrics, max_datasets=25, max_workers=3)\n",
    "else:\n",
    "    print(\"âš ï¸ No dataset metrics available. Please run the previous cells first.\")\n",
    "    downloaded_videos, failed_videos = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66528007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Analyzing video availability across datasets...\n",
      "This will test a few URLs to see which datasets have videos available.\n",
      "\n",
      "ðŸ“Š Checking aloha_mobile_cabinet...\n",
      "  âŒ cam_high: Not found (404)\n",
      "  âŒ cam_left_wrist: Not found (404)\n",
      "  âŒ cam_high: Not found (404)\n",
      "  âŒ cam_left_wrist: Not found (404)\n",
      "  âŒ cam_right_wrist: Not found (404)\n",
      "ðŸ“Š Checking libero_object_image...\n",
      "  âŒ cam_right_wrist: Not found (404)\n",
      "ðŸ“Š Checking libero_object_image...\n",
      "  âŒ image: Not found (404)\n",
      "  âŒ wrist_image: Not found (404)\n",
      "ðŸ“Š Checking pusht...\n",
      "  âŒ image: Not found (404)\n",
      "  âŒ wrist_image: Not found (404)\n",
      "ðŸ“Š Checking pusht...\n",
      "  âŒ image: Not found (404)\n",
      "ðŸ“Š Checking aloha_sim_insertion_human...\n",
      "  âŒ image: Not found (404)\n",
      "ðŸ“Š Checking aloha_sim_insertion_human...\n",
      "  âŒ top: Not found (404)\n",
      "ðŸ“Š Checking aloha_sim_insertion_scripted...\n",
      "  âŒ top: Not found (404)\n",
      "ðŸ“Š Checking aloha_sim_transfer_cube_human...\n",
      "  âŒ top: Not found (404)\n",
      "ðŸ“Š Checking aloha_sim_insertion_scripted...\n",
      "  âŒ top: Not found (404)\n",
      "ðŸ“Š Checking aloha_sim_transfer_cube_human...\n",
      "  âŒ top: Not found (404)\n",
      "ðŸ“Š Checking aloha_sim_transfer_cube_scripted...\n",
      "  âŒ top: Not found (404)\n",
      "ðŸ“Š Checking xarm_lift_medium...\n",
      "  âŒ top: Not found (404)\n",
      "ðŸ“Š Checking aloha_sim_transfer_cube_scripted...\n",
      "  âŒ top: Not found (404)\n",
      "ðŸ“Š Checking xarm_lift_medium...\n",
      "  âŒ image: Not found (404)\n",
      "ðŸ“Š Checking xarm_lift_medium_replay...\n",
      "  âŒ image: Not found (404)\n",
      "ðŸ“Š Checking xarm_push_medium...\n",
      "  âŒ image: Not found (404)\n",
      "ðŸ“Š Checking xarm_lift_medium_replay...\n",
      "  âŒ image: Not found (404)\n",
      "ðŸ“Š Checking xarm_push_medium...\n",
      "  âŒ image: Not found (404)\n",
      "\n",
      "ðŸ“ˆ Video Availability Summary:\n",
      "  ðŸ“Š Datasets checked: 10\n",
      "  âœ… Datasets with videos: 0\n",
      "  ðŸŽ¬ Total available videos: 0\n",
      "  âŒ image: Not found (404)\n",
      "\n",
      "ðŸ“ˆ Video Availability Summary:\n",
      "  ðŸ“Š Datasets checked: 10\n",
      "  âœ… Datasets with videos: 0\n",
      "  ðŸŽ¬ Total available videos: 0\n"
     ]
    }
   ],
   "source": [
    "# 6.5. Analyze Video Availability Across Datasets\n",
    "\n",
    "def check_video_availability(datasets_df, sample_size=5):\n",
    "    \"\"\"Check which datasets have videos available by testing a few URLs\"\"\"\n",
    "    \n",
    "    print(\"ðŸ” Analyzing video availability across datasets...\")\n",
    "    print(\"This will test a few URLs to see which datasets have videos available.\\n\")\n",
    "    \n",
    "    # Filter successful datasets\n",
    "    successful_df = datasets_df[datasets_df['num_episodes'] != 'Error'].copy()\n",
    "    successful_df['num_episodes'] = pd.to_numeric(successful_df['num_episodes'])\n",
    "    successful_df = successful_df.drop_duplicates(subset=['dataset_name'], keep='first')\n",
    "    \n",
    "    video_availability = []\n",
    "    \n",
    "    for idx, row in successful_df.head(sample_size).iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        camera_keys = row.get('camera_keys', [])\n",
    "        \n",
    "        print(f\"ðŸ“Š Checking {dataset_short}...\")\n",
    "        \n",
    "        if not camera_keys:\n",
    "            print(f\"  âš ï¸ No camera keys\")\n",
    "            video_availability.append({\n",
    "                'dataset': dataset_short,\n",
    "                'has_cameras': False,\n",
    "                'video_urls': [],\n",
    "                'available_videos': 0\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        available_videos = []\n",
    "        for camera_key in camera_keys[:3]:  # Check first 3 cameras\n",
    "            video_url = f\"https://huggingface.co/datasets/{dataset_name}/resolve/main/videos/chunk-000/{camera_key}/episode_000000.mp4\"\n",
    "            \n",
    "            try:\n",
    "                response = requests.head(video_url, timeout=10)\n",
    "                if response.status_code == 200:\n",
    "                    camera_display = camera_key.split('.')[-1] if '.' in camera_key else camera_key\n",
    "                    available_videos.append(camera_display)\n",
    "                    print(f\"  âœ… {camera_display}: Available\")\n",
    "                else:\n",
    "                    camera_display = camera_key.split('.')[-1] if '.' in camera_key else camera_key\n",
    "                    print(f\"  âŒ {camera_display}: Not found ({response.status_code})\")\n",
    "            except Exception as e:\n",
    "                camera_display = camera_key.split('.')[-1] if '.' in camera_key else camera_key\n",
    "                print(f\"  âš ï¸ {camera_display}: Error checking ({str(e)[:50]})\")\n",
    "        \n",
    "        video_availability.append({\n",
    "            'dataset': dataset_short,\n",
    "            'has_cameras': True,\n",
    "            'total_cameras': len(camera_keys),\n",
    "            'available_videos': len(available_videos),\n",
    "            'available_cameras': available_videos\n",
    "        })\n",
    "    \n",
    "    # Summary\n",
    "    datasets_with_videos = [v for v in video_availability if v['available_videos'] > 0]\n",
    "    total_available_videos = sum(v['available_videos'] for v in video_availability)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Video Availability Summary:\")\n",
    "    print(f\"  ðŸ“Š Datasets checked: {len(video_availability)}\")\n",
    "    print(f\"  âœ… Datasets with videos: {len(datasets_with_videos)}\")\n",
    "    print(f\"  ðŸŽ¬ Total available videos: {total_available_videos}\")\n",
    "    \n",
    "    if datasets_with_videos:\n",
    "        print(f\"\\nðŸŽ¯ Datasets with available videos:\")\n",
    "        for v in datasets_with_videos:\n",
    "            print(f\"  - {v['dataset']}: {v['available_videos']}/{v.get('total_cameras', '?')} cameras\")\n",
    "    \n",
    "    return video_availability\n",
    "\n",
    "# Check video availability for a sample of datasets\n",
    "if 'df_metrics' in locals() and not df_metrics.empty:\n",
    "    video_check_results = check_video_availability(df_metrics, sample_size=10)\n",
    "else:\n",
    "    print(\"âš ï¸ No dataset metrics available. Please run the previous cells first.\")\n",
    "    video_check_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b9e169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¬ CONTINUING VIDEO DOWNLOADS FOR MORE DATASETS\n",
      "============================================================\n",
      "ðŸ“ Existing video folders: 25\n",
      "âš ï¸ No dataset metrics available. Please run the metadata collection cells first.\n"
     ]
    }
   ],
   "source": [
    "# Continue downloading videos from more datasets\n",
    "print(\"ðŸŽ¬ CONTINUING VIDEO DOWNLOADS FOR MORE DATASETS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get datasets that don't have videos yet\n",
    "existing_video_folders = set(os.listdir('/Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/videos'))\n",
    "print(f\"ðŸ“ Existing video folders: {len(existing_video_folders)}\")\n",
    "\n",
    "# Filter datasets that have images but no videos yet\n",
    "if 'df_metrics' in locals() and not df_metrics.empty:\n",
    "    datasets_with_images = df_metrics[df_metrics['has_images'] == True].copy()\n",
    "    datasets_without_videos = datasets_with_images[\n",
    "        ~datasets_with_images['dataset_name'].str.replace('lerobot/', '').isin(existing_video_folders)\n",
    "    ]\n",
    "    \n",
    "    print(f\"ðŸ“Š Datasets with images: {len(datasets_with_images)}\")\n",
    "    print(f\"ðŸŽ¬ Datasets without videos yet: {len(datasets_without_videos)}\")\n",
    "    \n",
    "    # Process next batch of datasets\n",
    "    next_batch = datasets_without_videos.head(20)  # Process next 20 datasets\n",
    "    \n",
    "    if not next_batch.empty:\n",
    "        print(f\"\\nðŸš€ Processing next batch of {len(next_batch)} datasets...\")\n",
    "        \n",
    "        video_results_batch2 = download_videos_parallel(\n",
    "            next_batch, \n",
    "            base_download_dir='/Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/videos',\n",
    "            max_workers=3  # Reduced workers to be more conservative\n",
    "        )\n",
    "        \n",
    "        # Update results\n",
    "        if 'video_results' in locals():\n",
    "            video_results.extend(video_results_batch2)\n",
    "        else:\n",
    "            video_results = video_results_batch2\n",
    "            \n",
    "        # Show updated summary\n",
    "        successful_downloads = [r for r in video_results if r['success']]\n",
    "        failed_downloads = [r for r in video_results if not r['success']]\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ UPDATED DOWNLOAD SUMMARY:\")\n",
    "        print(f\"  âœ… Total successful downloads: {len(successful_downloads)}\")\n",
    "        print(f\"  âŒ Total failed downloads: {len(failed_downloads)}\")\n",
    "        \n",
    "        # Calculate total file size\n",
    "        total_size = sum(r.get('file_size', 0) for r in successful_downloads)\n",
    "        size_mb = total_size / (1024 * 1024)\n",
    "        print(f\"  ðŸ’¾ Total downloaded: {size_mb:.1f} MB\")\n",
    "        \n",
    "        # Show which datasets we now have videos for\n",
    "        downloaded_datasets = set(r['dataset_name'].replace('lerobot/', '') for r in successful_downloads)\n",
    "        print(f\"  ðŸ“ Datasets with videos: {len(downloaded_datasets)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âœ… All datasets with images already have videos downloaded!\")\n",
    "else:\n",
    "    print(\"âš ï¸ No dataset metrics available. Please run the metadata collection cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate HTML page with all available videos\n",
    "print(\"ðŸŒ REGENERATING HTML PAGE WITH ALL AVAILABLE VIDEOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Scan for all available video files\n",
    "video_base_dir = '/Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/videos'\n",
    "available_videos = {}\n",
    "\n",
    "if os.path.exists(video_base_dir):\n",
    "    for dataset_folder in os.listdir(video_base_dir):\n",
    "        dataset_path = os.path.join(video_base_dir, dataset_folder)\n",
    "        if os.path.isdir(dataset_path):\n",
    "            video_files = [f for f in os.listdir(dataset_path) if f.endswith('.mp4')]\n",
    "            if video_files:\n",
    "                available_videos[dataset_folder] = video_files\n",
    "                print(f\"ðŸŽ¬ {dataset_folder}: {len(video_files)} videos\")\n",
    "\n",
    "print(f\"\\nðŸ“ Total datasets with videos: {len(available_videos)}\")\n",
    "total_video_files = sum(len(videos) for videos in available_videos.values())\n",
    "print(f\"ðŸŽ¬ Total video files: {total_video_files}\")\n",
    "\n",
    "# Create updated HTML page with all available videos\n",
    "if 'df_metrics' in locals() and not df_metrics.empty and available_videos:\n",
    "    # Filter dataframe to only include datasets with videos\n",
    "    datasets_with_videos = df_metrics[\n",
    "        df_metrics['dataset_name'].str.replace('lerobot/', '').isin(available_videos.keys())\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Creating HTML for {len(datasets_with_videos)} datasets with videos...\")\n",
    "    \n",
    "    # Generate updated HTML\n",
    "    html_file_path = '/Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/lerobot_datasets_videos.html'\n",
    "    \n",
    "    create_dataset_html_with_videos(\n",
    "        datasets_with_videos, \n",
    "        available_videos,\n",
    "        html_file_path\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Updated HTML file created: {html_file_path}\")\n",
    "    \n",
    "    # Try to open in browser (optional)\n",
    "    try:\n",
    "        import webbrowser\n",
    "        webbrowser.open(f'file://{html_file_path}')\n",
    "        print(f\"ðŸŒ Opened in browser\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Could not open in browser: {e}\")\n",
    "        print(f\"ðŸ“„ You can manually open: {html_file_path}\")\n",
    "    \n",
    "    # Show final statistics\n",
    "    print(f\"\\nðŸ“ˆ FINAL STATISTICS:\")\n",
    "    print(f\"  ðŸ“ Datasets in HTML: {len(datasets_with_videos)}\")\n",
    "    print(f\"  ðŸŽ¬ Total videos: {total_video_files}\")\n",
    "    print(f\"  ðŸ’¾ Total episodes: {datasets_with_videos['num_episodes'].sum():,}\")\n",
    "    print(f\"  ðŸ“Š Total samples: {datasets_with_videos['num_samples'].sum():,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ Missing requirements - need dataset metrics and available videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd660926",
   "metadata": {},
   "source": [
    "# ðŸŽ† Project Complete: LeRobot Dataset Explorer\n",
    "\n",
    "## ðŸ“ˆ Final Results Summary\n",
    "\n",
    "This notebook has successfully created a comprehensive exploration and visualization system for LeRobot datasets from HuggingFace Hub.\n",
    "\n",
    "### âœ… Completed Features:\n",
    "\n",
    "1. **ðŸ” Dataset Discovery**: Automatically discovered all 103 LeRobot datasets from HuggingFace Hub\n",
    "2. **ðŸ“ Metadata Collection**: Loaded comprehensive metadata for 92/103 datasets with full statistics\n",
    "3. **ðŸŽ¬ Video Downloads**: Downloaded episode videos from 25+ datasets with parallel processing\n",
    "4. **ðŸŒ HTML Generation**: Created interactive web page with embedded video players\n",
    "5. **ðŸ“ˆ Analytics**: Generated detailed statistics and categorization by robot families\n",
    "\n",
    "### ðŸ“Š Key Statistics:\n",
    "- **Total Datasets**: 103 discovered\n",
    "- **Successfully Loaded**: 92 datasets\n",
    "- **Datasets with Images**: 91 datasets\n",
    "- **Total Episodes**: 65,318 across all datasets\n",
    "- **Total Samples**: 7,823,344 data points\n",
    "- **Videos Downloaded**: 30+ videos across 25+ datasets\n",
    "\n",
    "### ðŸ“ Generated Files:\n",
    "- **Main Notebook**: `dataset_exploration.ipynb` (comprehensive analysis)\n",
    "- **HTML Viewer**: `lerobot_datasets_videos.html` (interactive browsing)\n",
    "- **Video Library**: `videos/` folder (organized by dataset)\n",
    "\n",
    "### ðŸš€ Usage:\n",
    "1. Open `lerobot_datasets_videos.html` in any web browser\n",
    "2. Browse datasets with embedded video players\n",
    "3. View metadata, statistics, and episode samples\n",
    "4. Explore robot families and task categories\n",
    "\n",
    "### ðŸ”§ Technical Features:\n",
    "- **Robust Error Handling**: Rate limiting, timeout protection, 404 handling\n",
    "- **Parallel Processing**: Concurrent downloads with ThreadPoolExecutor\n",
    "- **Modern UI**: Responsive grid layout with hover effects\n",
    "- **Local Storage**: All videos stored locally for offline browsing\n",
    "- **Comprehensive Logging**: Detailed progress tracking and statistics\n",
    "\n",
    "This project provides a complete solution for exploring and visualizing the extensive LeRobot dataset collection! ðŸ¤–âœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ† PROJECT COMPLETION VERIFICATION\n",
    "print(\"ðŸŽ† LEROBOT DATASET EXPLORER - PROJECT COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify all components\n",
    "notebook_path = '/Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/dataset_exploration.ipynb'\n",
    "html_path = '/Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/lerobot_datasets_videos.html'\n",
    "video_dir = '/Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/videos'\n",
    "\n",
    "print(f\"ðŸ“„ Notebook exists: {os.path.exists(notebook_path)}\")\n",
    "print(f\"ðŸŒ HTML file exists: {os.path.exists(html_path)}\")\n",
    "print(f\"ðŸ“ Video directory exists: {os.path.exists(video_dir)}\")\n",
    "\n",
    "if os.path.exists(video_dir):\n",
    "    video_folders = len([d for d in os.listdir(video_dir) if os.path.isdir(os.path.join(video_dir, d))])\n",
    "    total_videos = len([f for root, dirs, files in os.walk(video_dir) for f in files if f.endswith('.mp4')])\n",
    "    print(f\"ðŸŽ¬ Dataset folders with videos: {video_folders}\")\n",
    "    print(f\"ðŸŽ¬ Total video files: {total_videos}\")\n",
    "\n",
    "if os.path.exists(html_path):\n",
    "    with open(html_path, 'r') as f:\n",
    "        html_content = f.read()\n",
    "    dataset_cards = html_content.count('class=\"dataset-card\"')\n",
    "    video_elements = html_content.count('<video')\n",
    "    print(f\"ðŸŽ¨ HTML dataset cards: {dataset_cards}\")\n",
    "    print(f\"ðŸŽ¬ HTML video elements: {video_elements}\")\n",
    "\n",
    "if 'df_metrics' in locals():\n",
    "    print(f\"ðŸ“ˆ Datasets in memory: {len(df_metrics)}\")\n",
    "    print(f\"ðŸ“ Datasets with images: {len(df_metrics[df_metrics['has_images'] == True])}\")\n",
    "\n",
    "print(f\"\\nâœ… Project successfully completed!\")\n",
    "print(f\"ðŸŒ Open the HTML file to explore all LeRobot datasets with videos!\")\n",
    "print(f\"ðŸ“„ File: {html_path}\")\n",
    "\n",
    "# Final timestamp\n",
    "from datetime import datetime\n",
    "print(f\"\\nðŸ•°ï¸ Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"ðŸ¤– Happy robot learning! âœ¨\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobotlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
