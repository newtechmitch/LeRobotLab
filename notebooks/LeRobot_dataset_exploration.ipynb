{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fef2ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michelmeyer/miniconda3/envs/lerobotlab/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added lerobot path: /Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/lerobot\n"
     ]
    }
   ],
   "source": [
    "# Essential imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from urllib.parse import urljoin\n",
    "import requests\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Add the lerobot folder to Python path (moved outside project)\n",
    "# Use current working directory to find the lerobot path\n",
    "current_dir = Path(os.getcwd())\n",
    "lerobot_path = current_dir.parent.parent / \"lerobot\"\n",
    "\n",
    "if lerobot_path.exists():\n",
    "    sys.path.insert(0, str(lerobot_path))\n",
    "    print(f\"Added lerobot path: {lerobot_path}\")\n",
    "else:\n",
    "    print(f\"Warning: lerobot path not found at {lerobot_path}\")\n",
    "    # Try alternative path\n",
    "    alt_path = current_dir.parent / \"lerobot\"\n",
    "    if alt_path.exists():\n",
    "        sys.path.insert(0, str(alt_path))\n",
    "        print(f\"Found lerobot at alternative path: {alt_path}\")\n",
    "    else:\n",
    "        print(f\"Alternative path also not found: {alt_path}\")\n",
    "\n",
    "# LeRobot specific imports  \n",
    "from lerobot.common.datasets.lerobot_dataset import LeRobotDataset, LeRobotDatasetMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e744403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovering LeRobot datasets...\n",
      "Found 103 datasets:\n",
      "   1. lerobot/aloha_mobile_cabinet\n",
      "   2. lerobot/aloha_mobile_chair\n",
      "   3. lerobot/aloha_mobile_elevator\n",
      "   4. lerobot/aloha_mobile_shrimp\n",
      "   5. lerobot/aloha_mobile_wash_pan\n",
      "   6. lerobot/aloha_mobile_wipe_wine\n",
      "   7. lerobot/aloha_sim_insertion_human\n",
      "   8. lerobot/aloha_sim_insertion_human_image\n",
      "   9. lerobot/aloha_sim_insertion_scripted\n",
      "  10. lerobot/aloha_sim_insertion_scripted_image\n",
      "  ... and 93 more\n",
      "\n",
      "Dataset Family Analysis:\n",
      "  aloha: 29 dataset(s)\n",
      "  berkeley: 8 dataset(s)\n",
      "  xarm: 8 dataset(s)\n",
      "  utokyo: 5 dataset(s)\n",
      "  koch: 4 dataset(s)\n",
      "  libero: 4 dataset(s)\n",
      "  unitreeh1: 4 dataset(s)\n",
      "  austin: 3 dataset(s)\n",
      "  cmu: 3 dataset(s)\n",
      "  dlr: 3 dataset(s)\n"
     ]
    }
   ],
   "source": [
    "def get_lerobot_datasets():\n",
    "    \"\"\"Get list of all LeRobot datasets from HuggingFace Hub\"\"\"\n",
    "    api = HfApi()\n",
    "    \n",
    "    try:\n",
    "        datasets = api.list_datasets(author=\"lerobot\", limit=None)\n",
    "        dataset_names = [dataset.id for dataset in datasets]\n",
    "        return sorted(dataset_names)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching datasets: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"Discovering LeRobot datasets...\")\n",
    "available_datasets = get_lerobot_datasets()\n",
    "\n",
    "print(f\"Found {len(available_datasets)} datasets:\")\n",
    "for i, dataset_name in enumerate(available_datasets[:10]):  # Show first 10\n",
    "    print(f\"  {i+1:2d}. {dataset_name}\")\n",
    "\n",
    "if len(available_datasets) > 10:\n",
    "    print(f\"  ... and {len(available_datasets) - 10} more\")\n",
    "\n",
    "# Analyze dataset families\n",
    "print(f\"\\nDataset Family Analysis:\")\n",
    "families = {}\n",
    "for dataset in available_datasets:\n",
    "    family = dataset.replace(\"lerobot/\", \"\").split('_')[0]\n",
    "    families[family] = families.get(family, 0) + 1\n",
    "\n",
    "sorted_families = sorted(families.items(), key=lambda x: x[1], reverse=True)\n",
    "for family, count in sorted_families[:10]:  # Show top 10 families\n",
    "    print(f\"  {family}: {count} dataset(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38741f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_metadata(dataset_name):\n",
    "    \"\"\"Get metadata without loading the full dataset\"\"\"\n",
    "    try:\n",
    "         \n",
    "        # Rate limiting\n",
    "        time.sleep(1.0)\n",
    "        \n",
    "        metadata = LeRobotDatasetMetadata(dataset_name)\n",
    "        \n",
    "        return {\n",
    "            'dataset_name': dataset_name,\n",
    "            'category': dataset_name.replace(\"lerobot/\", \"\").split('_')[0],\n",
    "            'num_episodes': metadata.total_episodes,\n",
    "            'total_samples': metadata.total_frames,\n",
    "            'fps': metadata.fps,\n",
    "            'robot_type': metadata.robot_type,\n",
    "            'camera_keys': metadata.camera_keys,\n",
    "            'features': list(metadata.features.keys()),\n",
    "            'has_images': len(metadata.camera_keys) > 0  \n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Error: {e}\")\n",
    "        return {\n",
    "            'dataset_name': dataset_name,\n",
    "            'category': dataset_name.replace(\"lerobot/\", \"\").split('_')[0],\n",
    "            'num_episodes': 'Error',\n",
    "            'total_samples': 'Error',\n",
    "            'fps': 'Error',\n",
    "            'robot_type': 'Error',\n",
    "            'camera_keys': [],\n",
    "            'features': [],\n",
    "            'has_images': False\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c88541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FRESH START ===\n",
      "Collecting metadata from all datasets...\n",
      "This may take a few minutes...\n",
      "Processing 1/103: lerobot/aloha_mobile_cabinet\n",
      "Processing 2/103: lerobot/aloha_mobile_chair\n",
      "Processing 3/103: lerobot/aloha_mobile_elevator\n",
      "Processing 4/103: lerobot/aloha_mobile_shrimp\n",
      "Processing 5/103: lerobot/aloha_mobile_wash_pan\n",
      "-------- Taking a break...\n",
      "Processing 6/103: lerobot/aloha_mobile_wipe_wine\n",
      "Processing 7/103: lerobot/aloha_sim_insertion_human\n",
      "Processing 8/103: lerobot/aloha_sim_insertion_human_image\n",
      "Processing 9/103: lerobot/aloha_sim_insertion_scripted\n",
      "Processing 10/103: lerobot/aloha_sim_insertion_scripted_image\n",
      "-------- Taking a break...\n",
      "Processing 11/103: lerobot/aloha_sim_transfer_cube_human\n",
      "Processing 12/103: lerobot/aloha_sim_transfer_cube_human_image\n",
      "Processing 13/103: lerobot/aloha_sim_transfer_cube_scripted\n",
      "Processing 14/103: lerobot/aloha_sim_transfer_cube_scripted_image\n",
      "Processing 15/103: lerobot/aloha_static_battery\n",
      "    Error: \n",
      "The dataset you requested (lerobot/aloha_static_battery) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/aloha_static_battery \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "-------- Taking a break...\n",
      "Processing 16/103: lerobot/aloha_static_candy\n",
      "Processing 17/103: lerobot/aloha_static_coffee\n",
      "Processing 18/103: lerobot/aloha_static_coffee_new\n",
      "Processing 19/103: lerobot/aloha_static_cups_open\n",
      "Processing 20/103: lerobot/aloha_static_fork_pick_up\n",
      "    Error: \n",
      "The dataset you requested (lerobot/aloha_static_fork_pick_up) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/aloha_static_fork_pick_up \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "-------- Taking a break...\n",
      "Processing 21/103: lerobot/aloha_static_pingpong_test\n",
      "Processing 22/103: lerobot/aloha_static_pro_pencil\n",
      "Processing 23/103: lerobot/aloha_static_screw_driver\n",
      "Processing 24/103: lerobot/aloha_static_tape\n",
      "    Error: \n",
      "The dataset you requested (lerobot/aloha_static_tape) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/aloha_static_tape \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 25/103: lerobot/aloha_static_thread_velcro\n",
      "    Error: \n",
      "The dataset you requested (lerobot/aloha_static_thread_velcro) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/aloha_static_thread_velcro \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "-------- Taking a break...\n",
      "Processing 26/103: lerobot/aloha_static_towel\n",
      "Processing 27/103: lerobot/aloha_static_vinh_cup\n",
      "Processing 28/103: lerobot/aloha_static_vinh_cup_left\n",
      "Processing 29/103: lerobot/aloha_static_ziploc_slide\n",
      "Processing 30/103: lerobot/asu_table_top\n",
      "-------- Taking a break...\n",
      "Processing 31/103: lerobot/austin_buds_dataset\n",
      "Processing 32/103: lerobot/austin_sailor_dataset\n",
      "Processing 33/103: lerobot/austin_sirius_dataset\n",
      "Processing 34/103: lerobot/berkeley_autolab_ur5\n",
      "Processing 35/103: lerobot/berkeley_cable_routing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/berkeley_cable_routing) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/berkeley_cable_routing\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Taking a break...\n",
      "Processing 36/103: lerobot/berkeley_fanuc_manipulation\n",
      "Processing 37/103: lerobot/berkeley_gnm_cory_hall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/berkeley_gnm_cory_hall) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/berkeley_gnm_cory_hall\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 38/103: lerobot/berkeley_gnm_recon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/berkeley_gnm_recon) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/berkeley_gnm_recon\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 39/103: lerobot/berkeley_gnm_sac_son\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/berkeley_gnm_sac_son) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/berkeley_gnm_sac_son\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 40/103: lerobot/berkeley_mvp\n",
      "-------- Taking a break...\n",
      "Processing 41/103: lerobot/berkeley_rpt\n",
      "Processing 42/103: lerobot/cmu_franka_exploration_dataset\n",
      "Processing 43/103: lerobot/cmu_play_fusion\n",
      "Processing 44/103: lerobot/cmu_stretch\n",
      "Processing 45/103: lerobot/columbia_cairlab_pusht_real\n",
      "-------- Taking a break...\n",
      "Processing 46/103: lerobot/conq_hose_manipulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/conq_hose_manipulation) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/conq_hose_manipulation\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 47/103: lerobot/dlr_edan_shared_control\n",
      "Processing 48/103: lerobot/dlr_sara_grid_clamp\n",
      "Processing 49/103: lerobot/dlr_sara_pour\n",
      "Processing 50/103: lerobot/droid_100\n",
      "-------- Taking a break...\n",
      "Processing 51/103: lerobot/fmb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/fmb) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/fmb\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 52/103: lerobot/iamlab_cmu_pickup_insert\n",
      "Processing 53/103: lerobot/imperialcollege_sawyer_wrist_cam\n",
      "Processing 54/103: lerobot/jaco_play\n",
      "Processing 55/103: lerobot/kaist_nonprehensile\n",
      "-------- Taking a break...\n",
      "Processing 56/103: lerobot/koch_pick_place_1_lego\n",
      "    Error: \n",
      "The dataset you requested (lerobot/koch_pick_place_1_lego) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/koch_pick_place_1_lego \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 57/103: lerobot/koch_pick_place_1_lego_raph\n",
      "    Error: \n",
      "The dataset you requested (lerobot/koch_pick_place_1_lego_raph) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/koch_pick_place_1_lego_raph \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 58/103: lerobot/koch_pick_place_5_lego\n",
      "    Error: \n",
      "The dataset you requested (lerobot/koch_pick_place_5_lego) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/koch_pick_place_5_lego \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 59/103: lerobot/koch_pick_place_5_lego_random_pose\n",
      "    Error: \n",
      "The dataset you requested (lerobot/koch_pick_place_5_lego_random_pose) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/koch_pick_place_5_lego_random_pose \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 60/103: lerobot/libero_10_image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/libero_10_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/libero_10_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Taking a break...\n",
      "Processing 61/103: lerobot/libero_goal_image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/libero_goal_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/libero_goal_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 62/103: lerobot/libero_object_image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/libero_object_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/libero_object_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 63/103: lerobot/libero_spatial_image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/libero_spatial_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/libero_spatial_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 64/103: lerobot/metaworld_mt50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/metaworld_mt50) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/metaworld_mt50\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 65/103: lerobot/metaworld_mt50_push_v2_image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/metaworld_mt50_push_v2_image) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/metaworld_mt50_push_v2_image\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- Taking a break...\n",
      "Processing 66/103: lerobot/nyu_door_opening_surprising_effectiveness\n",
      "Processing 67/103: lerobot/nyu_franka_play_dataset\n",
      "Processing 68/103: lerobot/nyu_rot_dataset\n",
      "Processing 69/103: lerobot/pusht\n",
      "Processing 70/103: lerobot/pusht_image\n",
      "-------- Taking a break...\n",
      "Processing 71/103: lerobot/pusht_keypoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/pusht_keypoints) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/pusht_keypoints\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 72/103: lerobot/roboturk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/roboturk) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/roboturk\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 73/103: lerobot/stanford_hydra_dataset\n",
      "Processing 74/103: lerobot/stanford_kuka_multimodal_dataset\n",
      "Processing 75/103: lerobot/stanford_robocook\n",
      "-------- Taking a break...\n",
      "Processing 76/103: lerobot/taco_play\n",
      "Processing 77/103: lerobot/test\n",
      "    Error: \n",
      "The dataset you requested (lerobot/test) is in 1.5 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/test \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 78/103: lerobot/tokyo_u_lsmo\n",
      "Processing 79/103: lerobot/toto\n",
      "Processing 80/103: lerobot/ucsd_kitchen_dataset\n",
      "-------- Taking a break...\n",
      "Processing 81/103: lerobot/ucsd_pick_and_place_dataset\n",
      "Processing 82/103: lerobot/uiuc_d3field\n",
      "    Error: \n",
      "The dataset you requested (lerobot/uiuc_d3field) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/uiuc_d3field \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "Processing 83/103: lerobot/umi_cup_in_the_wild\n",
      "Processing 84/103: lerobot/unitreeh1_fold_clothes\n",
      "Processing 85/103: lerobot/unitreeh1_rearrange_objects\n",
      "-------- Taking a break...\n",
      "Processing 86/103: lerobot/unitreeh1_two_robot_greeting\n",
      "Processing 87/103: lerobot/unitreeh1_warehouse\n",
      "Processing 88/103: lerobot/usc_cloth_sim\n",
      "Processing 89/103: lerobot/utaustin_mutex\n",
      "Processing 90/103: lerobot/utokyo_pr2_opening_fridge\n",
      "-------- Taking a break...\n",
      "Processing 91/103: lerobot/utokyo_pr2_tabletop_manipulation\n",
      "Processing 92/103: lerobot/utokyo_saytap\n",
      "Processing 93/103: lerobot/utokyo_xarm_bimanual\n",
      "Processing 94/103: lerobot/utokyo_xarm_pick_and_place\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "The dataset you requested (lerobot/utokyo_xarm_pick_and_place) is in 2.0 format.\n",
      "While current version of LeRobot is backward-compatible with it, the version of your dataset still uses global\n",
      "stats instead of per-episode stats. Update your dataset stats to the new format using this command:\n",
      "```\n",
      "python lerobot/common/datasets/v21/convert_dataset_v20_to_v21.py --repo-id=lerobot/utokyo_xarm_pick_and_place\n",
      "```\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 95/103: lerobot/viola\n",
      "    Error: \n",
      "The dataset you requested (lerobot/viola) is in 1.6 format.\n",
      "\n",
      "We introduced a new format since v2.0 which is not backward compatible with v1.x.\n",
      "Please, use our conversion script. Modify the following command with your own task description:\n",
      "```\n",
      "python lerobot/common/datasets/v2/convert_dataset_v1_to_v2.py \\\n",
      "    --repo-id lerobot/viola \\\n",
      "    --single-task \"TASK DESCRIPTION.\"  # <---- /!\\ Replace TASK DESCRIPTION /!\\\n",
      "```\n",
      "\n",
      "A few examples to replace TASK DESCRIPTION: \"Pick up the blue cube and place it into the bin.\", \"Insert the\n",
      "peg into the socket.\", \"Slide open the ziploc bag.\", \"Take the elevator to the 1st floor.\", \"Open the top\n",
      "cabinet, store the pot inside it then close the cabinet.\", \"Push the T-shaped block onto the T-shaped\n",
      "target.\", \"Grab the spray paint on the shelf and place it in the bin on top of the robot dog.\", \"Fold the\n",
      "sweatshirt.\", ...\n",
      "\n",
      "If you encounter a problem, contact LeRobot maintainers on [Discord](https://discord.com/invite/s3KuuzsPFb)\n",
      "or open an [issue on GitHub](https://github.com/huggingface/lerobot/issues/new/choose).\n",
      "\n",
      "-------- Taking a break...\n",
      "Processing 96/103: lerobot/xarm_lift_medium\n",
      "Processing 97/103: lerobot/xarm_lift_medium_image\n",
      "Processing 98/103: lerobot/xarm_lift_medium_replay\n",
      "Processing 99/103: lerobot/xarm_lift_medium_replay_image\n",
      "Processing 100/103: lerobot/xarm_push_medium\n",
      "-------- Taking a break...\n",
      "Processing 101/103: lerobot/xarm_push_medium_image\n",
      "Processing 102/103: lerobot/xarm_push_medium_replay\n",
      "Processing 103/103: lerobot/xarm_push_medium_replay_image\n",
      "\n",
      "=== PROCESSING COMPLETE ===\n",
      "Collected metadata for 103 datasets\n",
      "Successfully processed: 92\n"
     ]
    }
   ],
   "source": [
    "# Aggressive output clearing and fresh restart\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Clear all output and restart\n",
    "clear_output(wait=True)\n",
    "\n",
    "# Reset any problematic variables\n",
    "if 'dataset_metrics' in globals():\n",
    "    del dataset_metrics\n",
    "if 'df_metrics' in globals():\n",
    "    del df_metrics\n",
    "\n",
    "print(\"=== FRESH START ===\")\n",
    "print(\"Collecting metadata from all datasets...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Initialize completely fresh list\n",
    "dataset_metrics = []\n",
    "\n",
    "# Process all datasets\n",
    "datasets_to_process = available_datasets\n",
    "\n",
    "for i, dataset_name in enumerate(datasets_to_process):\n",
    "    print(f\"Processing {i+1}/{len(datasets_to_process)}: {dataset_name}\")\n",
    "    \n",
    "    metadata = get_dataset_metadata(dataset_name)\n",
    "    if metadata:\n",
    "        dataset_metrics.append(metadata)\n",
    "        \n",
    "    # Brief pause every 5 datasets\n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"-------- Taking a break...\")\n",
    "        time.sleep(2)\n",
    "\n",
    "# Create DataFrame\n",
    "df_metrics = pd.DataFrame(dataset_metrics)\n",
    "\n",
    "print(f\"\\n=== PROCESSING COMPLETE ===\")\n",
    "print(f\"Collected metadata for {len(df_metrics)} datasets\")\n",
    "print(f\"Successfully processed: {len([d for d in dataset_metrics if d['num_episodes'] != 'Error'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18ad92e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Analysis Summary\n",
      "==================================================\n",
      "Dataset Overview:\n",
      "  Total Processed: 103\n",
      "  Successfully Loaded: 92\n",
      "  With Camera Data: 91\n",
      "  Total Episodes: 65,318\n",
      "  Total Samples: 7,823,344\n",
      "\n",
      "Category Summary:\n",
      "           total  with_cameras\n",
      "category                      \n",
      "aloha         29            25\n",
      "berkeley       8             8\n",
      "xarm           8             8\n",
      "utokyo         5             5\n",
      "koch           4             0\n",
      "unitreeh1      4             4\n",
      "libero         4             4\n",
      "austin         3             3\n",
      "stanford       3             3\n",
      "cmu            3             3\n",
      "\n",
      "Sample datasets with cameras:\n",
      "  aloha_mobile_cabinet: 85 episodes, 3 cameras\n",
      "  aloha_mobile_chair: 55 episodes, 3 cameras\n",
      "  aloha_mobile_elevator: 20 episodes, 3 cameras\n",
      "  aloha_mobile_shrimp: 18 episodes, 3 cameras\n",
      "  aloha_mobile_wash_pan: 50 episodes, 3 cameras\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Analysis Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Basic statistics\n",
    "successful_df = df_metrics[df_metrics['num_episodes'] != 'Error']\n",
    "total_datasets = len(df_metrics)\n",
    "successful_loads = len(successful_df)\n",
    "datasets_with_images = len(df_metrics[df_metrics['has_images'] == True])\n",
    "\n",
    "print(f\"Dataset Overview:\")\n",
    "print(f\"  Total Processed: {total_datasets}\")\n",
    "print(f\"  Successfully Loaded: {successful_loads}\")\n",
    "print(f\"  With Camera Data: {datasets_with_images}\")\n",
    "\n",
    "if len(successful_df) > 0:\n",
    "    total_episodes = successful_df['num_episodes'].sum()\n",
    "    total_samples = successful_df['total_samples'].sum()\n",
    "    print(f\"  Total Episodes: {total_episodes:,}\")\n",
    "    print(f\"  Total Samples: {total_samples:,}\")\n",
    "\n",
    "# Category breakdown\n",
    "print(f\"\\nCategory Summary:\")\n",
    "category_summary = df_metrics.groupby('category').agg({\n",
    "    'dataset_name': 'count',\n",
    "    'has_images': lambda x: sum(1 for val in x if val == True)\n",
    "}).rename(columns={'dataset_name': 'total', 'has_images': 'with_cameras'})\n",
    "\n",
    "category_summary = category_summary.sort_values('total', ascending=False)\n",
    "print(category_summary.head(10).to_string())\n",
    "\n",
    "# Show sample of datasets with cameras\n",
    "if datasets_with_images > 0:\n",
    "    print(f\"\\nSample datasets with cameras:\")\n",
    "    sample_with_cameras = df_metrics[df_metrics['has_images'] == True].head(5)\n",
    "    for _, row in sample_with_cameras.iterrows():\n",
    "        dataset_short = row['dataset_name'].replace('lerobot/', '')\n",
    "        cameras = len(row['camera_keys'])\n",
    "        episodes = row['num_episodes'] if row['num_episodes'] != 'Error' else 'Unknown'\n",
    "        print(f\"  {dataset_short}: {episodes} episodes, {cameras} cameras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40cbebce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video download functions ready!\n"
     ]
    }
   ],
   "source": [
    "def download_episode_videos(datasets_df, videos_folder=\"videos\", max_datasets=None, max_workers=3):\n",
    "    \"\"\"Download episode videos from datasets with parallel processing\"\"\"\n",
    "    \n",
    "    print(f\"Starting video download process...\")\n",
    "    \n",
    "    # Filter to datasets with images only\n",
    "    datasets_with_images = datasets_df[\n",
    "        (datasets_df['has_images'] == True) & \n",
    "        (datasets_df['num_episodes'] != 'Error')\n",
    "    ].copy()\n",
    "    \n",
    "    if max_datasets:\n",
    "        datasets_with_images = datasets_with_images.head(max_datasets)\n",
    "    \n",
    "    print(f\"Target: {len(datasets_with_images)} datasets with cameras\")\n",
    "    \n",
    "    # Create videos directory\n",
    "    os.makedirs(videos_folder, exist_ok=True)\n",
    "    \n",
    "    downloaded_videos = []\n",
    "    failed_videos = []\n",
    "    \n",
    "    def download_single_video(args):\n",
    "        dataset_name, camera_key, dataset_folder = args\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        \n",
    "        try:\n",
    "            # Create dataset folder\n",
    "            os.makedirs(dataset_folder, exist_ok=True)\n",
    "            \n",
    "            # Try to download episode 0 video\n",
    "            video_url = f\"https://huggingface.co/datasets/{dataset_name}/resolve/main/videos/chunk-000/{camera_key}/episode_000000.mp4\"\n",
    "            video_path = os.path.join(dataset_folder, f\"{camera_key.replace('.', '_')}_episode_000000.mp4\")\n",
    "            \n",
    "            if os.path.exists(video_path):\n",
    "                file_size = os.path.getsize(video_path)\n",
    "                return {\n",
    "                    'status': 'exists',\n",
    "                    'dataset': dataset_short,\n",
    "                    'camera': camera_key,\n",
    "                    'path': video_path,\n",
    "                    'size': file_size\n",
    "                }\n",
    "            \n",
    "            # Download the video\n",
    "            response = requests.get(video_url, timeout=30, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                with open(video_path, 'wb') as f:\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                \n",
    "                file_size = os.path.getsize(video_path)\n",
    "                return {\n",
    "                    'status': 'downloaded',\n",
    "                    'dataset': dataset_short,\n",
    "                    'camera': camera_key,\n",
    "                    'path': video_path,\n",
    "                    'size': file_size\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'status': 'failed',\n",
    "                    'dataset': dataset_short,\n",
    "                    'camera': camera_key,\n",
    "                    'error': f\"HTTP {response.status_code}\"\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'failed',\n",
    "                'dataset': dataset_short,\n",
    "                'camera': camera_key,\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    # Prepare download tasks\n",
    "    download_tasks = []\n",
    "    for _, row in datasets_with_images.iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        dataset_folder = os.path.join(videos_folder, dataset_short)\n",
    "        \n",
    "        # Download from all cameras\n",
    "        for camera_key in row['camera_keys']:\n",
    "            download_tasks.append((dataset_name, camera_key, dataset_folder))\n",
    "    \n",
    "    # Execute downloads in parallel\n",
    "    print(f\"Downloading {len(download_tasks)} videos using {max_workers} workers...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_task = {executor.submit(download_single_video, task): task for task in download_tasks}\n",
    "        \n",
    "        for i, future in enumerate(as_completed(future_to_task)):\n",
    "            result = future.result()\n",
    "            \n",
    "            if result['status'] in ['downloaded', 'exists']:\n",
    "                downloaded_videos.append(result)\n",
    "                status_text = \"Downloaded\" if result['status'] == 'downloaded' else \"Found\"\n",
    "                size_mb = result['size'] / (1024*1024)\n",
    "                print(f\"  {status_text}: {result['dataset']}/{result['camera']} ({size_mb:.1f}MB)\")\n",
    "            else:\n",
    "                failed_videos.append(result)\n",
    "                print(f\"  Failed: {result['dataset']}/{result['camera']}: {result['error']}\")\n",
    "            \n",
    "            # Progress update\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"    Progress: {i+1}/{len(download_tasks)} completed\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nDownload Summary:\")\n",
    "    print(f\"  Successfully downloaded: {len([v for v in downloaded_videos if v['status'] == 'downloaded'])}\")\n",
    "    print(f\"  Already existed: {len([v for v in downloaded_videos if v['status'] == 'exists'])}\")\n",
    "    print(f\"  Failed: {len(failed_videos)}\")\n",
    "    \n",
    "    total_size = sum(v.get('size', 0) for v in downloaded_videos)\n",
    "    print(f\"  Total size: {total_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    return downloaded_videos, failed_videos\n",
    "\n",
    "print(\"Video download functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a5ba8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video download process...\n",
      "Starting video download process...\n",
      "Target: 91 datasets with cameras\n",
      "Downloading 175 videos using 3 workers...\n",
      "  Failed: aloha_mobile_cabinet/observation.images.cam_right_wrist: HTTP 404\n",
      "  Failed: aloha_mobile_cabinet/observation.images.cam_left_wrist: HTTP 404\n",
      "  Failed: aloha_mobile_cabinet/observation.images.cam_high: HTTP 404\n",
      "  Failed: aloha_mobile_cabinet/observation.images.cam_right_wrist: HTTP 404\n",
      "  Failed: aloha_mobile_cabinet/observation.images.cam_left_wrist: HTTP 404\n",
      "  Failed: aloha_mobile_cabinet/observation.images.cam_high: HTTP 404\n",
      "  Downloaded: aloha_mobile_chair/observation.images.cam_right_wrist (9.1MB)\n",
      "  Downloaded: aloha_mobile_chair/observation.images.cam_right_wrist (9.1MB)\n",
      "  Downloaded: aloha_mobile_chair/observation.images.cam_left_wrist (9.8MB)\n",
      "  Downloaded: aloha_mobile_chair/observation.images.cam_left_wrist (9.8MB)\n",
      "  Downloaded: aloha_mobile_elevator/observation.images.cam_high (9.2MB)\n",
      "  Downloaded: aloha_mobile_elevator/observation.images.cam_high (9.2MB)\n",
      "  Downloaded: aloha_mobile_chair/observation.images.cam_high (15.3MB)\n",
      "  Downloaded: aloha_mobile_chair/observation.images.cam_high (15.3MB)\n",
      "  Downloaded: aloha_mobile_elevator/observation.images.cam_right_wrist (9.5MB)\n",
      "  Downloaded: aloha_mobile_elevator/observation.images.cam_right_wrist (9.5MB)\n",
      "  Downloaded: aloha_mobile_elevator/observation.images.cam_left_wrist (8.5MB)\n",
      "  Downloaded: aloha_mobile_elevator/observation.images.cam_left_wrist (8.5MB)\n",
      "  Downloaded: aloha_mobile_shrimp/observation.images.cam_right_wrist (16.8MB)\n",
      "    Progress: 10/175 completed\n",
      "  Downloaded: aloha_mobile_shrimp/observation.images.cam_right_wrist (16.8MB)\n",
      "    Progress: 10/175 completed\n",
      "  Downloaded: aloha_mobile_shrimp/observation.images.cam_high (33.5MB)\n",
      "  Downloaded: aloha_mobile_shrimp/observation.images.cam_high (33.5MB)\n",
      "  Downloaded: aloha_mobile_wash_pan/observation.images.cam_left_wrist (6.9MB)\n",
      "  Downloaded: aloha_mobile_wash_pan/observation.images.cam_left_wrist (6.9MB)\n",
      "  Downloaded: aloha_mobile_wash_pan/observation.images.cam_right_wrist (5.7MB)\n",
      "  Downloaded: aloha_mobile_wash_pan/observation.images.cam_right_wrist (5.7MB)\n",
      "  Downloaded: aloha_mobile_wipe_wine/observation.images.cam_high (11.7MB)\n",
      "  Downloaded: aloha_mobile_shrimp/observation.images.cam_left_wrist (19.4MB)\n",
      "  Downloaded: aloha_mobile_wipe_wine/observation.images.cam_high (11.7MB)\n",
      "  Downloaded: aloha_mobile_shrimp/observation.images.cam_left_wrist (19.4MB)\n",
      "  Downloaded: aloha_mobile_wash_pan/observation.images.cam_high (10.5MB)\n",
      "  Downloaded: aloha_mobile_wash_pan/observation.images.cam_high (10.5MB)\n",
      "  Failed: aloha_sim_insertion_human/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_insertion_human/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_insertion_human_image/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_insertion_human_image/observation.images.top: HTTP 404\n",
      "  Downloaded: aloha_mobile_wipe_wine/observation.images.cam_left_wrist (6.1MB)\n",
      "  Failed: aloha_sim_insertion_scripted/observation.images.top: HTTP 404\n",
      "    Progress: 20/175 completed\n",
      "  Downloaded: aloha_mobile_wipe_wine/observation.images.cam_left_wrist (6.1MB)\n",
      "  Failed: aloha_sim_insertion_scripted/observation.images.top: HTTP 404\n",
      "    Progress: 20/175 completed\n",
      "  Failed: aloha_sim_insertion_scripted_image/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_transfer_cube_human/observation.images.top: HTTP 404\n",
      "  Downloaded: aloha_mobile_wipe_wine/observation.images.cam_right_wrist (7.1MB)\n",
      "  Failed: aloha_sim_insertion_scripted_image/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_transfer_cube_human/observation.images.top: HTTP 404\n",
      "  Downloaded: aloha_mobile_wipe_wine/observation.images.cam_right_wrist (7.1MB)\n",
      "  Failed: aloha_sim_transfer_cube_human_image/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_transfer_cube_scripted_image/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_transfer_cube_scripted/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_transfer_cube_human_image/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_transfer_cube_scripted_image/observation.images.top: HTTP 404\n",
      "  Failed: aloha_sim_transfer_cube_scripted/observation.images.top: HTTP 404\n",
      "  Downloaded: aloha_static_candy/observation.images.cam_left_wrist (3.9MB)\n",
      "  Downloaded: aloha_static_candy/observation.images.cam_left_wrist (3.9MB)\n",
      "  Downloaded: aloha_static_candy/observation.images.cam_low (3.9MB)\n",
      "  Downloaded: aloha_static_candy/observation.images.cam_low (3.9MB)\n",
      "  Downloaded: aloha_static_candy/observation.images.cam_high (4.9MB)\n",
      "  Downloaded: aloha_static_candy/observation.images.cam_high (4.9MB)\n",
      "  Downloaded: aloha_static_candy/observation.images.cam_right_wrist (4.0MB)\n",
      "    Progress: 30/175 completed\n",
      "  Downloaded: aloha_static_candy/observation.images.cam_right_wrist (4.0MB)\n",
      "    Progress: 30/175 completed\n",
      "  Downloaded: aloha_static_coffee/observation.images.cam_low (7.0MB)\n",
      "  Downloaded: aloha_static_coffee/observation.images.cam_low (7.0MB)\n",
      "  Downloaded: aloha_static_coffee/observation.images.cam_right_wrist (6.2MB)\n",
      "  Downloaded: aloha_static_coffee/observation.images.cam_right_wrist (6.2MB)\n",
      "  Downloaded: aloha_static_coffee/observation.images.cam_left_wrist (6.0MB)\n",
      "  Downloaded: aloha_static_coffee/observation.images.cam_left_wrist (6.0MB)\n",
      "  Downloaded: aloha_static_coffee_new/observation.images.cam_high (12.9MB)\n",
      "  Downloaded: aloha_static_coffee_new/observation.images.cam_high (12.9MB)\n",
      "  Downloaded: aloha_static_coffee/observation.images.cam_high (9.5MB)\n",
      "  Downloaded: aloha_static_coffee_new/observation.images.cam_left_wrist (7.9MB)\n",
      "  Downloaded: aloha_static_coffee/observation.images.cam_high (9.5MB)\n",
      "  Downloaded: aloha_static_coffee_new/observation.images.cam_left_wrist (7.9MB)\n",
      "  Downloaded: aloha_static_cups_open/observation.images.cam_high (2.7MB)\n",
      "  Downloaded: aloha_static_cups_open/observation.images.cam_high (2.7MB)\n",
      "  Downloaded: aloha_static_cups_open/observation.images.cam_left_wrist (1.8MB)\n",
      "  Downloaded: aloha_static_cups_open/observation.images.cam_left_wrist (1.8MB)\n",
      "  Downloaded: aloha_static_cups_open/observation.images.cam_low (2.2MB)\n",
      "  Downloaded: aloha_static_cups_open/observation.images.cam_low (2.2MB)\n",
      "  Downloaded: aloha_static_coffee_new/observation.images.cam_low (9.2MB)\n",
      "    Progress: 40/175 completed\n",
      "  Downloaded: aloha_static_coffee_new/observation.images.cam_low (9.2MB)\n",
      "    Progress: 40/175 completed\n",
      "  Downloaded: aloha_static_cups_open/observation.images.cam_right_wrist (2.7MB)\n",
      "  Downloaded: aloha_static_cups_open/observation.images.cam_right_wrist (2.7MB)\n",
      "  Downloaded: aloha_static_coffee_new/observation.images.cam_right_wrist (9.2MB)\n",
      "  Downloaded: aloha_static_pingpong_test/observation.images.cam_high (4.9MB)\n",
      "  Downloaded: aloha_static_coffee_new/observation.images.cam_right_wrist (9.2MB)\n",
      "  Downloaded: aloha_static_pingpong_test/observation.images.cam_high (4.9MB)\n",
      "  Downloaded: aloha_static_pingpong_test/observation.images.cam_left_wrist (4.5MB)\n",
      "  Downloaded: aloha_static_pingpong_test/observation.images.cam_left_wrist (4.5MB)\n",
      "  Downloaded: aloha_static_pingpong_test/observation.images.cam_low (3.2MB)\n",
      "  Downloaded: aloha_static_pingpong_test/observation.images.cam_low (3.2MB)\n",
      "  Downloaded: aloha_static_pingpong_test/observation.images.cam_right_wrist (4.3MB)\n",
      "  Downloaded: aloha_static_pingpong_test/observation.images.cam_right_wrist (4.3MB)\n",
      "  Downloaded: aloha_static_pro_pencil/observation.images.cam_high (5.4MB)\n",
      "  Downloaded: aloha_static_pro_pencil/observation.images.cam_high (5.4MB)\n",
      "  Downloaded: aloha_static_pro_pencil/observation.images.cam_low (4.0MB)\n",
      "  Downloaded: aloha_static_pro_pencil/observation.images.cam_low (4.0MB)\n",
      "  Downloaded: aloha_static_pro_pencil/observation.images.cam_left_wrist (5.3MB)\n",
      "  Downloaded: aloha_static_pro_pencil/observation.images.cam_left_wrist (5.3MB)\n",
      "  Downloaded: aloha_static_screw_driver/observation.images.cam_high (2.9MB)\n",
      "    Progress: 50/175 completed\n",
      "  Downloaded: aloha_static_screw_driver/observation.images.cam_high (2.9MB)\n",
      "    Progress: 50/175 completed\n",
      "  Downloaded: aloha_static_pro_pencil/observation.images.cam_right_wrist (5.3MB)\n",
      "  Downloaded: aloha_static_pro_pencil/observation.images.cam_right_wrist (5.3MB)\n",
      "  Downloaded: aloha_static_screw_driver/observation.images.cam_low (2.0MB)\n",
      "  Downloaded: aloha_static_screw_driver/observation.images.cam_low (2.0MB)\n",
      "  Downloaded: aloha_static_screw_driver/observation.images.cam_right_wrist (2.6MB)\n",
      "  Downloaded: aloha_static_screw_driver/observation.images.cam_right_wrist (2.6MB)\n",
      "  Downloaded: aloha_static_screw_driver/observation.images.cam_left_wrist (2.4MB)\n",
      "  Downloaded: aloha_static_screw_driver/observation.images.cam_left_wrist (2.4MB)\n",
      "  Downloaded: aloha_static_towel/observation.images.cam_high (4.0MB)\n",
      "  Downloaded: aloha_static_towel/observation.images.cam_high (4.0MB)\n",
      "  Downloaded: aloha_static_towel/observation.images.cam_low (2.6MB)\n",
      "  Downloaded: aloha_static_towel/observation.images.cam_low (2.6MB)\n",
      "  Downloaded: aloha_static_towel/observation.images.cam_left_wrist (3.2MB)\n",
      "  Downloaded: aloha_static_towel/observation.images.cam_left_wrist (3.2MB)\n",
      "  Downloaded: aloha_static_vinh_cup/observation.images.cam_high (3.3MB)\n",
      "  Downloaded: aloha_static_vinh_cup/observation.images.cam_high (3.3MB)\n",
      "  Downloaded: aloha_static_vinh_cup/observation.images.cam_left_wrist (2.3MB)\n",
      "  Downloaded: aloha_static_vinh_cup/observation.images.cam_left_wrist (2.3MB)\n",
      "  Downloaded: aloha_static_towel/observation.images.cam_right_wrist (2.0MB)\n",
      "    Progress: 60/175 completed\n",
      "  Downloaded: aloha_static_towel/observation.images.cam_right_wrist (2.0MB)\n",
      "    Progress: 60/175 completed\n",
      "  Downloaded: aloha_static_vinh_cup/observation.images.cam_low (2.5MB)\n",
      "  Downloaded: aloha_static_vinh_cup/observation.images.cam_low (2.5MB)\n",
      "  Downloaded: aloha_static_vinh_cup/observation.images.cam_right_wrist (3.6MB)\n",
      "  Downloaded: aloha_static_vinh_cup/observation.images.cam_right_wrist (3.6MB)\n",
      "  Downloaded: aloha_static_vinh_cup_left/observation.images.cam_high (3.3MB)\n",
      "  Downloaded: aloha_static_vinh_cup_left/observation.images.cam_high (3.3MB)\n",
      "  Downloaded: aloha_static_vinh_cup_left/observation.images.cam_left_wrist (2.6MB)\n",
      "  Downloaded: aloha_static_vinh_cup_left/observation.images.cam_left_wrist (2.6MB)\n",
      "  Downloaded: aloha_static_vinh_cup_left/observation.images.cam_low (2.6MB)\n",
      "  Downloaded: aloha_static_vinh_cup_left/observation.images.cam_low (2.6MB)\n",
      "  Downloaded: aloha_static_vinh_cup_left/observation.images.cam_right_wrist (2.6MB)\n",
      "  Downloaded: aloha_static_vinh_cup_left/observation.images.cam_right_wrist (2.6MB)\n",
      "  Downloaded: aloha_static_ziploc_slide/observation.images.cam_high (2.5MB)\n",
      "  Downloaded: aloha_static_ziploc_slide/observation.images.cam_left_wrist (1.7MB)\n",
      "  Downloaded: aloha_static_ziploc_slide/observation.images.cam_high (2.5MB)\n",
      "  Downloaded: aloha_static_ziploc_slide/observation.images.cam_left_wrist (1.7MB)\n",
      "  Downloaded: asu_table_top/observation.images.image (0.6MB)\n",
      "  Downloaded: asu_table_top/observation.images.image (0.6MB)\n",
      "  Downloaded: aloha_static_ziploc_slide/observation.images.cam_right_wrist (1.7MB)\n",
      "    Progress: 70/175 completed\n",
      "  Downloaded: aloha_static_ziploc_slide/observation.images.cam_right_wrist (1.7MB)\n",
      "    Progress: 70/175 completed\n",
      "  Downloaded: aloha_static_ziploc_slide/observation.images.cam_low (3.2MB)\n",
      "  Downloaded: aloha_static_ziploc_slide/observation.images.cam_low (3.2MB)\n",
      "  Downloaded: austin_buds_dataset/observation.images.wrist_image (0.3MB)\n",
      "  Downloaded: austin_buds_dataset/observation.images.wrist_image (0.3MB)\n",
      "  Downloaded: austin_buds_dataset/observation.images.image (1.7MB)\n",
      "  Downloaded: austin_buds_dataset/observation.images.image (1.7MB)\n",
      "  Downloaded: austin_sailor_dataset/observation.images.wrist_image (1.2MB)\n",
      "  Downloaded: austin_sailor_dataset/observation.images.wrist_image (1.2MB)\n",
      "  Downloaded: austin_sirius_dataset/observation.images.image (0.3MB)\n",
      "  Downloaded: austin_sirius_dataset/observation.images.image (0.3MB)\n",
      "  Downloaded: austin_sirius_dataset/observation.images.wrist_image (0.3MB)\n",
      "  Downloaded: austin_sirius_dataset/observation.images.wrist_image (0.3MB)\n",
      "  Downloaded: austin_sailor_dataset/observation.images.image (3.9MB)\n",
      "  Downloaded: austin_sailor_dataset/observation.images.image (3.9MB)\n",
      "  Downloaded: berkeley_autolab_ur5/observation.images.hand_image (0.2MB)\n",
      "  Downloaded: berkeley_autolab_ur5/observation.images.hand_image (0.2MB)\n",
      "  Downloaded: berkeley_autolab_ur5/observation.images.image (1.1MB)\n",
      "  Downloaded: berkeley_autolab_ur5/observation.images.image (1.1MB)\n",
      "  Downloaded: berkeley_cable_routing/observation.images.top_image (0.1MB)\n",
      "    Progress: 80/175 completed\n",
      "  Downloaded: berkeley_cable_routing/observation.images.top_image (0.1MB)\n",
      "    Progress: 80/175 completed\n",
      "  Downloaded: berkeley_cable_routing/observation.images.wrist225_image (0.0MB)\n",
      "  Downloaded: berkeley_cable_routing/observation.images.wrist225_image (0.0MB)\n",
      "  Downloaded: berkeley_cable_routing/observation.images.wrist45_image (0.0MB)\n",
      "  Downloaded: berkeley_autolab_ur5/observation.images.image_with_depth (8.8MB)\n",
      "  Downloaded: berkeley_cable_routing/observation.images.image (0.0MB)\n",
      "  Downloaded: berkeley_cable_routing/observation.images.wrist45_image (0.0MB)\n",
      "  Downloaded: berkeley_autolab_ur5/observation.images.image_with_depth (8.8MB)\n",
      "  Downloaded: berkeley_cable_routing/observation.images.image (0.0MB)\n",
      "  Downloaded: berkeley_gnm_cory_hall/observation.images.image (0.0MB)\n",
      "  Downloaded: berkeley_gnm_cory_hall/observation.images.image (0.0MB)\n",
      "  Downloaded: berkeley_fanuc_manipulation/observation.images.wrist_image (0.4MB)\n",
      "  Downloaded: berkeley_fanuc_manipulation/observation.images.image (0.9MB)\n",
      "  Downloaded: berkeley_fanuc_manipulation/observation.images.wrist_image (0.4MB)\n",
      "  Downloaded: berkeley_fanuc_manipulation/observation.images.image (0.9MB)\n",
      "  Downloaded: berkeley_gnm_recon/observation.images.image (0.2MB)\n",
      "  Downloaded: berkeley_gnm_recon/observation.images.image (0.2MB)\n",
      "  Downloaded: berkeley_gnm_sac_son/observation.images.image (0.0MB)\n",
      "  Downloaded: berkeley_gnm_sac_son/observation.images.image (0.0MB)\n",
      "  Downloaded: cmu_franka_exploration_dataset/observation.images.image (0.0MB)\n",
      "    Progress: 90/175 completed\n",
      "  Downloaded: cmu_franka_exploration_dataset/observation.images.image (0.0MB)\n",
      "    Progress: 90/175 completed\n",
      "  Downloaded: berkeley_mvp/observation.images.hand_image (0.5MB)\n",
      "  Downloaded: berkeley_mvp/observation.images.hand_image (0.5MB)\n",
      "  Downloaded: berkeley_rpt/observation.images.hand_image (1.1MB)\n",
      "  Downloaded: cmu_franka_exploration_dataset/observation.images.highres_image (0.1MB)\n",
      "  Downloaded: berkeley_rpt/observation.images.hand_image (1.1MB)\n",
      "  Downloaded: cmu_franka_exploration_dataset/observation.images.highres_image (0.1MB)\n",
      "  Downloaded: cmu_play_fusion/observation.images.image (0.5MB)\n",
      "  Downloaded: cmu_play_fusion/observation.images.image (0.5MB)\n",
      "  Downloaded: columbia_cairlab_pusht_real/observation.images.wrist_image (0.2MB)\n",
      "  Downloaded: cmu_stretch/observation.images.image (0.3MB)\n",
      "  Downloaded: columbia_cairlab_pusht_real/observation.images.wrist_image (0.2MB)\n",
      "  Downloaded: cmu_stretch/observation.images.image (0.3MB)\n",
      "  Downloaded: columbia_cairlab_pusht_real/observation.images.image (0.6MB)\n",
      "  Downloaded: columbia_cairlab_pusht_real/observation.images.image (0.6MB)\n",
      "  Downloaded: conq_hose_manipulation/observation.images.frontright_fisheye_image (0.6MB)\n",
      "  Downloaded: conq_hose_manipulation/observation.images.frontright_fisheye_image (0.6MB)\n",
      "  Downloaded: conq_hose_manipulation/observation.images.frontleft_fisheye_image (0.6MB)\n",
      "  Downloaded: conq_hose_manipulation/observation.images.hand_color_image (1.0MB)\n",
      "    Progress: 100/175 completed\n",
      "  Downloaded: conq_hose_manipulation/observation.images.frontleft_fisheye_image (0.6MB)\n",
      "  Downloaded: conq_hose_manipulation/observation.images.hand_color_image (1.0MB)\n",
      "    Progress: 100/175 completed\n",
      "  Downloaded: dlr_edan_shared_control/observation.images.image (1.1MB)\n",
      "  Downloaded: dlr_edan_shared_control/observation.images.image (1.1MB)\n",
      "  Downloaded: dlr_sara_grid_clamp/observation.images.image (0.9MB)\n",
      "  Downloaded: dlr_sara_grid_clamp/observation.images.image (0.9MB)\n",
      "  Downloaded: dlr_sara_pour/observation.images.image (2.3MB)\n",
      "  Downloaded: dlr_sara_pour/observation.images.image (2.3MB)\n",
      "  Downloaded: droid_100/observation.images.exterior_image_1_left (1.3MB)\n",
      "  Downloaded: droid_100/observation.images.exterior_image_1_left (1.3MB)\n",
      "  Downloaded: droid_100/observation.images.wrist_image_left (0.6MB)\n",
      "  Downloaded: droid_100/observation.images.wrist_image_left (0.6MB)\n",
      "  Downloaded: fmb/observation.images.image_side_1 (0.3MB)\n",
      "  Downloaded: fmb/observation.images.image_side_1 (0.3MB)\n",
      "  Downloaded: fmb/observation.images.image_side_2 (0.3MB)\n",
      "  Downloaded: fmb/observation.images.image_side_2 (0.3MB)\n",
      "  Downloaded: droid_100/observation.images.exterior_image_2_left (1.4MB)\n",
      "  Downloaded: droid_100/observation.images.exterior_image_2_left (1.4MB)\n",
      "  Downloaded: fmb/observation.images.image_wrist_1 (0.4MB)\n",
      "  Downloaded: fmb/observation.images.image_wrist_1 (0.4MB)\n",
      "  Downloaded: fmb/observation.images.image_wrist_2 (0.4MB)\n",
      "    Progress: 110/175 completed\n",
      "  Downloaded: fmb/observation.images.image_wrist_2 (0.4MB)\n",
      "    Progress: 110/175 completed\n",
      "  Downloaded: imperialcollege_sawyer_wrist_cam/observation.images.image (0.0MB)\n",
      "  Downloaded: imperialcollege_sawyer_wrist_cam/observation.images.image (0.0MB)\n",
      "  Downloaded: iamlab_cmu_pickup_insert/observation.images.wrist_image (1.0MB)\n",
      "  Downloaded: iamlab_cmu_pickup_insert/observation.images.wrist_image (1.0MB)\n",
      "  Downloaded: iamlab_cmu_pickup_insert/observation.images.image (4.1MB)\n",
      "  Downloaded: iamlab_cmu_pickup_insert/observation.images.image (4.1MB)\n",
      "  Downloaded: imperialcollege_sawyer_wrist_cam/observation.images.wrist_image (0.0MB)\n",
      "  Downloaded: imperialcollege_sawyer_wrist_cam/observation.images.wrist_image (0.0MB)\n",
      "  Downloaded: jaco_play/observation.images.image_wrist (0.2MB)\n",
      "  Downloaded: jaco_play/observation.images.image_wrist (0.2MB)\n",
      "  Failed: libero_10_image/observation.images.image: HTTP 404\n",
      "  Failed: libero_10_image/observation.images.image: HTTP 404\n",
      "  Downloaded: kaist_nonprehensile/observation.images.image (0.9MB)\n",
      "  Failed: libero_10_image/observation.images.wrist_image: HTTP 404\n",
      "  Downloaded: kaist_nonprehensile/observation.images.image (0.9MB)\n",
      "  Failed: libero_10_image/observation.images.wrist_image: HTTP 404\n",
      "  Downloaded: jaco_play/observation.images.image (0.4MB)\n",
      "  Failed: libero_goal_image/observation.images.image: HTTP 404\n",
      "    Progress: 120/175 completed\n",
      "  Failed: libero_goal_image/observation.images.wrist_image: HTTP 404\n",
      "  Downloaded: jaco_play/observation.images.image (0.4MB)\n",
      "  Failed: libero_goal_image/observation.images.image: HTTP 404\n",
      "    Progress: 120/175 completed\n",
      "  Failed: libero_goal_image/observation.images.wrist_image: HTTP 404\n",
      "  Failed: libero_object_image/observation.images.image: HTTP 404\n",
      "  Failed: libero_object_image/observation.images.wrist_image: HTTP 404\n",
      "  Failed: libero_spatial_image/observation.images.image: HTTP 404\n",
      "  Failed: libero_object_image/observation.images.image: HTTP 404\n",
      "  Failed: libero_object_image/observation.images.wrist_image: HTTP 404\n",
      "  Failed: libero_spatial_image/observation.images.image: HTTP 404\n",
      "  Failed: metaworld_mt50/observation.image: HTTP 404\n",
      "  Failed: libero_spatial_image/observation.images.wrist_image: HTTP 404\n",
      "  Failed: metaworld_mt50_push_v2_image/observation.image: HTTP 404\n",
      "  Failed: metaworld_mt50/observation.image: HTTP 404\n",
      "  Failed: libero_spatial_image/observation.images.wrist_image: HTTP 404\n",
      "  Failed: metaworld_mt50_push_v2_image/observation.image: HTTP 404\n",
      "  Downloaded: nyu_franka_play_dataset/observation.images.image_additional_view (0.2MB)\n",
      "  Downloaded: nyu_franka_play_dataset/observation.images.image (0.2MB)\n",
      "  Downloaded: nyu_franka_play_dataset/observation.images.image_additional_view (0.2MB)\n",
      "  Downloaded: nyu_franka_play_dataset/observation.images.image (0.2MB)\n",
      "  Downloaded: nyu_door_opening_surprising_effectiveness/observation.images.image (1.2MB)\n",
      "    Progress: 130/175 completed\n",
      "  Failed: pusht/observation.image: HTTP 404\n",
      "  Downloaded: nyu_door_opening_surprising_effectiveness/observation.images.image (1.2MB)\n",
      "    Progress: 130/175 completed\n",
      "  Failed: pusht/observation.image: HTTP 404\n",
      "  Downloaded: nyu_rot_dataset/observation.images.image (0.0MB)\n",
      "  Failed: pusht_image/observation.image: HTTP 404\n",
      "  Downloaded: nyu_rot_dataset/observation.images.image (0.0MB)\n",
      "  Failed: pusht_image/observation.image: HTTP 404\n",
      "  Downloaded: roboturk/observation.images.front_rgb (0.3MB)\n",
      "  Downloaded: roboturk/observation.images.front_rgb (0.3MB)\n",
      "  Downloaded: stanford_kuka_multimodal_dataset/observation.images.image (0.1MB)\n",
      "  Downloaded: stanford_kuka_multimodal_dataset/observation.images.image (0.1MB)\n",
      "  Downloaded: stanford_hydra_dataset/observation.images.wrist_image (1.3MB)\n",
      "  Downloaded: stanford_hydra_dataset/observation.images.wrist_image (1.3MB)\n",
      "  Downloaded: stanford_robocook/observation.images.image_1 (0.6MB)\n",
      "  Downloaded: stanford_robocook/observation.images.image_1 (0.6MB)\n",
      "  Downloaded: stanford_robocook/observation.images.image_2 (0.5MB)\n",
      "  Downloaded: stanford_robocook/observation.images.image_2 (0.5MB)\n",
      "  Downloaded: stanford_hydra_dataset/observation.images.image (2.4MB)\n",
      "  Downloaded: stanford_robocook/observation.images.image_4 (0.6MB)\n",
      "    Progress: 140/175 completed\n",
      "  Downloaded: stanford_robocook/observation.images.image_3 (0.4MB)\n",
      "  Downloaded: stanford_hydra_dataset/observation.images.image (2.4MB)\n",
      "  Downloaded: stanford_robocook/observation.images.image_4 (0.6MB)\n",
      "    Progress: 140/175 completed\n",
      "  Downloaded: stanford_robocook/observation.images.image_3 (0.4MB)\n",
      "  Downloaded: taco_play/observation.images.rgb_static (0.2MB)\n",
      "  Downloaded: taco_play/observation.images.rgb_gripper (0.1MB)\n",
      "  Downloaded: taco_play/observation.images.rgb_static (0.2MB)\n",
      "  Downloaded: taco_play/observation.images.rgb_gripper (0.1MB)\n",
      "  Downloaded: tokyo_u_lsmo/observation.images.image (0.4MB)\n",
      "  Downloaded: tokyo_u_lsmo/observation.images.image (0.4MB)\n",
      "  Downloaded: ucsd_kitchen_dataset/observation.images.image (0.3MB)\n",
      "  Downloaded: ucsd_pick_and_place_dataset/observation.images.image (0.1MB)\n",
      "  Downloaded: toto/observation.images.image (3.7MB)\n",
      "  Downloaded: ucsd_kitchen_dataset/observation.images.image (0.3MB)\n",
      "  Downloaded: ucsd_pick_and_place_dataset/observation.images.image (0.1MB)\n",
      "  Downloaded: toto/observation.images.image (3.7MB)\n",
      "  Downloaded: umi_cup_in_the_wild/observation.image (2.1MB)\n",
      "  Downloaded: umi_cup_in_the_wild/observation.image (2.1MB)\n",
      "  Downloaded: unitreeh1_fold_clothes/observation.images.cam_right (10.5MB)\n",
      "  Downloaded: unitreeh1_fold_clothes/observation.images.cam_right (10.5MB)\n",
      "  Downloaded: unitreeh1_rearrange_objects/observation.images.cam_left (2.2MB)\n",
      "    Progress: 150/175 completed\n",
      "  Downloaded: unitreeh1_rearrange_objects/observation.images.cam_left (2.2MB)\n",
      "    Progress: 150/175 completed\n",
      "  Downloaded: unitreeh1_rearrange_objects/observation.images.cam_right (1.6MB)\n",
      "  Downloaded: unitreeh1_rearrange_objects/observation.images.cam_right (1.6MB)\n",
      "  Downloaded: unitreeh1_two_robot_greeting/observation.images.cam_left (1.8MB)\n",
      "  Downloaded: unitreeh1_two_robot_greeting/observation.images.cam_left (1.8MB)\n",
      "  Downloaded: unitreeh1_two_robot_greeting/observation.images.cam_right (0.9MB)\n",
      "  Downloaded: unitreeh1_two_robot_greeting/observation.images.cam_right (0.9MB)\n",
      "  Downloaded: unitreeh1_fold_clothes/observation.images.cam_left (13.5MB)\n",
      "  Downloaded: unitreeh1_fold_clothes/observation.images.cam_left (13.5MB)\n",
      "  Downloaded: usc_cloth_sim/observation.images.image (0.0MB)\n",
      "  Downloaded: usc_cloth_sim/observation.images.image (0.0MB)\n",
      "  Downloaded: unitreeh1_warehouse/observation.images.cam_right (3.6MB)\n",
      "  Downloaded: utaustin_mutex/observation.images.image (0.5MB)\n",
      "  Downloaded: unitreeh1_warehouse/observation.images.cam_right (3.6MB)\n",
      "  Downloaded: utaustin_mutex/observation.images.image (0.5MB)\n",
      "  Downloaded: unitreeh1_warehouse/observation.images.cam_left (6.5MB)\n",
      "  Downloaded: utaustin_mutex/observation.images.wrist_image (0.1MB)\n",
      "  Downloaded: unitreeh1_warehouse/observation.images.cam_left (6.5MB)\n",
      "  Downloaded: utaustin_mutex/observation.images.wrist_image (0.1MB)\n",
      "  Downloaded: utokyo_pr2_opening_fridge/observation.images.image (0.3MB)\n",
      "    Progress: 160/175 completed\n",
      "  Downloaded: utokyo_pr2_tabletop_manipulation/observation.images.image (0.1MB)\n",
      "  Downloaded: utokyo_saytap/observation.images.wrist_image (0.0MB)\n",
      "  Downloaded: utokyo_pr2_opening_fridge/observation.images.image (0.3MB)\n",
      "    Progress: 160/175 completed\n",
      "  Downloaded: utokyo_pr2_tabletop_manipulation/observation.images.image (0.1MB)\n",
      "  Downloaded: utokyo_saytap/observation.images.wrist_image (0.0MB)\n",
      "  Downloaded: utokyo_saytap/observation.images.image (0.0MB)\n",
      "  Downloaded: utokyo_saytap/observation.images.image (0.0MB)\n",
      "  Downloaded: utokyo_xarm_bimanual/observation.images.image (0.0MB)\n",
      "  Downloaded: utokyo_xarm_bimanual/observation.images.image (0.0MB)\n",
      "  Downloaded: utokyo_xarm_pick_and_place/observation.images.hand_image (0.1MB)\n",
      "  Downloaded: utokyo_xarm_pick_and_place/observation.images.image2 (0.2MB)\n",
      "  Downloaded: utokyo_xarm_pick_and_place/observation.images.hand_image (0.1MB)\n",
      "  Downloaded: utokyo_xarm_pick_and_place/observation.images.image2 (0.2MB)\n",
      "  Failed: xarm_lift_medium/observation.image: HTTP 404\n",
      "  Failed: xarm_lift_medium_image/observation.image: HTTP 404\n",
      "  Failed: xarm_lift_medium_replay/observation.image: HTTP 404\n",
      "  Failed: xarm_lift_medium/observation.image: HTTP 404\n",
      "  Failed: xarm_lift_medium_image/observation.image: HTTP 404\n",
      "  Failed: xarm_lift_medium_replay/observation.image: HTTP 404\n",
      "  Failed: xarm_lift_medium_replay_image/observation.image: HTTP 404\n",
      "    Progress: 170/175 completed\n",
      "  Failed: xarm_push_medium/observation.image: HTTP 404\n",
      "  Failed: xarm_lift_medium_replay_image/observation.image: HTTP 404\n",
      "    Progress: 170/175 completed\n",
      "  Failed: xarm_push_medium/observation.image: HTTP 404\n",
      "  Failed: xarm_push_medium_image/observation.image: HTTP 404\n",
      "  Downloaded: utokyo_xarm_pick_and_place/observation.images.image (0.2MB)\n",
      "  Failed: xarm_push_medium_replay/observation.image: HTTP 404\n",
      "  Failed: xarm_push_medium_image/observation.image: HTTP 404\n",
      "  Downloaded: utokyo_xarm_pick_and_place/observation.images.image (0.2MB)\n",
      "  Failed: xarm_push_medium_replay/observation.image: HTTP 404\n",
      "  Failed: xarm_push_medium_replay_image/observation.image: HTTP 404\n",
      "\n",
      "Download Summary:\n",
      "  Successfully downloaded: 144\n",
      "  Already existed: 0\n",
      "  Failed: 31\n",
      "  Total size: 461.9 MB\n",
      "\n",
      "Video download completed!\n",
      "Check the 'videos/' folder for downloaded content\n",
      "  Failed: xarm_push_medium_replay_image/observation.image: HTTP 404\n",
      "\n",
      "Download Summary:\n",
      "  Successfully downloaded: 144\n",
      "  Already existed: 0\n",
      "  Failed: 31\n",
      "  Total size: 461.9 MB\n",
      "\n",
      "Video download completed!\n",
      "Check the 'videos/' folder for downloaded content\n"
     ]
    }
   ],
   "source": [
    "# Execute video downloads\n",
    "if 'df_metrics' in locals() and not df_metrics.empty:\n",
    "    print(\"Starting video download process...\")\n",
    "    \n",
    "    # For full run: remove max_datasets parameter\n",
    "    downloaded_videos, failed_videos = download_episode_videos(\n",
    "        df_metrics, \n",
    "        videos_folder=\"videos\", \n",
    "        max_datasets=None,  # FULL PROCESSING: Download from all datasets with cameras\n",
    "        max_workers=3\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nVideo download completed!\")\n",
    "    print(f\"Check the 'videos/' folder for downloaded content\")\n",
    "    \n",
    "else:\n",
    "    print(\"No dataset metrics available. Run the previous cells first.\")\n",
    "    downloaded_videos, failed_videos = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae294fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML generation function ready!\n"
     ]
    }
   ],
   "source": [
    "def create_dataset_html_with_videos(datasets_df, downloaded_videos, output_file=\"lerobot_datasets_videos.html\"):\n",
    "    \"\"\"Create an interactive HTML page with embedded videos\"\"\"\n",
    "    \n",
    "    print(f\"Creating HTML page: {output_file}\")\n",
    "    \n",
    "    # Create video lookup\n",
    "    video_lookup = {}\n",
    "    for video in downloaded_videos:\n",
    "        key = f\"{video['dataset']}_{video['camera']}\"\n",
    "        video_lookup[key] = video\n",
    "    \n",
    "    # Filter successful datasets\n",
    "    successful_df = datasets_df[datasets_df['num_episodes'] != 'Error'].copy()\n",
    "    if len(successful_df) > 0:\n",
    "        successful_df['num_episodes'] = pd.to_numeric(successful_df['num_episodes'])\n",
    "        successful_df = successful_df.sort_values('num_episodes', ascending=False)\n",
    "    \n",
    "    # HTML template\n",
    "    html_content = f\"\"\"<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>LeRobot Datasets - Explorer ({len(successful_df)} datasets)</title>\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "            max-width: 1400px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            background-color: #f8f9fa;\n",
    "            line-height: 1.6;\n",
    "        }}\n",
    "        .header {{\n",
    "            text-align: center;\n",
    "            margin-bottom: 40px;\n",
    "            padding: 30px;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            color: white;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 4px 6px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .stats {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));\n",
    "            gap: 20px;\n",
    "            margin: 30px 0;\n",
    "        }}\n",
    "        .stat-card {{\n",
    "            background: white;\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "            text-align: center;\n",
    "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .stat-number {{\n",
    "            font-size: 2em;\n",
    "            font-weight: bold;\n",
    "            color: #667eea;\n",
    "        }}\n",
    "        .dataset-grid {{\n",
    "            display: grid;\n",
    "            gap: 25px;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(500px, 1fr));\n",
    "        }}\n",
    "        .dataset-card {{\n",
    "            background: white;\n",
    "            border-radius: 12px;\n",
    "            padding: 25px;\n",
    "            box-shadow: 0 3px 12px rgba(0,0,0,0.1);\n",
    "            transition: transform 0.2s;\n",
    "        }}\n",
    "        .dataset-card:hover {{\n",
    "            transform: translateY(-2px);\n",
    "            box-shadow: 0 5px 20px rgba(0,0,0,0.15);\n",
    "        }}\n",
    "        .dataset-name {{\n",
    "            font-size: 1.4em;\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 15px;\n",
    "            color: #2c3e50;\n",
    "        }}\n",
    "        .dataset-stats {{\n",
    "            margin: 15px 0;\n",
    "            color: #666;\n",
    "        }}\n",
    "        .category-tag {{\n",
    "            display: inline-block;\n",
    "            background: #e3f2fd;\n",
    "            color: #1976d2;\n",
    "            padding: 4px 12px;\n",
    "            border-radius: 20px;\n",
    "            font-size: 0.8em;\n",
    "            font-weight: bold;\n",
    "            margin-right: 10px;\n",
    "        }}\n",
    "        .video-section {{\n",
    "            margin-top: 20px;\n",
    "        }}\n",
    "        .video-grid {{\n",
    "            display: grid;\n",
    "            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));\n",
    "            gap: 15px;\n",
    "            margin-top: 15px;\n",
    "        }}\n",
    "        .video-container {{\n",
    "            text-align: center;\n",
    "        }}\n",
    "        .camera-label {{\n",
    "            font-weight: bold;\n",
    "            margin-bottom: 8px;\n",
    "            color: #495057;\n",
    "            font-size: 0.9em;\n",
    "        }}\n",
    "        video {{\n",
    "            width: 100%;\n",
    "            max-width: 300px;\n",
    "            height: auto;\n",
    "            border-radius: 8px;\n",
    "            box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .no-videos {{\n",
    "            background: #e9ecef;\n",
    "            color: #6c757d;\n",
    "            padding: 30px 20px;\n",
    "            border-radius: 8px;\n",
    "            text-align: center;\n",
    "            font-style: italic;\n",
    "        }}\n",
    "        .video-link {{\n",
    "            display: block;\n",
    "            margin-top: 5px;\n",
    "            font-size: 0.8em;\n",
    "            color: #667eea;\n",
    "            text-decoration: none;\n",
    "        }}\n",
    "        .video-link:hover {{\n",
    "            text-decoration: underline;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>LeRobot Datasets Explorer</h1>\n",
    "        <p>Interactive exploration of {len(successful_df)} robot learning datasets</p>\n",
    "        <p style=\"opacity: 0.9; font-size: 0.9em;\">Generated on {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    </div>\n",
    "\"\"\"\n",
    "    \n",
    "    # Statistics section\n",
    "    if len(successful_df) > 0:\n",
    "        total_episodes = successful_df['num_episodes'].sum()\n",
    "        total_samples = successful_df['total_samples'].sum() if 'total_samples' in successful_df.columns else 0\n",
    "        datasets_with_videos = len(set(v['dataset'] for v in downloaded_videos))\n",
    "        \n",
    "        html_content += f\"\"\"    <div class=\"stats\">\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{len(successful_df)}</div>\n",
    "            <div>Datasets</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{int(total_episodes):,}</div>\n",
    "            <div>Episodes</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{int(total_samples):,}</div>\n",
    "            <div>Samples</div>\n",
    "        </div>\n",
    "        <div class=\"stat-card\">\n",
    "            <div class=\"stat-number\">{datasets_with_videos}</div>\n",
    "            <div>With Videos</div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"dataset-grid\">\n",
    "\"\"\"\n",
    "    \n",
    "    # Generate dataset cards\n",
    "    for _, row in successful_df.iterrows():\n",
    "        dataset_name = row['dataset_name']\n",
    "        dataset_short = dataset_name.replace('lerobot/', '')\n",
    "        \n",
    "        episodes = int(row['num_episodes']) if row['num_episodes'] != 'Error' else 'Unknown'\n",
    "        samples = int(row['total_samples']) if row['total_samples'] != 'Error' else 'Unknown'\n",
    "        \n",
    "        # Find videos for this dataset\n",
    "        dataset_videos = [v for v in downloaded_videos if v['dataset'] == dataset_short]\n",
    "        \n",
    "        # Video section\n",
    "        video_section_html = \"\"\n",
    "        if dataset_videos:\n",
    "            video_section_html = '<div class=\"video-grid\">'\n",
    "            for video in dataset_videos:\n",
    "                camera_display = video['camera'].replace('observation.images.', '').replace('.', ' ')\n",
    "                relative_path = f\"videos/{video['dataset']}/{os.path.basename(video['path'])}\"\n",
    "                file_size = video.get('size', 0) / (1024*1024)\n",
    "                \n",
    "                video_section_html += f\"\"\"\n",
    "                <div class=\"video-container\">\n",
    "                    <div class=\"camera-label\">Camera: {camera_display}</div>\n",
    "                    <video class=\"video-player\" controls preload=\"metadata\">\n",
    "                        <source src=\"{relative_path}\" type=\"video/mp4\">\n",
    "                        Your browser does not support the video tag.\n",
    "                    </video>\n",
    "                    <a href=\"{relative_path}\" target=\"_blank\" class=\"video-link\">Download ({file_size:.1f} MB)</a>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            video_section_html += '</div>'\n",
    "        else:\n",
    "            video_section_html = '<div class=\"no-videos\">No local videos available for this dataset</div>'\n",
    "        \n",
    "        html_content += f\"\"\"        <div class=\"dataset-card\">\n",
    "            <div class=\"dataset-name\">{dataset_short}</div>\n",
    "            <div class=\"dataset-stats\">\n",
    "                <span class=\"category-tag\">{row['category']}</span>\n",
    "                <strong>{episodes:,}</strong> episodes  <strong>{samples:,}</strong> samples\n",
    "            </div>\n",
    "            <div class=\"video-section\">\n",
    "                {video_section_html}\n",
    "            </div>\n",
    "        </div>\n",
    "\"\"\"\n",
    "    \n",
    "    # Close HTML\n",
    "    html_content += \"\"\"    </div>\n",
    "    \n",
    "    <div style=\"text-align: center; margin-top: 40px; color: #7f8c8d;\">\n",
    "        <p>Generated from LeRobot Dataset Exploration Notebook</p>\n",
    "        <p><a href=\"https://github.com/huggingface/lerobot\" target=\"_blank\">LeRobot GitHub</a>  \n",
    "           <a href=\"https://lerobot.huggingface.co\" target=\"_blank\">Documentation</a></p>\n",
    "        <p><small>Videos stored locally for offline browsing</small></p>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\"\"\"\n",
    "    \n",
    "    # Write HTML file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    file_path = Path(output_file).resolve()\n",
    "    print(f\"HTML file created: {output_file}\")\n",
    "    print(f\"Open in browser: file://{file_path}\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "print(\"HTML generation function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75134c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating final HTML page...\n",
      "Creating HTML page: lerobot_datasets_videos.html\n",
      "HTML file created: lerobot_datasets_videos.html\n",
      "Open in browser: file:///Users/michelmeyer/Library/CloudStorage/Dropbox/Dev/LeRobotLab/notebooks/lerobot_datasets_videos.html\n",
      "Opened in browser automatically\n",
      "\n",
      "Final Project Statistics:\n",
      "  Datasets processed: 103\n",
      "  Videos downloaded: 144\n",
      "  HTML file: lerobot_datasets_videos.html\n"
     ]
    }
   ],
   "source": [
    "# Generate the HTML page\n",
    "if 'df_metrics' in locals() and 'downloaded_videos' in locals():\n",
    "    print(\"Generating final HTML page...\")\n",
    "    \n",
    "    html_file = create_dataset_html_with_videos(\n",
    "        df_metrics, \n",
    "        downloaded_videos, \n",
    "        output_file=\"lerobot_datasets_videos.html\"\n",
    "    )\n",
    "    \n",
    "    # Try to open in browser\n",
    "    import webbrowser\n",
    "    try:\n",
    "        abs_path = Path(html_file).resolve()\n",
    "        webbrowser.open(f'file://{abs_path}')\n",
    "        print(f\"Opened in browser automatically\")\n",
    "    except Exception as e:\n",
    "        print(f\"Manual link: file://{Path(html_file).resolve()}\")\n",
    "    \n",
    "    # Final statistics\n",
    "    print(f\"\\nFinal Project Statistics:\")\n",
    "    print(f\"  Datasets processed: {len(df_metrics)}\")\n",
    "    print(f\"  Videos downloaded: {len(downloaded_videos)}\")\n",
    "    print(f\"  HTML file: {html_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Missing data. Please run all previous cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1bb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PROJECT COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"LeRobot Dataset Explorer successfully created!\")\n",
    "print(f\"Open lerobot_datasets_videos.html to explore {len(df_metrics) if 'df_metrics' in locals() else 'all'} datasets\")\n",
    "print(f\"Videos stored in the 'videos/' folder\")\n",
    "print(\"Happy robot learning!\")\n",
    "print(\"End of notebook execution.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lerobotlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
